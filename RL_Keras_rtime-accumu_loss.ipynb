{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Trains an agent with (stochastic) Policy Gradients on Pong. Uses OpenAI Gym. \"\"\"\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from matplotlib import pyplot as plt\n",
    "# hyperparameters\n",
    "H = 200 # number of hidden layer neurons\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "learning_rate = 1e-4\n",
    "gamma = 0.99 # discount factor for reward\n",
    "# gamma = 1-0.\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "resume = True # resume from previous checkpoint?\n",
    "# resume = False;\n",
    "render = False\n",
    "# render = True\n",
    "backlen=20;\n",
    "\n",
    "\n",
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(xrange(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def policy_backward(eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "def lookback(lst):\n",
    "    lst = lst[-backlen:];\n",
    "#     np.pad(lst,(20-lst.size,), 'constant', constant_values=0);\n",
    "    if len(lst) != backlen:\n",
    "        lst = [None]*(backlen-len(lst)) + lst;\n",
    "    return(lst)\n",
    "\n",
    "def time_rewards(r):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    grad = 0;\n",
    "    for t in reversed(xrange(0, r.size)):\n",
    "#         grad = grad * gamma + r[t] ;\n",
    "        if r[t] != 0: \n",
    "            running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "            grad = 2 * (r[t] > 0) - 1; \n",
    "        running_add = running_add + grad;\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initiliase topology\n",
    "* set input and output\n",
    "* set optimiser\n",
    "* set routine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model initialization\n",
    "resume = 1;\n",
    "# resume = True;\n",
    "render = False;\n",
    "render = True;\n",
    "H=5;\n",
    "k=4;\n",
    "gamma = 0.99;\n",
    "D1=80;D2=80;\n",
    "D = 80 * 80 # input dimensionality: 80x80 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "from keras.layers import Input, Dense, convolutional,core,concatenate,Flatten\n",
    "from keras.models import Model,load_model\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "def quickax():\n",
    "    fig = plt.figure(figsize=[8,8])\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    return ax1\n",
    "def savemodel(m,ModelFile):\n",
    "    # serialize model to JSON\n",
    "    model_json = m.to_json()\n",
    "    with open(ModelFile+'.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(ModelFile+'.h5')\n",
    "    pickle.dump(losshist,open(ModelFile+'.p', \"wb\"))\n",
    "    print(\"Saved model to disk at \"+ModelFile)\n",
    "# savemodel(model,ModelFile)\n",
    "\n",
    "# load json and create model\n",
    "def loadmodel(ModelFile):\n",
    "    global losshist,episode_number\n",
    "    json_file = open(ModelFile+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(ModelFile+'.h5')\n",
    "#     print(\"Saved model to disk at \"+ModelFile)\n",
    "    losshist = pickle.load(open(ModelFile+'.p', 'rb'))\n",
    "    episode_number = len(losshist.losses);\n",
    "    print(\"Model loaded from disk at \"+ModelFile)\n",
    "    return(loaded_model)\n",
    "# model = loadmodel(ModelFile)\n",
    "class LossCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "class LossHist():\n",
    "    def __init__(self):\n",
    "        self.losses=[];\n",
    "    def add(self,n,loss):\n",
    "        l = len(self.losses);\n",
    "        if n == l+1:\n",
    "            self.losses.append(loss);\n",
    "        else:\n",
    "            self.losses += [0]*(n-l);\n",
    "            self.losses = self.losses[:n];\n",
    "            self.losses[n-1] = loss;\n",
    "            print('Loss history has changed ')\n",
    "    def vis(self,ax):\n",
    "        ax.plot(self.losses,'-');\n",
    "        pass\n",
    "\n",
    "def lossfunc(y_true,y_pred):\n",
    "    return K.mean(K.mean( K.square( y_pred / (K.abs(y_true)+1) - 1)  )); \n",
    "# tpr=time_epr;\n",
    "def decouple(tpr):\n",
    "    tpr1=np.maximum(tpr,0);\n",
    "    tpr2=np.minimum(tpr,0);\n",
    "    tpr1[tpr1==0]=np.maximum(np.max(tpr1),20);\n",
    "    tpr2[tpr2==0]=np.minimum(np.min(tpr2),-20);\n",
    "    tpr2=-tpr2;\n",
    "    time_epr = np.hstack([tpr1,tpr2])\n",
    "    return(time_epr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_input = Input(shape=(D1,D2,1,))\n",
    "po_input = Input(shape=(1,));\n",
    "conv1 = convolutional.Conv2D(filters=H,\n",
    "                             kernel_size=(k,k),\n",
    "                            strides=(1,1),\n",
    "                            padding='same',\n",
    "                            activation='relu')(x_input)\n",
    "den1 = Flatten()(Dense(units=5*H,\n",
    "             activation='relu')(conv1))\n",
    "\n",
    "den1c = concatenate([den1,po_input]);\n",
    "score = Dense(units=2,\n",
    "              activation = 'relu')(den1c)\n",
    "\n",
    "model = Model(inputs=[x_input,po_input], outputs=[score])\n",
    "\n",
    "optimiser = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=lossfunc)\n",
    "history = LossCallback()\n",
    "# log = model.fit([epx,epy], time_epr,callbacks=[history])\n",
    "# loss = model.train_on_batch([epx,epy], time_epr)\n",
    "# print(history.losses[-1])\n",
    "# x = Dense(64, activation='relu')(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xinput.shape\n",
    "del model\n",
    "del losshist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1.0300502315163613)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPMAAADoCAYAAAA659JnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJVKEf8fdsWlBbJsyXEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f323c0bbf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# losshist_temp=losshist;\n",
    "\n",
    "ax = quickax();\n",
    "losses = losshist.losses;\n",
    "losshist = LossHist();\n",
    "losshist.losses = losses;\n",
    "losshist.vis(ax);\n",
    "ax.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEyCAYAAACGZHknAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhoQrQzHunUgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f323c027090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# discount_rewards(epdlogp)\n",
    "x.size\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "fig=plt.figure(figsize=[5,5])\n",
    "ax1=plt.subplot()\n",
    "# ax1.plot(time_epr)\n",
    "# ax1.plot(discounted_epr)\n",
    "ax1.scatter(abs(time_epr),eptpred)\n",
    "# ax1.set_xlim([0, 200])\n",
    "# ax1.set_xlim([800, 1000])\n",
    "# ax1.set_ylim([-10, 000])\n",
    "# ax1.imshow(eph[:500,:500].T)\n",
    "time_epr.size\n",
    "# tpreds.size\n",
    "D1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-05 18:26:41,899] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 90 reward total was -21.000000. loss_func: 0.225661\n",
      "resetting env. episode 91 reward total was -21.000000. loss_func: 0.539773\n",
      "resetting env. episode 92 reward total was -21.000000. loss_func: 0.234752\n",
      "resetting env. episode 93 reward total was -19.000000. loss_func: 0.663639\n",
      "resetting env. episode 94 reward total was -21.000000. loss_func: 0.212461\n",
      "resetting env. episode 95 reward total was -21.000000. loss_func: 0.273226\n",
      "resetting env. episode 96 reward total was -21.000000. loss_func: 0.204887\n",
      "resetting env. episode 97 reward total was -21.000000. loss_func: 0.141673\n",
      "resetting env. episode 98 reward total was -20.000000. loss_func: 0.544682\n",
      "resetting env. episode 99 reward total was -21.000000. loss_func: 0.254858\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 100 reward total was -21.000000. loss_func: 0.175006\n",
      "resetting env. episode 101 reward total was -20.000000. loss_func: 0.646351\n",
      "resetting env. episode 102 reward total was -20.000000. loss_func: 0.566101\n",
      "resetting env. episode 103 reward total was -19.000000. loss_func: 0.602543\n",
      "resetting env. episode 104 reward total was -20.000000. loss_func: 0.558299\n",
      "resetting env. episode 105 reward total was -20.000000. loss_func: 0.528320\n",
      "resetting env. episode 106 reward total was -21.000000. loss_func: 0.204816\n",
      "resetting env. episode 107 reward total was -20.000000. loss_func: 0.525634\n",
      "resetting env. episode 108 reward total was -21.000000. loss_func: 0.163200\n",
      "resetting env. episode 109 reward total was -21.000000. loss_func: 0.136290\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 110 reward total was -21.000000. loss_func: 0.225917\n",
      "resetting env. episode 111 reward total was -19.000000. loss_func: 0.595170\n",
      "resetting env. episode 112 reward total was -20.000000. loss_func: 0.618084\n",
      "resetting env. episode 113 reward total was -21.000000. loss_func: 0.187152\n",
      "resetting env. episode 114 reward total was -20.000000. loss_func: 0.527939\n",
      "resetting env. episode 115 reward total was -20.000000. loss_func: 0.615757\n",
      "resetting env. episode 116 reward total was -21.000000. loss_func: 0.235743\n",
      "resetting env. episode 117 reward total was -20.000000. loss_func: 0.580063\n",
      "resetting env. episode 118 reward total was -21.000000. loss_func: 0.202038\n",
      "resetting env. episode 119 reward total was -21.000000. loss_func: 0.183574\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 120 reward total was -21.000000. loss_func: 0.257493\n",
      "resetting env. episode 121 reward total was -19.000000. loss_func: 0.608367\n",
      "resetting env. episode 122 reward total was -21.000000. loss_func: 0.193343\n",
      "resetting env. episode 123 reward total was -21.000000. loss_func: 0.244720\n",
      "resetting env. episode 124 reward total was -21.000000. loss_func: 0.237236\n",
      "resetting env. episode 125 reward total was -21.000000. loss_func: 0.213056\n",
      "resetting env. episode 126 reward total was -21.000000. loss_func: 0.170572\n",
      "resetting env. episode 127 reward total was -21.000000. loss_func: 0.220016\n",
      "resetting env. episode 128 reward total was -20.000000. loss_func: 0.544643\n",
      "resetting env. episode 129 reward total was -20.000000. loss_func: 0.508928\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 130 reward total was -20.000000. loss_func: 0.536119\n",
      "resetting env. episode 131 reward total was -18.000000. loss_func: 0.724009\n",
      "resetting env. episode 132 reward total was -21.000000. loss_func: 0.180206\n",
      "resetting env. episode 133 reward total was -20.000000. loss_func: 0.498036\n",
      "resetting env. episode 134 reward total was -20.000000. loss_func: 0.543193\n",
      "resetting env. episode 135 reward total was -21.000000. loss_func: 0.210102\n",
      "resetting env. episode 136 reward total was -20.000000. loss_func: 0.553472\n",
      "resetting env. episode 137 reward total was -21.000000. loss_func: 0.280279\n",
      "resetting env. episode 138 reward total was -21.000000. loss_func: 0.193840\n",
      "resetting env. episode 139 reward total was -20.000000. loss_func: 0.543194\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 140 reward total was -19.000000. loss_func: 0.668840\n",
      "resetting env. episode 141 reward total was -20.000000. loss_func: 0.608016\n",
      "resetting env. episode 142 reward total was -21.000000. loss_func: 0.200500\n",
      "resetting env. episode 143 reward total was -21.000000. loss_func: 0.172657\n",
      "resetting env. episode 144 reward total was -21.000000. loss_func: 0.206958\n",
      "resetting env. episode 145 reward total was -21.000000. loss_func: 0.204099\n",
      "resetting env. episode 146 reward total was -19.000000. loss_func: 0.620677\n",
      "resetting env. episode 147 reward total was -20.000000. loss_func: 0.548187\n",
      "resetting env. episode 148 reward total was -19.000000. loss_func: 0.564027\n",
      "resetting env. episode 149 reward total was -21.000000. loss_func: 0.181732\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 150 reward total was -21.000000. loss_func: 0.122261\n",
      "resetting env. episode 151 reward total was -20.000000. loss_func: 0.565872\n",
      "resetting env. episode 152 reward total was -21.000000. loss_func: 0.248032\n",
      "resetting env. episode 153 reward total was -21.000000. loss_func: 0.194163\n",
      "resetting env. episode 154 reward total was -20.000000. loss_func: 0.560715\n",
      "resetting env. episode 155 reward total was -20.000000. loss_func: 0.710052\n",
      "resetting env. episode 156 reward total was -20.000000. loss_func: 0.534394\n",
      "resetting env. episode 157 reward total was -21.000000. loss_func: 0.130909\n",
      "resetting env. episode 158 reward total was -20.000000. loss_func: 0.540904\n",
      "resetting env. episode 159 reward total was -21.000000. loss_func: 0.203918\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 160 reward total was -21.000000. loss_func: 0.171223\n",
      "resetting env. episode 161 reward total was -20.000000. loss_func: 0.494980\n",
      "resetting env. episode 162 reward total was -21.000000. loss_func: 0.221778\n",
      "resetting env. episode 163 reward total was -21.000000. loss_func: 0.176224\n",
      "resetting env. episode 164 reward total was -20.000000. loss_func: 0.519664\n",
      "resetting env. episode 165 reward total was -21.000000. loss_func: 0.222239\n",
      "resetting env. episode 166 reward total was -19.000000. loss_func: 0.654967\n",
      "resetting env. episode 167 reward total was -21.000000. loss_func: 0.220798\n",
      "resetting env. episode 168 reward total was -21.000000. loss_func: 0.236313\n",
      "resetting env. episode 169 reward total was -21.000000. loss_func: 0.181041\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 170 reward total was -21.000000. loss_func: 0.222760\n",
      "resetting env. episode 171 reward total was -21.000000. loss_func: 0.203106\n",
      "resetting env. episode 172 reward total was -21.000000. loss_func: 0.205480\n",
      "resetting env. episode 173 reward total was -20.000000. loss_func: 0.534804\n",
      "resetting env. episode 174 reward total was -21.000000. loss_func: 0.141974\n",
      "resetting env. episode 175 reward total was -20.000000. loss_func: 0.502552\n",
      "resetting env. episode 176 reward total was -18.000000. loss_func: 0.649242\n",
      "resetting env. episode 177 reward total was -21.000000. loss_func: 0.204144\n",
      "resetting env. episode 178 reward total was -21.000000. loss_func: 0.204090\n",
      "resetting env. episode 179 reward total was -20.000000. loss_func: 0.501723\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 180 reward total was -21.000000. loss_func: 0.198041\n",
      "resetting env. episode 181 reward total was -19.000000. loss_func: 0.603242\n",
      "resetting env. episode 182 reward total was -21.000000. loss_func: 0.206741\n",
      "resetting env. episode 183 reward total was -19.000000. loss_func: 0.527633\n",
      "resetting env. episode 184 reward total was -18.000000. loss_func: 0.651754\n",
      "resetting env. episode 185 reward total was -21.000000. loss_func: 0.184761\n",
      "resetting env. episode 186 reward total was -21.000000. loss_func: 0.157750\n",
      "resetting env. episode 187 reward total was -20.000000. loss_func: 0.590514\n",
      "resetting env. episode 188 reward total was -21.000000. loss_func: 0.175186\n",
      "resetting env. episode 189 reward total was -21.000000. loss_func: 0.187576\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 190 reward total was -21.000000. loss_func: 0.191784\n",
      "resetting env. episode 191 reward total was -21.000000. loss_func: 0.240664\n",
      "resetting env. episode 192 reward total was -20.000000. loss_func: 0.473161\n",
      "resetting env. episode 193 reward total was -21.000000. loss_func: 0.187245\n",
      "resetting env. episode 194 reward total was -20.000000. loss_func: 0.495300\n",
      "resetting env. episode 195 reward total was -19.000000. loss_func: 0.508455\n",
      "resetting env. episode 196 reward total was -19.000000. loss_func: 0.605880\n",
      "resetting env. episode 197 reward total was -20.000000. loss_func: 0.467911\n",
      "resetting env. episode 198 reward total was -19.000000. loss_func: 0.471598\n",
      "resetting env. episode 199 reward total was -21.000000. loss_func: 0.137421\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 200 reward total was -21.000000. loss_func: 0.226341\n",
      "resetting env. episode 201 reward total was -21.000000. loss_func: 0.141283\n",
      "resetting env. episode 202 reward total was -21.000000. loss_func: 0.236165\n",
      "resetting env. episode 203 reward total was -21.000000. loss_func: 0.243390\n",
      "resetting env. episode 204 reward total was -21.000000. loss_func: 0.173195\n",
      "resetting env. episode 205 reward total was -21.000000. loss_func: 0.200139\n",
      "resetting env. episode 206 reward total was -21.000000. loss_func: 0.202041\n",
      "resetting env. episode 207 reward total was -20.000000. loss_func: 0.448938\n",
      "resetting env. episode 208 reward total was -20.000000. loss_func: 0.487919\n",
      "resetting env. episode 209 reward total was -21.000000. loss_func: 0.173286\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 210 reward total was -21.000000. loss_func: 0.221507\n",
      "resetting env. episode 211 reward total was -20.000000. loss_func: 0.489307\n",
      "resetting env. episode 212 reward total was -21.000000. loss_func: 0.164058\n",
      "resetting env. episode 213 reward total was -21.000000. loss_func: 0.202527\n",
      "resetting env. episode 214 reward total was -21.000000. loss_func: 0.169006\n",
      "resetting env. episode 215 reward total was -21.000000. loss_func: 0.151497\n",
      "resetting env. episode 216 reward total was -21.000000. loss_func: 0.199940\n",
      "resetting env. episode 217 reward total was -20.000000. loss_func: 0.519744\n",
      "resetting env. episode 218 reward total was -21.000000. loss_func: 0.210790\n",
      "resetting env. episode 219 reward total was -20.000000. loss_func: 0.532424\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 220 reward total was -21.000000. loss_func: 0.164120\n",
      "resetting env. episode 221 reward total was -21.000000. loss_func: 0.214050\n",
      "resetting env. episode 222 reward total was -21.000000. loss_func: 0.157162\n",
      "resetting env. episode 223 reward total was -20.000000. loss_func: 0.631897\n",
      "resetting env. episode 224 reward total was -21.000000. loss_func: 0.201790\n",
      "resetting env. episode 225 reward total was -18.000000. loss_func: 0.502976\n",
      "resetting env. episode 226 reward total was -19.000000. loss_func: 0.518662\n",
      "resetting env. episode 227 reward total was -21.000000. loss_func: 0.156742\n",
      "resetting env. episode 228 reward total was -21.000000. loss_func: 0.220265\n",
      "resetting env. episode 229 reward total was -20.000000. loss_func: 0.558457\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 230 reward total was -21.000000. loss_func: 0.177537\n",
      "resetting env. episode 231 reward total was -20.000000. loss_func: 0.469834\n",
      "resetting env. episode 232 reward total was -20.000000. loss_func: 0.580120\n",
      "resetting env. episode 233 reward total was -21.000000. loss_func: 0.145916\n",
      "resetting env. episode 234 reward total was -21.000000. loss_func: 0.208366\n",
      "resetting env. episode 235 reward total was -19.000000. loss_func: 0.530560\n",
      "resetting env. episode 236 reward total was -21.000000. loss_func: 0.133474\n",
      "resetting env. episode 237 reward total was -21.000000. loss_func: 0.182159\n",
      "resetting env. episode 238 reward total was -20.000000. loss_func: 0.496490\n",
      "resetting env. episode 239 reward total was -20.000000. loss_func: 0.483730\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 240 reward total was -20.000000. loss_func: 0.459032\n",
      "resetting env. episode 241 reward total was -21.000000. loss_func: 0.266289\n",
      "resetting env. episode 242 reward total was -21.000000. loss_func: 0.206632\n",
      "resetting env. episode 243 reward total was -20.000000. loss_func: 0.561692\n",
      "resetting env. episode 244 reward total was -21.000000. loss_func: 0.232368\n",
      "resetting env. episode 245 reward total was -21.000000. loss_func: 0.138153\n",
      "resetting env. episode 246 reward total was -21.000000. loss_func: 0.192601\n",
      "resetting env. episode 247 reward total was -20.000000. loss_func: 0.474457\n",
      "resetting env. episode 248 reward total was -21.000000. loss_func: 0.201587\n",
      "resetting env. episode 249 reward total was -21.000000. loss_func: 0.192993\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 250 reward total was -19.000000. loss_func: 0.592922\n",
      "resetting env. episode 251 reward total was -20.000000. loss_func: 0.512573\n",
      "resetting env. episode 252 reward total was -21.000000. loss_func: 0.128279\n",
      "resetting env. episode 253 reward total was -20.000000. loss_func: 0.573368\n",
      "resetting env. episode 254 reward total was -21.000000. loss_func: 0.170604\n",
      "resetting env. episode 255 reward total was -20.000000. loss_func: 0.534267\n",
      "resetting env. episode 256 reward total was -20.000000. loss_func: 0.432824\n",
      "resetting env. episode 257 reward total was -21.000000. loss_func: 0.227760\n",
      "resetting env. episode 258 reward total was -21.000000. loss_func: 0.184268\n",
      "resetting env. episode 259 reward total was -21.000000. loss_func: 0.120623\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 260 reward total was -21.000000. loss_func: 0.182178\n",
      "resetting env. episode 261 reward total was -18.000000. loss_func: 0.504018\n",
      "resetting env. episode 262 reward total was -21.000000. loss_func: 0.209899\n",
      "resetting env. episode 263 reward total was -21.000000. loss_func: 0.206296\n",
      "resetting env. episode 264 reward total was -21.000000. loss_func: 0.179627\n",
      "resetting env. episode 265 reward total was -20.000000. loss_func: 0.439377\n",
      "resetting env. episode 266 reward total was -19.000000. loss_func: 0.503185\n",
      "resetting env. episode 267 reward total was -21.000000. loss_func: 0.194614\n",
      "resetting env. episode 268 reward total was -21.000000. loss_func: 0.188807\n",
      "resetting env. episode 269 reward total was -21.000000. loss_func: 0.163578\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 270 reward total was -21.000000. loss_func: 0.147040\n",
      "resetting env. episode 271 reward total was -19.000000. loss_func: 0.723357\n",
      "resetting env. episode 272 reward total was -20.000000. loss_func: 0.584941\n",
      "resetting env. episode 273 reward total was -20.000000. loss_func: 0.572132\n",
      "resetting env. episode 274 reward total was -21.000000. loss_func: 0.146280\n",
      "resetting env. episode 275 reward total was -20.000000. loss_func: 0.446207\n",
      "resetting env. episode 276 reward total was -21.000000. loss_func: 0.166009\n",
      "resetting env. episode 277 reward total was -21.000000. loss_func: 0.122561\n",
      "resetting env. episode 278 reward total was -20.000000. loss_func: 0.539393\n",
      "resetting env. episode 279 reward total was -20.000000. loss_func: 0.461258\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 280 reward total was -20.000000. loss_func: 0.436011\n",
      "resetting env. episode 281 reward total was -21.000000. loss_func: 0.162769\n",
      "resetting env. episode 282 reward total was -21.000000. loss_func: 0.219459\n",
      "resetting env. episode 283 reward total was -20.000000. loss_func: 0.474026\n",
      "resetting env. episode 284 reward total was -21.000000. loss_func: 0.161220\n",
      "resetting env. episode 285 reward total was -21.000000. loss_func: 0.125786\n",
      "resetting env. episode 286 reward total was -21.000000. loss_func: 0.222702\n",
      "resetting env. episode 287 reward total was -19.000000. loss_func: 0.640702\n",
      "resetting env. episode 288 reward total was -21.000000. loss_func: 0.216339\n",
      "resetting env. episode 289 reward total was -21.000000. loss_func: 0.153121\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 290 reward total was -21.000000. loss_func: 0.122629\n",
      "resetting env. episode 291 reward total was -21.000000. loss_func: 0.160540\n",
      "resetting env. episode 292 reward total was -21.000000. loss_func: 0.183434\n",
      "resetting env. episode 293 reward total was -21.000000. loss_func: 0.212715\n",
      "resetting env. episode 294 reward total was -20.000000. loss_func: 0.459441\n",
      "resetting env. episode 295 reward total was -19.000000. loss_func: 0.510957\n",
      "resetting env. episode 296 reward total was -21.000000. loss_func: 0.219864\n",
      "resetting env. episode 297 reward total was -21.000000. loss_func: 0.152960\n",
      "resetting env. episode 298 reward total was -21.000000. loss_func: 0.205627\n",
      "resetting env. episode 299 reward total was -21.000000. loss_func: 0.214796\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 300 reward total was -21.000000. loss_func: 0.186950\n",
      "resetting env. episode 301 reward total was -21.000000. loss_func: 0.156677\n",
      "resetting env. episode 302 reward total was -21.000000. loss_func: 0.096710\n",
      "resetting env. episode 303 reward total was -21.000000. loss_func: 0.154050\n",
      "resetting env. episode 304 reward total was -21.000000. loss_func: 0.157722\n",
      "resetting env. episode 305 reward total was -19.000000. loss_func: 0.593719\n",
      "resetting env. episode 306 reward total was -20.000000. loss_func: 0.450377\n",
      "resetting env. episode 307 reward total was -21.000000. loss_func: 0.173397\n",
      "resetting env. episode 308 reward total was -21.000000. loss_func: 0.205247\n",
      "resetting env. episode 309 reward total was -20.000000. loss_func: 0.437439\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 310 reward total was -19.000000. loss_func: 0.543427\n",
      "resetting env. episode 311 reward total was -21.000000. loss_func: 0.215195\n",
      "resetting env. episode 312 reward total was -20.000000. loss_func: 0.462152\n",
      "resetting env. episode 313 reward total was -20.000000. loss_func: 0.486593\n",
      "resetting env. episode 314 reward total was -21.000000. loss_func: 0.171140\n",
      "resetting env. episode 315 reward total was -21.000000. loss_func: 0.171760\n",
      "resetting env. episode 316 reward total was -21.000000. loss_func: 0.126545\n",
      "resetting env. episode 317 reward total was -21.000000. loss_func: 0.198936\n",
      "resetting env. episode 318 reward total was -21.000000. loss_func: 0.183606\n",
      "resetting env. episode 319 reward total was -21.000000. loss_func: 0.123273\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 320 reward total was -21.000000. loss_func: 0.126921\n",
      "resetting env. episode 321 reward total was -21.000000. loss_func: 0.113794\n",
      "resetting env. episode 322 reward total was -21.000000. loss_func: 0.153085\n",
      "resetting env. episode 323 reward total was -20.000000. loss_func: 0.461095\n",
      "resetting env. episode 324 reward total was -21.000000. loss_func: 0.203221\n",
      "resetting env. episode 325 reward total was -19.000000. loss_func: 0.546437\n",
      "resetting env. episode 326 reward total was -20.000000. loss_func: 0.444626\n",
      "resetting env. episode 327 reward total was -21.000000. loss_func: 0.159672\n",
      "resetting env. episode 328 reward total was -20.000000. loss_func: 0.486985\n",
      "resetting env. episode 329 reward total was -20.000000. loss_func: 0.538975\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 330 reward total was -21.000000. loss_func: 0.142590\n",
      "resetting env. episode 331 reward total was -21.000000. loss_func: 0.163514\n",
      "resetting env. episode 332 reward total was -21.000000. loss_func: 0.174115\n",
      "resetting env. episode 333 reward total was -21.000000. loss_func: 0.114120\n",
      "resetting env. episode 334 reward total was -20.000000. loss_func: 0.464482\n",
      "resetting env. episode 335 reward total was -21.000000. loss_func: 0.205787\n",
      "resetting env. episode 336 reward total was -20.000000. loss_func: 0.429108\n",
      "resetting env. episode 337 reward total was -20.000000. loss_func: 0.471359\n",
      "resetting env. episode 338 reward total was -21.000000. loss_func: 0.120434\n",
      "resetting env. episode 339 reward total was -21.000000. loss_func: 0.154368\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 340 reward total was -21.000000. loss_func: 0.213905\n",
      "resetting env. episode 341 reward total was -20.000000. loss_func: 0.434625\n",
      "resetting env. episode 342 reward total was -21.000000. loss_func: 0.179992\n",
      "resetting env. episode 343 reward total was -21.000000. loss_func: 0.163258\n",
      "resetting env. episode 344 reward total was -21.000000. loss_func: 0.110268\n",
      "resetting env. episode 345 reward total was -21.000000. loss_func: 0.183899\n",
      "resetting env. episode 346 reward total was -21.000000. loss_func: 0.152993\n",
      "resetting env. episode 347 reward total was -21.000000. loss_func: 0.171189\n",
      "resetting env. episode 348 reward total was -21.000000. loss_func: 0.226283\n",
      "resetting env. episode 349 reward total was -21.000000. loss_func: 0.183463\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 350 reward total was -21.000000. loss_func: 0.124149\n",
      "resetting env. episode 351 reward total was -20.000000. loss_func: 0.565018\n",
      "resetting env. episode 352 reward total was -20.000000. loss_func: 0.408873\n",
      "resetting env. episode 353 reward total was -21.000000. loss_func: 0.206019\n",
      "resetting env. episode 354 reward total was -21.000000. loss_func: 0.227667\n",
      "resetting env. episode 355 reward total was -21.000000. loss_func: 0.155690\n",
      "resetting env. episode 356 reward total was -19.000000. loss_func: 0.582584\n",
      "resetting env. episode 357 reward total was -21.000000. loss_func: 0.136986\n",
      "resetting env. episode 358 reward total was -21.000000. loss_func: 0.136446\n",
      "resetting env. episode 359 reward total was -21.000000. loss_func: 0.141111\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 360 reward total was -21.000000. loss_func: 0.183765\n",
      "resetting env. episode 361 reward total was -20.000000. loss_func: 0.497665\n",
      "resetting env. episode 362 reward total was -21.000000. loss_func: 0.182214\n",
      "resetting env. episode 363 reward total was -21.000000. loss_func: 0.144413\n",
      "resetting env. episode 364 reward total was -21.000000. loss_func: 0.180286\n",
      "resetting env. episode 365 reward total was -20.000000. loss_func: 0.462774\n",
      "resetting env. episode 366 reward total was -19.000000. loss_func: 0.581024\n",
      "resetting env. episode 367 reward total was -21.000000. loss_func: 0.132259\n",
      "resetting env. episode 368 reward total was -21.000000. loss_func: 0.145734\n",
      "resetting env. episode 369 reward total was -21.000000. loss_func: 0.141077\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 370 reward total was -21.000000. loss_func: 0.127951\n",
      "resetting env. episode 371 reward total was -21.000000. loss_func: 0.147690\n",
      "resetting env. episode 372 reward total was -21.000000. loss_func: 0.187058\n",
      "resetting env. episode 373 reward total was -20.000000. loss_func: 0.491499\n",
      "resetting env. episode 374 reward total was -21.000000. loss_func: 0.131744\n",
      "resetting env. episode 375 reward total was -21.000000. loss_func: 0.163429\n",
      "resetting env. episode 376 reward total was -21.000000. loss_func: 0.160671\n",
      "resetting env. episode 377 reward total was -20.000000. loss_func: 0.468521\n",
      "resetting env. episode 378 reward total was -20.000000. loss_func: 0.420844\n",
      "resetting env. episode 379 reward total was -21.000000. loss_func: 0.158080\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 380 reward total was -21.000000. loss_func: 0.135999\n",
      "resetting env. episode 381 reward total was -21.000000. loss_func: 0.142234\n",
      "resetting env. episode 382 reward total was -21.000000. loss_func: 0.104707\n",
      "resetting env. episode 383 reward total was -21.000000. loss_func: 0.171528\n",
      "resetting env. episode 384 reward total was -19.000000. loss_func: 0.554638\n",
      "resetting env. episode 385 reward total was -21.000000. loss_func: 0.131649\n",
      "resetting env. episode 386 reward total was -21.000000. loss_func: 0.171836\n",
      "resetting env. episode 387 reward total was -21.000000. loss_func: 0.091345\n",
      "resetting env. episode 388 reward total was -21.000000. loss_func: 0.147068\n",
      "resetting env. episode 389 reward total was -18.000000. loss_func: 0.497146\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 390 reward total was -20.000000. loss_func: 0.437697\n",
      "resetting env. episode 391 reward total was -20.000000. loss_func: 0.403838\n",
      "resetting env. episode 392 reward total was -19.000000. loss_func: 0.471298\n",
      "resetting env. episode 393 reward total was -21.000000. loss_func: 0.200231\n",
      "resetting env. episode 394 reward total was -21.000000. loss_func: 0.186238\n",
      "resetting env. episode 395 reward total was -18.000000. loss_func: 0.444478\n",
      "resetting env. episode 396 reward total was -21.000000. loss_func: 0.148404\n",
      "resetting env. episode 397 reward total was -21.000000. loss_func: 0.113617\n",
      "resetting env. episode 398 reward total was -21.000000. loss_func: 0.222633\n",
      "resetting env. episode 399 reward total was -21.000000. loss_func: 0.166513\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 400 reward total was -21.000000. loss_func: 0.165215\n",
      "resetting env. episode 401 reward total was -21.000000. loss_func: 0.170197\n",
      "resetting env. episode 402 reward total was -19.000000. loss_func: 0.425649\n",
      "resetting env. episode 403 reward total was -19.000000. loss_func: 0.485118\n",
      "resetting env. episode 404 reward total was -21.000000. loss_func: 0.138786\n",
      "resetting env. episode 405 reward total was -21.000000. loss_func: 0.133595\n",
      "resetting env. episode 406 reward total was -21.000000. loss_func: 0.144822\n",
      "resetting env. episode 407 reward total was -21.000000. loss_func: 0.156399\n",
      "resetting env. episode 408 reward total was -19.000000. loss_func: 0.537746\n",
      "resetting env. episode 409 reward total was -21.000000. loss_func: 0.152543\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 410 reward total was -21.000000. loss_func: 0.198311\n",
      "resetting env. episode 411 reward total was -21.000000. loss_func: 0.143627\n",
      "resetting env. episode 412 reward total was -21.000000. loss_func: 0.128220\n",
      "resetting env. episode 413 reward total was -19.000000. loss_func: 0.453136\n",
      "resetting env. episode 414 reward total was -21.000000. loss_func: 0.155637\n",
      "resetting env. episode 415 reward total was -21.000000. loss_func: 0.145794\n",
      "resetting env. episode 416 reward total was -20.000000. loss_func: 0.458653\n",
      "resetting env. episode 417 reward total was -21.000000. loss_func: 0.164387\n",
      "resetting env. episode 418 reward total was -20.000000. loss_func: 0.449812\n",
      "resetting env. episode 419 reward total was -21.000000. loss_func: 0.151634\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 420 reward total was -21.000000. loss_func: 0.172821\n",
      "resetting env. episode 421 reward total was -19.000000. loss_func: 0.499715\n",
      "resetting env. episode 422 reward total was -20.000000. loss_func: 0.520833\n",
      "resetting env. episode 423 reward total was -20.000000. loss_func: 0.445822\n",
      "resetting env. episode 424 reward total was -21.000000. loss_func: 0.151342\n",
      "resetting env. episode 425 reward total was -21.000000. loss_func: 0.135807\n",
      "resetting env. episode 426 reward total was -21.000000. loss_func: 0.155830\n",
      "resetting env. episode 427 reward total was -21.000000. loss_func: 0.133564\n",
      "resetting env. episode 428 reward total was -21.000000. loss_func: 0.140485\n",
      "resetting env. episode 429 reward total was -20.000000. loss_func: 0.513447\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 430 reward total was -20.000000. loss_func: 0.416758\n",
      "resetting env. episode 431 reward total was -21.000000. loss_func: 0.193607\n",
      "resetting env. episode 432 reward total was -21.000000. loss_func: 0.184894\n",
      "resetting env. episode 433 reward total was -18.000000. loss_func: 0.454845\n",
      "resetting env. episode 434 reward total was -19.000000. loss_func: 0.442724\n",
      "resetting env. episode 435 reward total was -21.000000. loss_func: 0.136187\n",
      "resetting env. episode 436 reward total was -21.000000. loss_func: 0.094468\n",
      "resetting env. episode 437 reward total was -21.000000. loss_func: 0.148177\n",
      "resetting env. episode 438 reward total was -19.000000. loss_func: 0.437998\n",
      "resetting env. episode 439 reward total was -20.000000. loss_func: 0.633380\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 440 reward total was -21.000000. loss_func: 0.143231\n",
      "resetting env. episode 441 reward total was -20.000000. loss_func: 0.427672\n",
      "resetting env. episode 442 reward total was -20.000000. loss_func: 0.403788\n",
      "resetting env. episode 443 reward total was -21.000000. loss_func: 0.142736\n",
      "resetting env. episode 444 reward total was -21.000000. loss_func: 0.138515\n",
      "resetting env. episode 445 reward total was -21.000000. loss_func: 0.177345\n",
      "resetting env. episode 446 reward total was -20.000000. loss_func: 0.418966\n",
      "resetting env. episode 447 reward total was -21.000000. loss_func: 0.113162\n",
      "resetting env. episode 448 reward total was -18.000000. loss_func: 0.432634\n",
      "resetting env. episode 449 reward total was -21.000000. loss_func: 0.122795\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 450 reward total was -20.000000. loss_func: 0.461639\n",
      "resetting env. episode 451 reward total was -21.000000. loss_func: 0.174365\n",
      "resetting env. episode 452 reward total was -21.000000. loss_func: 0.178716\n",
      "resetting env. episode 453 reward total was -20.000000. loss_func: 0.445494\n",
      "resetting env. episode 454 reward total was -20.000000. loss_func: 0.382391\n",
      "resetting env. episode 455 reward total was -21.000000. loss_func: 0.111208\n",
      "resetting env. episode 456 reward total was -20.000000. loss_func: 0.427852\n",
      "resetting env. episode 457 reward total was -21.000000. loss_func: 0.179844\n",
      "resetting env. episode 458 reward total was -20.000000. loss_func: 0.405504\n",
      "resetting env. episode 459 reward total was -20.000000. loss_func: 0.381378\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 460 reward total was -21.000000. loss_func: 0.120668\n",
      "resetting env. episode 461 reward total was -21.000000. loss_func: 0.143779\n",
      "resetting env. episode 462 reward total was -21.000000. loss_func: 0.152349\n",
      "resetting env. episode 463 reward total was -20.000000. loss_func: 0.410959\n",
      "resetting env. episode 464 reward total was -21.000000. loss_func: 0.136285\n",
      "resetting env. episode 465 reward total was -21.000000. loss_func: 0.131879\n",
      "resetting env. episode 466 reward total was -21.000000. loss_func: 0.140093\n",
      "resetting env. episode 467 reward total was -18.000000. loss_func: 0.606351\n",
      "resetting env. episode 468 reward total was -19.000000. loss_func: 0.461018\n",
      "resetting env. episode 469 reward total was -21.000000. loss_func: 0.163765\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 470 reward total was -21.000000. loss_func: 0.135294\n",
      "resetting env. episode 471 reward total was -21.000000. loss_func: 0.139248\n",
      "resetting env. episode 472 reward total was -21.000000. loss_func: 0.160458\n",
      "resetting env. episode 473 reward total was -21.000000. loss_func: 0.175704\n",
      "resetting env. episode 474 reward total was -19.000000. loss_func: 0.541027\n",
      "resetting env. episode 475 reward total was -21.000000. loss_func: 0.110741\n",
      "resetting env. episode 476 reward total was -20.000000. loss_func: 0.578201\n",
      "resetting env. episode 477 reward total was -21.000000. loss_func: 0.094114\n",
      "resetting env. episode 478 reward total was -21.000000. loss_func: 0.109714\n",
      "resetting env. episode 479 reward total was -21.000000. loss_func: 0.135220\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 480 reward total was -20.000000. loss_func: 0.403877\n",
      "resetting env. episode 481 reward total was -21.000000. loss_func: 0.153744\n",
      "resetting env. episode 482 reward total was -21.000000. loss_func: 0.162854\n",
      "resetting env. episode 483 reward total was -21.000000. loss_func: 0.150288\n",
      "resetting env. episode 484 reward total was -20.000000. loss_func: 0.416319\n",
      "resetting env. episode 485 reward total was -20.000000. loss_func: 0.385504\n",
      "resetting env. episode 486 reward total was -21.000000. loss_func: 0.164284\n",
      "resetting env. episode 487 reward total was -21.000000. loss_func: 0.156905\n",
      "resetting env. episode 488 reward total was -20.000000. loss_func: 0.446962\n",
      "resetting env. episode 489 reward total was -21.000000. loss_func: 0.157971\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 490 reward total was -21.000000. loss_func: 0.097266\n",
      "resetting env. episode 491 reward total was -21.000000. loss_func: 0.076298\n",
      "resetting env. episode 492 reward total was -18.000000. loss_func: 0.563846\n",
      "resetting env. episode 493 reward total was -20.000000. loss_func: 0.541930\n",
      "resetting env. episode 494 reward total was -20.000000. loss_func: 0.459087\n",
      "resetting env. episode 495 reward total was -21.000000. loss_func: 0.181121\n",
      "resetting env. episode 496 reward total was -18.000000. loss_func: 0.454799\n",
      "resetting env. episode 497 reward total was -19.000000. loss_func: 0.398985\n",
      "resetting env. episode 498 reward total was -21.000000. loss_func: 0.158974\n",
      "resetting env. episode 499 reward total was -21.000000. loss_func: 0.128662\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 500 reward total was -20.000000. loss_func: 0.404885\n",
      "resetting env. episode 501 reward total was -21.000000. loss_func: 0.108827\n",
      "resetting env. episode 502 reward total was -21.000000. loss_func: 0.132787\n",
      "resetting env. episode 503 reward total was -20.000000. loss_func: 0.577884\n",
      "resetting env. episode 504 reward total was -21.000000. loss_func: 0.107073\n",
      "resetting env. episode 505 reward total was -21.000000. loss_func: 0.097342\n",
      "resetting env. episode 506 reward total was -21.000000. loss_func: 0.143456\n",
      "resetting env. episode 507 reward total was -20.000000. loss_func: 0.378556\n",
      "resetting env. episode 508 reward total was -21.000000. loss_func: 0.155147\n",
      "resetting env. episode 509 reward total was -21.000000. loss_func: 0.129246\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 510 reward total was -21.000000. loss_func: 0.120214\n",
      "resetting env. episode 511 reward total was -21.000000. loss_func: 0.171490\n",
      "resetting env. episode 512 reward total was -21.000000. loss_func: 0.095050\n",
      "resetting env. episode 513 reward total was -21.000000. loss_func: 0.124246\n",
      "resetting env. episode 514 reward total was -21.000000. loss_func: 0.075957\n",
      "resetting env. episode 515 reward total was -21.000000. loss_func: 0.135423\n",
      "resetting env. episode 516 reward total was -21.000000. loss_func: 0.134488\n",
      "resetting env. episode 517 reward total was -18.000000. loss_func: 0.540089\n",
      "resetting env. episode 518 reward total was -21.000000. loss_func: 0.165013\n",
      "resetting env. episode 519 reward total was -21.000000. loss_func: 0.152832\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 520 reward total was -19.000000. loss_func: 0.420201\n",
      "resetting env. episode 521 reward total was -17.000000. loss_func: 0.516861\n",
      "resetting env. episode 522 reward total was -20.000000. loss_func: 0.384597\n",
      "resetting env. episode 523 reward total was -20.000000. loss_func: 0.428908\n",
      "resetting env. episode 524 reward total was -21.000000. loss_func: 0.177089\n",
      "resetting env. episode 525 reward total was -21.000000. loss_func: 0.075350\n",
      "resetting env. episode 526 reward total was -20.000000. loss_func: 0.435679\n",
      "resetting env. episode 527 reward total was -20.000000. loss_func: 0.413530\n",
      "resetting env. episode 528 reward total was -21.000000. loss_func: 0.157764\n",
      "resetting env. episode 529 reward total was -21.000000. loss_func: 0.125037\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 530 reward total was -21.000000. loss_func: 0.093372\n",
      "resetting env. episode 531 reward total was -20.000000. loss_func: 0.570491\n",
      "resetting env. episode 532 reward total was -21.000000. loss_func: 0.107924\n",
      "resetting env. episode 533 reward total was -20.000000. loss_func: 0.480126\n",
      "resetting env. episode 534 reward total was -18.000000. loss_func: 0.511231\n",
      "resetting env. episode 535 reward total was -21.000000. loss_func: 0.109547\n",
      "resetting env. episode 536 reward total was -20.000000. loss_func: 0.408861\n",
      "resetting env. episode 537 reward total was -20.000000. loss_func: 0.358925\n",
      "resetting env. episode 538 reward total was -21.000000. loss_func: 0.228988\n",
      "resetting env. episode 539 reward total was -20.000000. loss_func: 0.465938\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 540 reward total was -21.000000. loss_func: 0.091206\n",
      "resetting env. episode 541 reward total was -21.000000. loss_func: 0.148617\n",
      "resetting env. episode 542 reward total was -20.000000. loss_func: 0.401703\n",
      "resetting env. episode 543 reward total was -21.000000. loss_func: 0.128270\n",
      "resetting env. episode 544 reward total was -21.000000. loss_func: 0.114548\n",
      "resetting env. episode 545 reward total was -21.000000. loss_func: 0.129714\n",
      "resetting env. episode 546 reward total was -21.000000. loss_func: 0.098240\n",
      "resetting env. episode 547 reward total was -21.000000. loss_func: 0.092575\n",
      "resetting env. episode 548 reward total was -19.000000. loss_func: 0.420900\n",
      "resetting env. episode 549 reward total was -20.000000. loss_func: 0.523632\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 550 reward total was -20.000000. loss_func: 0.410875\n",
      "resetting env. episode 551 reward total was -20.000000. loss_func: 0.349394\n",
      "resetting env. episode 552 reward total was -18.000000. loss_func: 0.382028\n",
      "resetting env. episode 553 reward total was -18.000000. loss_func: 0.383139\n",
      "resetting env. episode 554 reward total was -19.000000. loss_func: 0.507904\n",
      "resetting env. episode 555 reward total was -21.000000. loss_func: 0.156787\n",
      "resetting env. episode 556 reward total was -20.000000. loss_func: 0.424113\n",
      "resetting env. episode 557 reward total was -21.000000. loss_func: 0.089294\n",
      "resetting env. episode 558 reward total was -20.000000. loss_func: 0.463502\n",
      "resetting env. episode 559 reward total was -21.000000. loss_func: 0.180584\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 560 reward total was -21.000000. loss_func: 0.080644\n",
      "resetting env. episode 561 reward total was -21.000000. loss_func: 0.095859\n",
      "resetting env. episode 562 reward total was -21.000000. loss_func: 0.092360\n",
      "resetting env. episode 563 reward total was -21.000000. loss_func: 0.110707\n",
      "resetting env. episode 564 reward total was -20.000000. loss_func: 0.501740\n",
      "resetting env. episode 565 reward total was -21.000000. loss_func: 0.076798\n",
      "resetting env. episode 566 reward total was -18.000000. loss_func: 0.505574\n",
      "resetting env. episode 567 reward total was -21.000000. loss_func: 0.122494\n",
      "resetting env. episode 568 reward total was -20.000000. loss_func: 0.425081\n",
      "resetting env. episode 569 reward total was -19.000000. loss_func: 0.394241\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 570 reward total was -21.000000. loss_func: 0.114561\n",
      "resetting env. episode 571 reward total was -20.000000. loss_func: 0.390304\n",
      "resetting env. episode 572 reward total was -19.000000. loss_func: 0.390106\n",
      "resetting env. episode 573 reward total was -18.000000. loss_func: 0.397659\n",
      "resetting env. episode 574 reward total was -21.000000. loss_func: 0.171902\n",
      "resetting env. episode 575 reward total was -19.000000. loss_func: 0.572145\n",
      "resetting env. episode 576 reward total was -21.000000. loss_func: 0.142631\n",
      "resetting env. episode 577 reward total was -20.000000. loss_func: 0.543615\n",
      "resetting env. episode 578 reward total was -21.000000. loss_func: 0.121013\n",
      "resetting env. episode 579 reward total was -21.000000. loss_func: 0.187134\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 580 reward total was -21.000000. loss_func: 0.064100\n",
      "resetting env. episode 581 reward total was -21.000000. loss_func: 0.091539\n",
      "resetting env. episode 582 reward total was -20.000000. loss_func: 0.504594\n",
      "resetting env. episode 583 reward total was -21.000000. loss_func: 0.083650\n",
      "resetting env. episode 584 reward total was -21.000000. loss_func: 0.124287\n",
      "resetting env. episode 585 reward total was -18.000000. loss_func: 0.493466\n",
      "resetting env. episode 586 reward total was -20.000000. loss_func: 0.428212\n",
      "resetting env. episode 587 reward total was -20.000000. loss_func: 0.649448\n",
      "resetting env. episode 588 reward total was -20.000000. loss_func: 0.450668\n",
      "resetting env. episode 589 reward total was -20.000000. loss_func: 0.366852\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 590 reward total was -21.000000. loss_func: 0.188759\n",
      "resetting env. episode 591 reward total was -21.000000. loss_func: 0.109983\n",
      "resetting env. episode 592 reward total was -20.000000. loss_func: 0.453116\n",
      "resetting env. episode 593 reward total was -21.000000. loss_func: 0.141907\n",
      "resetting env. episode 594 reward total was -21.000000. loss_func: 0.128131\n",
      "resetting env. episode 595 reward total was -21.000000. loss_func: 0.126724\n",
      "resetting env. episode 596 reward total was -20.000000. loss_func: 0.599915\n",
      "resetting env. episode 597 reward total was -21.000000. loss_func: 0.135289\n",
      "resetting env. episode 598 reward total was -21.000000. loss_func: 0.086689\n",
      "resetting env. episode 599 reward total was -21.000000. loss_func: 0.153125\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 600 reward total was -20.000000. loss_func: 0.433870\n",
      "resetting env. episode 601 reward total was -20.000000. loss_func: 0.460819\n",
      "resetting env. episode 602 reward total was -20.000000. loss_func: 0.414282\n",
      "resetting env. episode 603 reward total was -20.000000. loss_func: 0.382730\n",
      "resetting env. episode 604 reward total was -21.000000. loss_func: 0.214611\n",
      "resetting env. episode 605 reward total was -19.000000. loss_func: 0.402048\n",
      "resetting env. episode 606 reward total was -20.000000. loss_func: 0.370195\n",
      "resetting env. episode 607 reward total was -18.000000. loss_func: 0.578738\n",
      "resetting env. episode 608 reward total was -21.000000. loss_func: 0.150079\n",
      "resetting env. episode 609 reward total was -21.000000. loss_func: 0.095276\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 610 reward total was -20.000000. loss_func: 0.455058\n",
      "resetting env. episode 611 reward total was -20.000000. loss_func: 0.387634\n",
      "resetting env. episode 612 reward total was -21.000000. loss_func: 0.181690\n",
      "resetting env. episode 613 reward total was -21.000000. loss_func: 0.179825\n",
      "resetting env. episode 614 reward total was -20.000000. loss_func: 0.525280\n",
      "resetting env. episode 615 reward total was -20.000000. loss_func: 0.418498\n",
      "resetting env. episode 616 reward total was -21.000000. loss_func: 0.115861\n",
      "resetting env. episode 617 reward total was -20.000000. loss_func: 0.401957\n",
      "resetting env. episode 618 reward total was -21.000000. loss_func: 0.135765\n",
      "resetting env. episode 619 reward total was -21.000000. loss_func: 0.145518\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 620 reward total was -20.000000. loss_func: 0.352526\n",
      "resetting env. episode 621 reward total was -20.000000. loss_func: 0.398443\n",
      "resetting env. episode 622 reward total was -21.000000. loss_func: 0.183505\n",
      "resetting env. episode 623 reward total was -21.000000. loss_func: 0.104762\n",
      "resetting env. episode 624 reward total was -21.000000. loss_func: 0.142890\n",
      "resetting env. episode 625 reward total was -20.000000. loss_func: 0.452561\n",
      "resetting env. episode 626 reward total was -19.000000. loss_func: 0.483281\n",
      "resetting env. episode 627 reward total was -21.000000. loss_func: 0.078427\n",
      "resetting env. episode 628 reward total was -20.000000. loss_func: 0.398115\n",
      "resetting env. episode 629 reward total was -20.000000. loss_func: 0.358711\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 630 reward total was -21.000000. loss_func: 0.110462\n",
      "resetting env. episode 631 reward total was -21.000000. loss_func: 0.195746\n",
      "resetting env. episode 632 reward total was -20.000000. loss_func: 0.427185\n",
      "resetting env. episode 633 reward total was -21.000000. loss_func: 0.109747\n",
      "resetting env. episode 634 reward total was -21.000000. loss_func: 0.118955\n",
      "resetting env. episode 635 reward total was -20.000000. loss_func: 0.355980\n",
      "resetting env. episode 636 reward total was -21.000000. loss_func: 0.115480\n",
      "resetting env. episode 637 reward total was -20.000000. loss_func: 0.370606\n",
      "resetting env. episode 638 reward total was -19.000000. loss_func: 0.427451\n",
      "resetting env. episode 639 reward total was -21.000000. loss_func: 0.151711\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 640 reward total was -21.000000. loss_func: 0.148992\n",
      "resetting env. episode 641 reward total was -21.000000. loss_func: 0.124665\n",
      "resetting env. episode 642 reward total was -21.000000. loss_func: 0.147045\n",
      "resetting env. episode 643 reward total was -21.000000. loss_func: 0.145580\n",
      "resetting env. episode 644 reward total was -21.000000. loss_func: 0.101075\n",
      "resetting env. episode 645 reward total was -21.000000. loss_func: 0.142964\n",
      "resetting env. episode 646 reward total was -20.000000. loss_func: 0.436179\n",
      "resetting env. episode 647 reward total was -20.000000. loss_func: 0.383566\n",
      "resetting env. episode 648 reward total was -21.000000. loss_func: 0.119556\n",
      "resetting env. episode 649 reward total was -21.000000. loss_func: 0.121848\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 650 reward total was -20.000000. loss_func: 0.406428\n",
      "resetting env. episode 651 reward total was -20.000000. loss_func: 0.334269\n",
      "resetting env. episode 652 reward total was -19.000000. loss_func: 0.358595\n",
      "resetting env. episode 653 reward total was -21.000000. loss_func: 0.231209\n",
      "resetting env. episode 654 reward total was -21.000000. loss_func: 0.179253\n",
      "resetting env. episode 655 reward total was -21.000000. loss_func: 0.132203\n",
      "resetting env. episode 656 reward total was -20.000000. loss_func: 0.361710\n",
      "resetting env. episode 657 reward total was -21.000000. loss_func: 0.206246\n",
      "resetting env. episode 658 reward total was -21.000000. loss_func: 0.149535\n",
      "resetting env. episode 659 reward total was -21.000000. loss_func: 0.110439\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 660 reward total was -20.000000. loss_func: 0.396535\n",
      "resetting env. episode 661 reward total was -21.000000. loss_func: 0.107912\n",
      "resetting env. episode 662 reward total was -21.000000. loss_func: 0.057175\n",
      "resetting env. episode 663 reward total was -21.000000. loss_func: 0.068503\n",
      "resetting env. episode 664 reward total was -21.000000. loss_func: 0.066685\n",
      "resetting env. episode 665 reward total was -21.000000. loss_func: 0.120628\n",
      "resetting env. episode 666 reward total was -21.000000. loss_func: 0.074696\n",
      "resetting env. episode 667 reward total was -20.000000. loss_func: 0.479980\n",
      "resetting env. episode 668 reward total was -21.000000. loss_func: 0.166603\n",
      "resetting env. episode 669 reward total was -20.000000. loss_func: 0.399347\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 670 reward total was -21.000000. loss_func: 0.113972\n",
      "resetting env. episode 671 reward total was -20.000000. loss_func: 0.475459\n",
      "resetting env. episode 672 reward total was -20.000000. loss_func: 0.383249\n",
      "resetting env. episode 673 reward total was -21.000000. loss_func: 0.117275\n",
      "resetting env. episode 674 reward total was -21.000000. loss_func: 0.121193\n",
      "resetting env. episode 675 reward total was -21.000000. loss_func: 0.124532\n",
      "resetting env. episode 676 reward total was -21.000000. loss_func: 0.169506\n",
      "resetting env. episode 677 reward total was -20.000000. loss_func: 0.366281\n",
      "resetting env. episode 678 reward total was -19.000000. loss_func: 0.389771\n",
      "resetting env. episode 679 reward total was -19.000000. loss_func: 0.399843\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 680 reward total was -21.000000. loss_func: 0.256773\n",
      "resetting env. episode 681 reward total was -19.000000. loss_func: 0.466090\n",
      "resetting env. episode 682 reward total was -19.000000. loss_func: 0.353493\n",
      "resetting env. episode 683 reward total was -20.000000. loss_func: 0.351158\n",
      "resetting env. episode 684 reward total was -21.000000. loss_func: 0.193592\n",
      "resetting env. episode 685 reward total was -20.000000. loss_func: 0.375574\n",
      "resetting env. episode 686 reward total was -21.000000. loss_func: 0.189125\n",
      "resetting env. episode 687 reward total was -21.000000. loss_func: 0.157020\n",
      "resetting env. episode 688 reward total was -21.000000. loss_func: 0.094877\n",
      "resetting env. episode 689 reward total was -21.000000. loss_func: 0.136821\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 690 reward total was -19.000000. loss_func: 0.423320\n",
      "resetting env. episode 691 reward total was -20.000000. loss_func: 0.359400\n",
      "resetting env. episode 692 reward total was -19.000000. loss_func: 0.479192\n",
      "resetting env. episode 693 reward total was -21.000000. loss_func: 0.123530\n",
      "resetting env. episode 694 reward total was -21.000000. loss_func: 0.132065\n",
      "resetting env. episode 695 reward total was -21.000000. loss_func: 0.095928\n",
      "resetting env. episode 696 reward total was -21.000000. loss_func: 0.112338\n",
      "resetting env. episode 697 reward total was -20.000000. loss_func: 0.365767\n",
      "resetting env. episode 698 reward total was -18.000000. loss_func: 0.505294\n",
      "resetting env. episode 699 reward total was -19.000000. loss_func: 0.408275\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 700 reward total was -21.000000. loss_func: 0.115372\n",
      "resetting env. episode 701 reward total was -19.000000. loss_func: 0.401402\n",
      "resetting env. episode 702 reward total was -18.000000. loss_func: 0.431688\n",
      "resetting env. episode 703 reward total was -20.000000. loss_func: 0.419185\n",
      "resetting env. episode 704 reward total was -21.000000. loss_func: 0.154287\n",
      "resetting env. episode 705 reward total was -18.000000. loss_func: 0.501613\n",
      "resetting env. episode 706 reward total was -21.000000. loss_func: 0.102646\n",
      "resetting env. episode 707 reward total was -21.000000. loss_func: 0.090422\n",
      "resetting env. episode 708 reward total was -21.000000. loss_func: 0.092410\n",
      "resetting env. episode 709 reward total was -21.000000. loss_func: 0.140461\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 710 reward total was -20.000000. loss_func: 0.417779\n",
      "resetting env. episode 711 reward total was -20.000000. loss_func: 0.360253\n",
      "resetting env. episode 712 reward total was -21.000000. loss_func: 0.125782\n",
      "resetting env. episode 713 reward total was -20.000000. loss_func: 0.358061\n",
      "resetting env. episode 714 reward total was -21.000000. loss_func: 0.108235\n",
      "resetting env. episode 715 reward total was -20.000000. loss_func: 0.369692\n",
      "resetting env. episode 716 reward total was -18.000000. loss_func: 0.523159\n",
      "resetting env. episode 717 reward total was -21.000000. loss_func: 0.094221\n",
      "resetting env. episode 718 reward total was -20.000000. loss_func: 0.375716\n",
      "resetting env. episode 719 reward total was -20.000000. loss_func: 0.376967\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 720 reward total was -21.000000. loss_func: 0.118197\n",
      "resetting env. episode 721 reward total was -21.000000. loss_func: 0.208964\n",
      "resetting env. episode 722 reward total was -18.000000. loss_func: 0.446057\n",
      "resetting env. episode 723 reward total was -21.000000. loss_func: 0.119268\n",
      "resetting env. episode 724 reward total was -21.000000. loss_func: 0.126144\n",
      "resetting env. episode 725 reward total was -20.000000. loss_func: 0.400865\n",
      "resetting env. episode 726 reward total was -20.000000. loss_func: 0.386499\n",
      "resetting env. episode 727 reward total was -21.000000. loss_func: 0.139453\n",
      "resetting env. episode 728 reward total was -21.000000. loss_func: 0.099220\n",
      "resetting env. episode 729 reward total was -21.000000. loss_func: 0.089149\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 730 reward total was -21.000000. loss_func: 0.178936\n",
      "resetting env. episode 731 reward total was -20.000000. loss_func: 0.427064\n",
      "resetting env. episode 732 reward total was -21.000000. loss_func: 0.095110\n",
      "resetting env. episode 733 reward total was -21.000000. loss_func: 0.104900\n",
      "resetting env. episode 734 reward total was -18.000000. loss_func: 0.518314\n",
      "resetting env. episode 735 reward total was -21.000000. loss_func: 0.071652\n",
      "resetting env. episode 736 reward total was -21.000000. loss_func: 0.121601\n",
      "resetting env. episode 737 reward total was -20.000000. loss_func: 0.445704\n",
      "resetting env. episode 738 reward total was -21.000000. loss_func: 0.085428\n",
      "resetting env. episode 739 reward total was -21.000000. loss_func: 0.101431\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 740 reward total was -21.000000. loss_func: 0.100150\n",
      "resetting env. episode 741 reward total was -21.000000. loss_func: 0.102662\n",
      "resetting env. episode 742 reward total was -21.000000. loss_func: 0.132967\n",
      "resetting env. episode 743 reward total was -21.000000. loss_func: 0.124054\n",
      "resetting env. episode 744 reward total was -20.000000. loss_func: 0.415648\n",
      "resetting env. episode 745 reward total was -21.000000. loss_func: 0.074532\n",
      "resetting env. episode 746 reward total was -21.000000. loss_func: 0.113032\n",
      "resetting env. episode 747 reward total was -21.000000. loss_func: 0.148867\n",
      "resetting env. episode 748 reward total was -21.000000. loss_func: 0.112590\n",
      "resetting env. episode 749 reward total was -20.000000. loss_func: 0.371452\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 750 reward total was -21.000000. loss_func: 0.139361\n",
      "resetting env. episode 751 reward total was -21.000000. loss_func: 0.077185\n",
      "resetting env. episode 752 reward total was -21.000000. loss_func: 0.102470\n",
      "resetting env. episode 753 reward total was -21.000000. loss_func: 0.144809\n",
      "resetting env. episode 754 reward total was -21.000000. loss_func: 0.130705\n",
      "resetting env. episode 755 reward total was -21.000000. loss_func: 0.129312\n",
      "resetting env. episode 756 reward total was -20.000000. loss_func: 0.372297\n",
      "resetting env. episode 757 reward total was -19.000000. loss_func: 0.395468\n",
      "resetting env. episode 758 reward total was -20.000000. loss_func: 0.342286\n",
      "resetting env. episode 759 reward total was -21.000000. loss_func: 0.211464\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 760 reward total was -21.000000. loss_func: 0.152046\n",
      "resetting env. episode 761 reward total was -21.000000. loss_func: 0.091686\n",
      "resetting env. episode 762 reward total was -21.000000. loss_func: 0.099889\n",
      "resetting env. episode 763 reward total was -20.000000. loss_func: 0.399886\n",
      "resetting env. episode 764 reward total was -20.000000. loss_func: 0.366286\n",
      "resetting env. episode 765 reward total was -20.000000. loss_func: 0.397943\n",
      "resetting env. episode 766 reward total was -21.000000. loss_func: 0.135463\n",
      "resetting env. episode 767 reward total was -20.000000. loss_func: 0.429582\n",
      "resetting env. episode 768 reward total was -20.000000. loss_func: 0.522602\n",
      "resetting env. episode 769 reward total was -21.000000. loss_func: 0.068207\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 770 reward total was -21.000000. loss_func: 0.095787\n",
      "resetting env. episode 771 reward total was -20.000000. loss_func: 0.400614\n",
      "resetting env. episode 772 reward total was -20.000000. loss_func: 0.425079\n",
      "resetting env. episode 773 reward total was -21.000000. loss_func: 0.117104\n",
      "resetting env. episode 774 reward total was -21.000000. loss_func: 0.155589\n",
      "resetting env. episode 775 reward total was -20.000000. loss_func: 0.355646\n",
      "resetting env. episode 776 reward total was -21.000000. loss_func: 0.152275\n",
      "resetting env. episode 777 reward total was -20.000000. loss_func: 0.459026\n",
      "resetting env. episode 778 reward total was -21.000000. loss_func: 0.157701\n",
      "resetting env. episode 779 reward total was -21.000000. loss_func: 0.140736\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 780 reward total was -21.000000. loss_func: 0.148869\n",
      "resetting env. episode 781 reward total was -21.000000. loss_func: 0.074842\n",
      "resetting env. episode 782 reward total was -20.000000. loss_func: 0.424448\n",
      "resetting env. episode 783 reward total was -19.000000. loss_func: 0.356582\n",
      "resetting env. episode 784 reward total was -20.000000. loss_func: 0.451935\n",
      "resetting env. episode 785 reward total was -21.000000. loss_func: 0.149653\n",
      "resetting env. episode 786 reward total was -21.000000. loss_func: 0.082651\n",
      "resetting env. episode 787 reward total was -20.000000. loss_func: 0.417360\n",
      "resetting env. episode 788 reward total was -21.000000. loss_func: 0.083046\n",
      "resetting env. episode 789 reward total was -21.000000. loss_func: 0.116413\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 790 reward total was -21.000000. loss_func: 0.066959\n",
      "resetting env. episode 791 reward total was -20.000000. loss_func: 0.400749\n",
      "resetting env. episode 792 reward total was -21.000000. loss_func: 0.109253\n",
      "resetting env. episode 793 reward total was -20.000000. loss_func: 0.340912\n",
      "resetting env. episode 794 reward total was -20.000000. loss_func: 0.386113\n",
      "resetting env. episode 795 reward total was -20.000000. loss_func: 0.353571\n",
      "resetting env. episode 796 reward total was -20.000000. loss_func: 0.295319\n",
      "resetting env. episode 797 reward total was -21.000000. loss_func: 0.175604\n",
      "resetting env. episode 798 reward total was -21.000000. loss_func: 0.164478\n",
      "resetting env. episode 799 reward total was -21.000000. loss_func: 0.120239\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 800 reward total was -20.000000. loss_func: 0.373144\n",
      "resetting env. episode 801 reward total was -19.000000. loss_func: 0.352341\n",
      "resetting env. episode 802 reward total was -20.000000. loss_func: 0.346388\n",
      "resetting env. episode 803 reward total was -21.000000. loss_func: 0.099817\n",
      "resetting env. episode 804 reward total was -21.000000. loss_func: 0.070353\n",
      "resetting env. episode 805 reward total was -21.000000. loss_func: 0.097511\n",
      "resetting env. episode 806 reward total was -21.000000. loss_func: 0.058399\n",
      "resetting env. episode 807 reward total was -21.000000. loss_func: 0.068905\n",
      "resetting env. episode 808 reward total was -21.000000. loss_func: 0.073077\n",
      "resetting env. episode 809 reward total was -20.000000. loss_func: 0.389877\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 810 reward total was -21.000000. loss_func: 0.149437\n",
      "resetting env. episode 811 reward total was -21.000000. loss_func: 0.120432\n",
      "resetting env. episode 812 reward total was -21.000000. loss_func: 0.136020\n",
      "resetting env. episode 813 reward total was -18.000000. loss_func: 0.493466\n",
      "resetting env. episode 814 reward total was -20.000000. loss_func: 0.377806\n",
      "resetting env. episode 815 reward total was -21.000000. loss_func: 0.085462\n",
      "resetting env. episode 816 reward total was -21.000000. loss_func: 0.062095\n",
      "resetting env. episode 817 reward total was -21.000000. loss_func: 0.136898\n",
      "resetting env. episode 818 reward total was -20.000000. loss_func: 0.506237\n",
      "resetting env. episode 819 reward total was -21.000000. loss_func: 0.102144\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 820 reward total was -21.000000. loss_func: 0.063730\n",
      "resetting env. episode 821 reward total was -17.000000. loss_func: 0.422652\n",
      "resetting env. episode 822 reward total was -21.000000. loss_func: 0.101521\n",
      "resetting env. episode 823 reward total was -21.000000. loss_func: 0.081717\n",
      "resetting env. episode 824 reward total was -19.000000. loss_func: 0.475479\n",
      "resetting env. episode 825 reward total was -20.000000. loss_func: 0.373863\n",
      "resetting env. episode 826 reward total was -21.000000. loss_func: 0.160588\n",
      "resetting env. episode 827 reward total was -20.000000. loss_func: 0.424584\n",
      "resetting env. episode 828 reward total was -21.000000. loss_func: 0.072128\n",
      "resetting env. episode 829 reward total was -21.000000. loss_func: 0.094270\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 830 reward total was -21.000000. loss_func: 0.105119\n",
      "resetting env. episode 831 reward total was -19.000000. loss_func: 0.498173\n",
      "resetting env. episode 832 reward total was -21.000000. loss_func: 0.077898\n",
      "resetting env. episode 833 reward total was -21.000000. loss_func: 0.089897\n",
      "resetting env. episode 834 reward total was -21.000000. loss_func: 0.118778\n",
      "resetting env. episode 835 reward total was -20.000000. loss_func: 0.397467\n",
      "resetting env. episode 836 reward total was -20.000000. loss_func: 0.371506\n",
      "resetting env. episode 837 reward total was -20.000000. loss_func: 0.369759\n",
      "resetting env. episode 838 reward total was -21.000000. loss_func: 0.151662\n",
      "resetting env. episode 839 reward total was -21.000000. loss_func: 0.140119\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 840 reward total was -20.000000. loss_func: 0.393814\n",
      "resetting env. episode 841 reward total was -20.000000. loss_func: 0.361336\n",
      "resetting env. episode 842 reward total was -20.000000. loss_func: 0.341110\n",
      "resetting env. episode 843 reward total was -21.000000. loss_func: 0.141193\n",
      "resetting env. episode 844 reward total was -21.000000. loss_func: 0.138710\n",
      "resetting env. episode 845 reward total was -21.000000. loss_func: 0.103647\n",
      "resetting env. episode 846 reward total was -20.000000. loss_func: 0.359499\n",
      "resetting env. episode 847 reward total was -21.000000. loss_func: 0.149754\n",
      "resetting env. episode 848 reward total was -20.000000. loss_func: 0.398268\n",
      "resetting env. episode 849 reward total was -21.000000. loss_func: 0.070686\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 850 reward total was -21.000000. loss_func: 0.147435\n",
      "resetting env. episode 851 reward total was -21.000000. loss_func: 0.101540\n",
      "resetting env. episode 852 reward total was -21.000000. loss_func: 0.082735\n",
      "resetting env. episode 853 reward total was -20.000000. loss_func: 0.453415\n",
      "resetting env. episode 854 reward total was -21.000000. loss_func: 0.060545\n",
      "resetting env. episode 855 reward total was -19.000000. loss_func: 0.445983\n",
      "resetting env. episode 856 reward total was -20.000000. loss_func: 0.389230\n",
      "resetting env. episode 857 reward total was -21.000000. loss_func: 0.149205\n",
      "resetting env. episode 858 reward total was -21.000000. loss_func: 0.058388\n",
      "resetting env. episode 859 reward total was -19.000000. loss_func: 0.359552\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 860 reward total was -21.000000. loss_func: 0.122264\n",
      "resetting env. episode 861 reward total was -20.000000. loss_func: 0.434860\n",
      "resetting env. episode 862 reward total was -21.000000. loss_func: 0.132748\n",
      "resetting env. episode 863 reward total was -20.000000. loss_func: 0.408635\n",
      "resetting env. episode 864 reward total was -21.000000. loss_func: 0.079157\n",
      "resetting env. episode 865 reward total was -21.000000. loss_func: 0.072622\n",
      "resetting env. episode 866 reward total was -21.000000. loss_func: 0.141845\n",
      "resetting env. episode 867 reward total was -21.000000. loss_func: 0.157140\n",
      "resetting env. episode 868 reward total was -21.000000. loss_func: 0.131790\n",
      "resetting env. episode 869 reward total was -21.000000. loss_func: 0.115793\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 870 reward total was -21.000000. loss_func: 0.107828\n",
      "resetting env. episode 871 reward total was -21.000000. loss_func: 0.144300\n",
      "resetting env. episode 872 reward total was -21.000000. loss_func: 0.111145\n",
      "resetting env. episode 873 reward total was -21.000000. loss_func: 0.101676\n",
      "resetting env. episode 874 reward total was -21.000000. loss_func: 0.130421\n",
      "resetting env. episode 875 reward total was -20.000000. loss_func: 0.423743\n",
      "resetting env. episode 876 reward total was -21.000000. loss_func: 0.063273\n",
      "resetting env. episode 877 reward total was -21.000000. loss_func: 0.134491\n",
      "resetting env. episode 878 reward total was -21.000000. loss_func: 0.123984\n",
      "resetting env. episode 879 reward total was -21.000000. loss_func: 0.081964\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 880 reward total was -21.000000. loss_func: 0.100288\n",
      "resetting env. episode 881 reward total was -21.000000. loss_func: 0.100298\n",
      "resetting env. episode 882 reward total was -21.000000. loss_func: 0.123236\n",
      "resetting env. episode 883 reward total was -21.000000. loss_func: 0.115250\n",
      "resetting env. episode 884 reward total was -21.000000. loss_func: 0.061701\n",
      "resetting env. episode 885 reward total was -21.000000. loss_func: 0.129814\n",
      "resetting env. episode 886 reward total was -21.000000. loss_func: 0.106665\n",
      "resetting env. episode 887 reward total was -21.000000. loss_func: 0.088222\n",
      "resetting env. episode 888 reward total was -20.000000. loss_func: 0.386648\n",
      "resetting env. episode 889 reward total was -21.000000. loss_func: 0.198975\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 890 reward total was -21.000000. loss_func: 0.076834\n",
      "resetting env. episode 891 reward total was -20.000000. loss_func: 0.495419\n",
      "resetting env. episode 892 reward total was -20.000000. loss_func: 0.375772\n",
      "resetting env. episode 893 reward total was -21.000000. loss_func: 0.169439\n",
      "resetting env. episode 894 reward total was -21.000000. loss_func: 0.126202\n",
      "resetting env. episode 895 reward total was -21.000000. loss_func: 0.140456\n",
      "resetting env. episode 896 reward total was -21.000000. loss_func: 0.093395\n",
      "resetting env. episode 897 reward total was -21.000000. loss_func: 0.089920\n",
      "resetting env. episode 898 reward total was -21.000000. loss_func: 0.071585\n",
      "resetting env. episode 899 reward total was -20.000000. loss_func: 0.433183\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 900 reward total was -20.000000. loss_func: 0.479338\n",
      "resetting env. episode 901 reward total was -21.000000. loss_func: 0.079229\n",
      "resetting env. episode 902 reward total was -20.000000. loss_func: 0.373695\n",
      "resetting env. episode 903 reward total was -21.000000. loss_func: 0.124155\n",
      "resetting env. episode 904 reward total was -21.000000. loss_func: 0.139894\n",
      "resetting env. episode 905 reward total was -21.000000. loss_func: 0.071687\n",
      "resetting env. episode 906 reward total was -21.000000. loss_func: 0.173115\n",
      "resetting env. episode 907 reward total was -21.000000. loss_func: 0.109688\n",
      "resetting env. episode 908 reward total was -19.000000. loss_func: 0.436352\n",
      "resetting env. episode 909 reward total was -21.000000. loss_func: 0.152828\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 910 reward total was -21.000000. loss_func: 0.117144\n",
      "resetting env. episode 911 reward total was -21.000000. loss_func: 0.082046\n",
      "resetting env. episode 912 reward total was -20.000000. loss_func: 0.414307\n",
      "resetting env. episode 913 reward total was -21.000000. loss_func: 0.067312\n",
      "resetting env. episode 914 reward total was -20.000000. loss_func: 0.380600\n",
      "resetting env. episode 915 reward total was -21.000000. loss_func: 0.184554\n",
      "resetting env. episode 916 reward total was -21.000000. loss_func: 0.142582\n",
      "resetting env. episode 917 reward total was -21.000000. loss_func: 0.087946\n",
      "resetting env. episode 918 reward total was -20.000000. loss_func: 0.383173\n",
      "resetting env. episode 919 reward total was -19.000000. loss_func: 0.346863\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 920 reward total was -21.000000. loss_func: 0.139791\n",
      "resetting env. episode 921 reward total was -20.000000. loss_func: 0.368545\n",
      "resetting env. episode 922 reward total was -21.000000. loss_func: 0.110704\n",
      "resetting env. episode 923 reward total was -20.000000. loss_func: 0.395805\n",
      "resetting env. episode 924 reward total was -20.000000. loss_func: 0.347008\n",
      "resetting env. episode 925 reward total was -21.000000. loss_func: 0.100294\n",
      "resetting env. episode 926 reward total was -19.000000. loss_func: 0.381302\n",
      "resetting env. episode 927 reward total was -21.000000. loss_func: 0.104669\n",
      "resetting env. episode 928 reward total was -20.000000. loss_func: 0.367251\n",
      "resetting env. episode 929 reward total was -20.000000. loss_func: 0.448975\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 930 reward total was -20.000000. loss_func: 0.390004\n",
      "resetting env. episode 931 reward total was -20.000000. loss_func: 0.315704\n",
      "resetting env. episode 932 reward total was -21.000000. loss_func: 0.162141\n",
      "resetting env. episode 933 reward total was -18.000000. loss_func: 0.370948\n",
      "resetting env. episode 934 reward total was -17.000000. loss_func: 0.411179\n",
      "resetting env. episode 935 reward total was -20.000000. loss_func: 0.377023\n",
      "resetting env. episode 936 reward total was -19.000000. loss_func: 0.331672\n",
      "resetting env. episode 937 reward total was -21.000000. loss_func: 0.173961\n",
      "resetting env. episode 938 reward total was -20.000000. loss_func: 0.402446\n",
      "resetting env. episode 939 reward total was -19.000000. loss_func: 0.464040\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 940 reward total was -20.000000. loss_func: 0.381754\n",
      "resetting env. episode 941 reward total was -21.000000. loss_func: 0.238655\n",
      "resetting env. episode 942 reward total was -21.000000. loss_func: 0.171127\n",
      "resetting env. episode 943 reward total was -20.000000. loss_func: 0.354063\n",
      "resetting env. episode 944 reward total was -21.000000. loss_func: 0.126518\n",
      "resetting env. episode 945 reward total was -21.000000. loss_func: 0.123158\n",
      "resetting env. episode 946 reward total was -21.000000. loss_func: 0.076853\n",
      "resetting env. episode 947 reward total was -20.000000. loss_func: 0.420726\n",
      "resetting env. episode 948 reward total was -21.000000. loss_func: 0.102546\n",
      "resetting env. episode 949 reward total was -21.000000. loss_func: 0.085991\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 950 reward total was -20.000000. loss_func: 0.359978\n",
      "resetting env. episode 951 reward total was -21.000000. loss_func: 0.103233\n",
      "resetting env. episode 952 reward total was -21.000000. loss_func: 0.116814\n",
      "resetting env. episode 953 reward total was -20.000000. loss_func: 0.400979\n",
      "resetting env. episode 954 reward total was -21.000000. loss_func: 0.081922\n",
      "resetting env. episode 955 reward total was -19.000000. loss_func: 0.391205\n",
      "resetting env. episode 956 reward total was -20.000000. loss_func: 0.570252\n",
      "resetting env. episode 957 reward total was -21.000000. loss_func: 0.104589\n",
      "resetting env. episode 958 reward total was -21.000000. loss_func: 0.126991\n",
      "resetting env. episode 959 reward total was -21.000000. loss_func: 0.104797\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 960 reward total was -21.000000. loss_func: 0.070728\n",
      "resetting env. episode 961 reward total was -21.000000. loss_func: 0.103285\n",
      "resetting env. episode 962 reward total was -21.000000. loss_func: 0.052087\n",
      "resetting env. episode 963 reward total was -20.000000. loss_func: 0.343521\n",
      "resetting env. episode 964 reward total was -21.000000. loss_func: 0.136524\n",
      "resetting env. episode 965 reward total was -21.000000. loss_func: 0.095675\n",
      "resetting env. episode 966 reward total was -21.000000. loss_func: 0.092646\n",
      "resetting env. episode 967 reward total was -21.000000. loss_func: 0.123171\n",
      "resetting env. episode 968 reward total was -21.000000. loss_func: 0.097056\n",
      "resetting env. episode 969 reward total was -21.000000. loss_func: 0.087683\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 970 reward total was -21.000000. loss_func: 0.170371\n",
      "resetting env. episode 971 reward total was -20.000000. loss_func: 0.413343\n",
      "resetting env. episode 972 reward total was -21.000000. loss_func: 0.067884\n",
      "resetting env. episode 973 reward total was -20.000000. loss_func: 0.345083\n",
      "resetting env. episode 974 reward total was -21.000000. loss_func: 0.152589\n",
      "resetting env. episode 975 reward total was -21.000000. loss_func: 0.120325\n",
      "resetting env. episode 976 reward total was -20.000000. loss_func: 0.385496\n",
      "resetting env. episode 977 reward total was -21.000000. loss_func: 0.151828\n",
      "resetting env. episode 978 reward total was -21.000000. loss_func: 0.077462\n",
      "resetting env. episode 979 reward total was -19.000000. loss_func: 0.365782\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 980 reward total was -20.000000. loss_func: 0.336447\n",
      "resetting env. episode 981 reward total was -21.000000. loss_func: 0.134909\n",
      "resetting env. episode 982 reward total was -21.000000. loss_func: 0.098475\n",
      "resetting env. episode 983 reward total was -20.000000. loss_func: 0.411179\n",
      "resetting env. episode 984 reward total was -21.000000. loss_func: 0.128692\n",
      "resetting env. episode 985 reward total was -21.000000. loss_func: 0.063222\n",
      "resetting env. episode 986 reward total was -21.000000. loss_func: 0.096886\n",
      "resetting env. episode 987 reward total was -21.000000. loss_func: 0.103247\n",
      "resetting env. episode 988 reward total was -21.000000. loss_func: 0.112581\n",
      "resetting env. episode 989 reward total was -20.000000. loss_func: 0.374870\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 990 reward total was -21.000000. loss_func: 0.082445\n",
      "resetting env. episode 991 reward total was -21.000000. loss_func: 0.112829\n",
      "resetting env. episode 992 reward total was -20.000000. loss_func: 0.343475\n",
      "resetting env. episode 993 reward total was -20.000000. loss_func: 0.509461\n",
      "resetting env. episode 994 reward total was -21.000000. loss_func: 0.155830\n",
      "resetting env. episode 995 reward total was -20.000000. loss_func: 0.339811\n",
      "resetting env. episode 996 reward total was -21.000000. loss_func: 0.093922\n",
      "resetting env. episode 997 reward total was -21.000000. loss_func: 0.115904\n",
      "resetting env. episode 998 reward total was -21.000000. loss_func: 0.136456\n",
      "resetting env. episode 999 reward total was -19.000000. loss_func: 0.427170\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1000 reward total was -15.000000. loss_func: 0.497146\n",
      "resetting env. episode 1001 reward total was -21.000000. loss_func: 0.122277\n",
      "resetting env. episode 1002 reward total was -21.000000. loss_func: 0.060235\n",
      "resetting env. episode 1003 reward total was -21.000000. loss_func: 0.089264\n",
      "resetting env. episode 1004 reward total was -21.000000. loss_func: 0.072260\n",
      "resetting env. episode 1005 reward total was -20.000000. loss_func: 0.423782\n",
      "resetting env. episode 1006 reward total was -21.000000. loss_func: 0.050348\n",
      "resetting env. episode 1007 reward total was -19.000000. loss_func: 0.496399\n",
      "resetting env. episode 1008 reward total was -21.000000. loss_func: 0.114763\n",
      "resetting env. episode 1009 reward total was -21.000000. loss_func: 0.134651\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1010 reward total was -21.000000. loss_func: 0.108410\n",
      "resetting env. episode 1011 reward total was -21.000000. loss_func: 0.115640\n",
      "resetting env. episode 1012 reward total was -21.000000. loss_func: 0.111093\n",
      "resetting env. episode 1013 reward total was -20.000000. loss_func: 0.503673\n",
      "resetting env. episode 1014 reward total was -20.000000. loss_func: 0.350119\n",
      "resetting env. episode 1015 reward total was -21.000000. loss_func: 0.142927\n",
      "resetting env. episode 1016 reward total was -20.000000. loss_func: 0.395132\n",
      "resetting env. episode 1017 reward total was -21.000000. loss_func: 0.074986\n",
      "resetting env. episode 1018 reward total was -20.000000. loss_func: 0.355630\n",
      "resetting env. episode 1019 reward total was -21.000000. loss_func: 0.122797\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1020 reward total was -21.000000. loss_func: 0.070652\n",
      "resetting env. episode 1021 reward total was -21.000000. loss_func: 0.105415\n",
      "resetting env. episode 1022 reward total was -20.000000. loss_func: 0.501938\n",
      "resetting env. episode 1023 reward total was -21.000000. loss_func: 0.045084\n",
      "resetting env. episode 1024 reward total was -18.000000. loss_func: 0.455078\n",
      "resetting env. episode 1025 reward total was -21.000000. loss_func: 0.090406\n",
      "resetting env. episode 1026 reward total was -20.000000. loss_func: 0.366394\n",
      "resetting env. episode 1027 reward total was -20.000000. loss_func: 0.371874\n",
      "resetting env. episode 1028 reward total was -19.000000. loss_func: 0.399449\n",
      "resetting env. episode 1029 reward total was -20.000000. loss_func: 0.352003\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1030 reward total was -20.000000. loss_func: 0.348343\n",
      "resetting env. episode 1031 reward total was -21.000000. loss_func: 0.196297\n",
      "resetting env. episode 1032 reward total was -17.000000. loss_func: 0.502487\n",
      "resetting env. episode 1033 reward total was -20.000000. loss_func: 0.324501\n",
      "resetting env. episode 1034 reward total was -21.000000. loss_func: 0.144708\n",
      "resetting env. episode 1035 reward total was -21.000000. loss_func: 0.153745\n",
      "resetting env. episode 1036 reward total was -21.000000. loss_func: 0.071697\n",
      "resetting env. episode 1037 reward total was -21.000000. loss_func: 0.122242\n",
      "resetting env. episode 1038 reward total was -21.000000. loss_func: 0.123565\n",
      "resetting env. episode 1039 reward total was -19.000000. loss_func: 0.409204\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1040 reward total was -21.000000. loss_func: 0.082067\n",
      "resetting env. episode 1041 reward total was -21.000000. loss_func: 0.072209\n",
      "resetting env. episode 1042 reward total was -21.000000. loss_func: 0.111940\n",
      "resetting env. episode 1043 reward total was -20.000000. loss_func: 0.380844\n",
      "resetting env. episode 1044 reward total was -20.000000. loss_func: 0.415883\n",
      "resetting env. episode 1045 reward total was -21.000000. loss_func: 0.110506\n",
      "resetting env. episode 1046 reward total was -21.000000. loss_func: 0.069756\n",
      "resetting env. episode 1047 reward total was -21.000000. loss_func: 0.118113\n",
      "resetting env. episode 1048 reward total was -20.000000. loss_func: 0.433263\n",
      "resetting env. episode 1049 reward total was -20.000000. loss_func: 0.338957\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1050 reward total was -20.000000. loss_func: 0.408955\n",
      "resetting env. episode 1051 reward total was -21.000000. loss_func: 0.145541\n",
      "resetting env. episode 1052 reward total was -19.000000. loss_func: 0.368879\n",
      "resetting env. episode 1053 reward total was -21.000000. loss_func: 0.134591\n",
      "resetting env. episode 1054 reward total was -21.000000. loss_func: 0.117125\n",
      "resetting env. episode 1055 reward total was -21.000000. loss_func: 0.104740\n",
      "resetting env. episode 1056 reward total was -20.000000. loss_func: 0.418091\n",
      "resetting env. episode 1057 reward total was -19.000000. loss_func: 0.344766\n",
      "resetting env. episode 1058 reward total was -21.000000. loss_func: 0.115693\n",
      "resetting env. episode 1059 reward total was -21.000000. loss_func: 0.100914\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1060 reward total was -20.000000. loss_func: 0.389358\n",
      "resetting env. episode 1061 reward total was -20.000000. loss_func: 0.342339\n",
      "resetting env. episode 1062 reward total was -21.000000. loss_func: 0.109665\n",
      "resetting env. episode 1063 reward total was -21.000000. loss_func: 0.083663\n",
      "resetting env. episode 1064 reward total was -21.000000. loss_func: 0.097575\n",
      "resetting env. episode 1065 reward total was -21.000000. loss_func: 0.175686\n",
      "resetting env. episode 1066 reward total was -21.000000. loss_func: 0.081669\n",
      "resetting env. episode 1067 reward total was -20.000000. loss_func: 0.470765\n",
      "resetting env. episode 1068 reward total was -20.000000. loss_func: 0.388711\n",
      "resetting env. episode 1069 reward total was -21.000000. loss_func: 0.142616\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1070 reward total was -20.000000. loss_func: 0.511948\n",
      "resetting env. episode 1071 reward total was -21.000000. loss_func: 0.080408\n",
      "resetting env. episode 1072 reward total was -21.000000. loss_func: 0.086586\n",
      "resetting env. episode 1073 reward total was -21.000000. loss_func: 0.107326\n",
      "resetting env. episode 1074 reward total was -21.000000. loss_func: 0.075949\n",
      "resetting env. episode 1075 reward total was -17.000000. loss_func: 0.483552\n",
      "resetting env. episode 1076 reward total was -21.000000. loss_func: 0.126926\n",
      "resetting env. episode 1077 reward total was -20.000000. loss_func: 0.382774\n",
      "resetting env. episode 1078 reward total was -21.000000. loss_func: 0.105333\n",
      "resetting env. episode 1079 reward total was -21.000000. loss_func: 0.090936\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1080 reward total was -21.000000. loss_func: 0.041267\n",
      "resetting env. episode 1081 reward total was -21.000000. loss_func: 0.110294\n",
      "resetting env. episode 1082 reward total was -21.000000. loss_func: 0.103256\n",
      "resetting env. episode 1083 reward total was -21.000000. loss_func: 0.082157\n",
      "resetting env. episode 1084 reward total was -19.000000. loss_func: 0.423437\n",
      "resetting env. episode 1085 reward total was -21.000000. loss_func: 0.064615\n",
      "resetting env. episode 1086 reward total was -19.000000. loss_func: 0.526630\n",
      "resetting env. episode 1087 reward total was -21.000000. loss_func: 0.126840\n",
      "resetting env. episode 1088 reward total was -19.000000. loss_func: 0.517822\n",
      "resetting env. episode 1089 reward total was -21.000000. loss_func: 0.073563\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1090 reward total was -20.000000. loss_func: 0.411482\n",
      "resetting env. episode 1091 reward total was -21.000000. loss_func: 0.096063\n",
      "resetting env. episode 1092 reward total was -21.000000. loss_func: 0.137881\n",
      "resetting env. episode 1093 reward total was -21.000000. loss_func: 0.111857\n",
      "resetting env. episode 1094 reward total was -21.000000. loss_func: 0.080495\n",
      "resetting env. episode 1095 reward total was -21.000000. loss_func: 0.146075\n",
      "resetting env. episode 1096 reward total was -21.000000. loss_func: 0.059881\n",
      "resetting env. episode 1097 reward total was -21.000000. loss_func: 0.072428\n",
      "resetting env. episode 1098 reward total was -21.000000. loss_func: 0.055503\n",
      "resetting env. episode 1099 reward total was -20.000000. loss_func: 0.393783\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1100 reward total was -21.000000. loss_func: 0.104056\n",
      "resetting env. episode 1101 reward total was -20.000000. loss_func: 0.476781\n",
      "resetting env. episode 1102 reward total was -20.000000. loss_func: 0.391383\n",
      "resetting env. episode 1103 reward total was -20.000000. loss_func: 0.339087\n",
      "resetting env. episode 1104 reward total was -21.000000. loss_func: 0.142235\n",
      "resetting env. episode 1105 reward total was -21.000000. loss_func: 0.097359\n",
      "resetting env. episode 1106 reward total was -20.000000. loss_func: 0.363747\n",
      "resetting env. episode 1107 reward total was -21.000000. loss_func: 0.088539\n",
      "resetting env. episode 1108 reward total was -21.000000. loss_func: 0.067849\n",
      "resetting env. episode 1109 reward total was -21.000000. loss_func: 0.085541\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1110 reward total was -20.000000. loss_func: 0.353188\n",
      "resetting env. episode 1111 reward total was -19.000000. loss_func: 0.392427\n",
      "resetting env. episode 1112 reward total was -21.000000. loss_func: 0.083370\n",
      "resetting env. episode 1113 reward total was -19.000000. loss_func: 0.402710\n",
      "resetting env. episode 1114 reward total was -20.000000. loss_func: 0.441667\n",
      "resetting env. episode 1115 reward total was -19.000000. loss_func: 0.373037\n",
      "resetting env. episode 1116 reward total was -21.000000. loss_func: 0.102554\n",
      "resetting env. episode 1117 reward total was -21.000000. loss_func: 0.116525\n",
      "resetting env. episode 1118 reward total was -21.000000. loss_func: 0.138573\n",
      "resetting env. episode 1119 reward total was -21.000000. loss_func: 0.107767\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1120 reward total was -20.000000. loss_func: 0.388571\n",
      "resetting env. episode 1121 reward total was -19.000000. loss_func: 0.510350\n",
      "resetting env. episode 1122 reward total was -21.000000. loss_func: 0.126530\n",
      "resetting env. episode 1123 reward total was -21.000000. loss_func: 0.086466\n",
      "resetting env. episode 1124 reward total was -21.000000. loss_func: 0.110658\n",
      "resetting env. episode 1125 reward total was -21.000000. loss_func: 0.112495\n",
      "resetting env. episode 1126 reward total was -21.000000. loss_func: 0.036562\n",
      "resetting env. episode 1127 reward total was -21.000000. loss_func: 0.111345\n",
      "resetting env. episode 1128 reward total was -21.000000. loss_func: 0.072179\n",
      "resetting env. episode 1129 reward total was -20.000000. loss_func: 0.432622\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1130 reward total was -21.000000. loss_func: 0.131046\n",
      "resetting env. episode 1131 reward total was -20.000000. loss_func: 0.540333\n",
      "resetting env. episode 1132 reward total was -21.000000. loss_func: 0.053323\n",
      "resetting env. episode 1133 reward total was -21.000000. loss_func: 0.032882\n",
      "resetting env. episode 1134 reward total was -21.000000. loss_func: 0.109395\n",
      "resetting env. episode 1135 reward total was -21.000000. loss_func: 0.074489\n",
      "resetting env. episode 1136 reward total was -21.000000. loss_func: 0.106792\n",
      "resetting env. episode 1137 reward total was -21.000000. loss_func: 0.125652\n",
      "resetting env. episode 1138 reward total was -20.000000. loss_func: 0.361986\n",
      "resetting env. episode 1139 reward total was -21.000000. loss_func: 0.110855\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1140 reward total was -20.000000. loss_func: 0.396506\n",
      "resetting env. episode 1141 reward total was -21.000000. loss_func: 0.098742\n",
      "resetting env. episode 1142 reward total was -18.000000. loss_func: 0.386978\n",
      "resetting env. episode 1143 reward total was -20.000000. loss_func: 0.497875\n",
      "resetting env. episode 1144 reward total was -21.000000. loss_func: 0.083544\n",
      "resetting env. episode 1145 reward total was -21.000000. loss_func: 0.117019\n",
      "resetting env. episode 1146 reward total was -21.000000. loss_func: 0.110641\n",
      "resetting env. episode 1147 reward total was -21.000000. loss_func: 0.112527\n",
      "resetting env. episode 1148 reward total was -21.000000. loss_func: 0.122443\n",
      "resetting env. episode 1149 reward total was -21.000000. loss_func: 0.122913\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1150 reward total was -19.000000. loss_func: 0.403733\n",
      "resetting env. episode 1151 reward total was -21.000000. loss_func: 0.092886\n",
      "resetting env. episode 1152 reward total was -20.000000. loss_func: 0.410594\n",
      "resetting env. episode 1153 reward total was -21.000000. loss_func: 0.059071\n",
      "resetting env. episode 1154 reward total was -21.000000. loss_func: 0.081293\n",
      "resetting env. episode 1155 reward total was -20.000000. loss_func: 0.399270\n",
      "resetting env. episode 1156 reward total was -21.000000. loss_func: 0.098444\n",
      "resetting env. episode 1157 reward total was -20.000000. loss_func: 0.374156\n",
      "resetting env. episode 1158 reward total was -19.000000. loss_func: 0.346459\n",
      "resetting env. episode 1159 reward total was -19.000000. loss_func: 0.465633\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1160 reward total was -20.000000. loss_func: 0.394512\n",
      "resetting env. episode 1161 reward total was -19.000000. loss_func: 0.444275\n",
      "resetting env. episode 1162 reward total was -18.000000. loss_func: 0.336615\n",
      "resetting env. episode 1163 reward total was -21.000000. loss_func: 0.240708\n",
      "resetting env. episode 1164 reward total was -19.000000. loss_func: 0.409642\n",
      "resetting env. episode 1165 reward total was -21.000000. loss_func: 0.164642\n",
      "resetting env. episode 1166 reward total was -20.000000. loss_func: 0.339648\n",
      "resetting env. episode 1167 reward total was -19.000000. loss_func: 0.387044\n",
      "resetting env. episode 1168 reward total was -20.000000. loss_func: 0.510040\n",
      "resetting env. episode 1169 reward total was -21.000000. loss_func: 0.153500\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1170 reward total was -21.000000. loss_func: 0.104550\n",
      "resetting env. episode 1171 reward total was -18.000000. loss_func: 0.550327\n",
      "resetting env. episode 1172 reward total was -20.000000. loss_func: 0.383323\n",
      "resetting env. episode 1173 reward total was -20.000000. loss_func: 0.499425\n",
      "resetting env. episode 1174 reward total was -20.000000. loss_func: 0.330620\n",
      "resetting env. episode 1175 reward total was -20.000000. loss_func: 0.314596\n",
      "resetting env. episode 1176 reward total was -21.000000. loss_func: 0.198199\n",
      "resetting env. episode 1177 reward total was -20.000000. loss_func: 0.544890\n",
      "resetting env. episode 1178 reward total was -21.000000. loss_func: 0.080489\n",
      "resetting env. episode 1179 reward total was -21.000000. loss_func: 0.098599\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1180 reward total was -21.000000. loss_func: 0.071802\n",
      "resetting env. episode 1181 reward total was -19.000000. loss_func: 0.468492\n",
      "resetting env. episode 1182 reward total was -21.000000. loss_func: 0.102295\n",
      "resetting env. episode 1183 reward total was -19.000000. loss_func: 0.482996\n",
      "resetting env. episode 1184 reward total was -21.000000. loss_func: 0.107407\n",
      "resetting env. episode 1185 reward total was -21.000000. loss_func: 0.108528\n",
      "resetting env. episode 1186 reward total was -21.000000. loss_func: 0.055393\n",
      "resetting env. episode 1187 reward total was -21.000000. loss_func: 0.144906\n",
      "resetting env. episode 1188 reward total was -20.000000. loss_func: 0.403997\n",
      "resetting env. episode 1189 reward total was -21.000000. loss_func: 0.040057\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1190 reward total was -21.000000. loss_func: 0.067620\n",
      "resetting env. episode 1191 reward total was -21.000000. loss_func: 0.089736\n",
      "resetting env. episode 1192 reward total was -20.000000. loss_func: 0.374708\n",
      "resetting env. episode 1193 reward total was -17.000000. loss_func: 0.479785\n",
      "resetting env. episode 1194 reward total was -21.000000. loss_func: 0.130872\n",
      "resetting env. episode 1195 reward total was -18.000000. loss_func: 0.401718\n",
      "resetting env. episode 1196 reward total was -16.000000. loss_func: 0.405522\n",
      "resetting env. episode 1197 reward total was -19.000000. loss_func: 0.459061\n",
      "resetting env. episode 1198 reward total was -20.000000. loss_func: 0.345278\n",
      "resetting env. episode 1199 reward total was -21.000000. loss_func: 0.176022\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1200 reward total was -21.000000. loss_func: 0.096319\n",
      "resetting env. episode 1201 reward total was -20.000000. loss_func: 0.389236\n",
      "resetting env. episode 1202 reward total was -21.000000. loss_func: 0.119873\n",
      "resetting env. episode 1203 reward total was -21.000000. loss_func: 0.132900\n",
      "resetting env. episode 1204 reward total was -21.000000. loss_func: 0.056675\n",
      "resetting env. episode 1205 reward total was -20.000000. loss_func: 0.453430\n",
      "resetting env. episode 1206 reward total was -21.000000. loss_func: 0.043398\n",
      "resetting env. episode 1207 reward total was -20.000000. loss_func: 0.389801\n",
      "resetting env. episode 1208 reward total was -20.000000. loss_func: 0.309341\n",
      "resetting env. episode 1209 reward total was -20.000000. loss_func: 0.375824\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1210 reward total was -21.000000. loss_func: 0.158593\n",
      "resetting env. episode 1211 reward total was -21.000000. loss_func: 0.061620\n",
      "resetting env. episode 1212 reward total was -21.000000. loss_func: 0.081155\n",
      "resetting env. episode 1213 reward total was -20.000000. loss_func: 0.382995\n",
      "resetting env. episode 1214 reward total was -21.000000. loss_func: 0.035546\n",
      "resetting env. episode 1215 reward total was -21.000000. loss_func: 0.104054\n",
      "resetting env. episode 1216 reward total was -20.000000. loss_func: 0.395370\n",
      "resetting env. episode 1217 reward total was -21.000000. loss_func: 0.070219\n",
      "resetting env. episode 1218 reward total was -21.000000. loss_func: 0.069188\n",
      "resetting env. episode 1219 reward total was -21.000000. loss_func: 0.143308\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1220 reward total was -21.000000. loss_func: 0.063332\n",
      "resetting env. episode 1221 reward total was -20.000000. loss_func: 0.386751\n",
      "resetting env. episode 1222 reward total was -21.000000. loss_func: 0.129069\n",
      "resetting env. episode 1223 reward total was -21.000000. loss_func: 0.084186\n",
      "resetting env. episode 1224 reward total was -21.000000. loss_func: 0.077846\n",
      "resetting env. episode 1225 reward total was -21.000000. loss_func: 0.117362\n",
      "resetting env. episode 1226 reward total was -19.000000. loss_func: 0.439991\n",
      "resetting env. episode 1227 reward total was -21.000000. loss_func: 0.082710\n",
      "resetting env. episode 1228 reward total was -21.000000. loss_func: 0.073645\n",
      "resetting env. episode 1229 reward total was -21.000000. loss_func: 0.113072\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1230 reward total was -19.000000. loss_func: 0.446654\n",
      "resetting env. episode 1231 reward total was -21.000000. loss_func: 0.072241\n",
      "resetting env. episode 1232 reward total was -21.000000. loss_func: 0.131592\n",
      "resetting env. episode 1233 reward total was -21.000000. loss_func: 0.044059\n",
      "resetting env. episode 1234 reward total was -21.000000. loss_func: 0.034591\n",
      "resetting env. episode 1235 reward total was -21.000000. loss_func: 0.063211\n",
      "resetting env. episode 1236 reward total was -20.000000. loss_func: 0.454433\n",
      "resetting env. episode 1237 reward total was -21.000000. loss_func: 0.067142\n",
      "resetting env. episode 1238 reward total was -20.000000. loss_func: 0.402573\n",
      "resetting env. episode 1239 reward total was -20.000000. loss_func: 0.482982\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1240 reward total was -21.000000. loss_func: 0.118813\n",
      "resetting env. episode 1241 reward total was -20.000000. loss_func: 0.404237\n",
      "resetting env. episode 1242 reward total was -17.000000. loss_func: 0.383699\n",
      "resetting env. episode 1243 reward total was -20.000000. loss_func: 0.358048\n",
      "resetting env. episode 1244 reward total was -21.000000. loss_func: 0.176965\n",
      "resetting env. episode 1245 reward total was -19.000000. loss_func: 0.415495\n",
      "resetting env. episode 1246 reward total was -21.000000. loss_func: 0.094631\n",
      "resetting env. episode 1247 reward total was -20.000000. loss_func: 0.352456\n",
      "resetting env. episode 1248 reward total was -20.000000. loss_func: 0.335512\n",
      "resetting env. episode 1249 reward total was -21.000000. loss_func: 0.111254\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1250 reward total was -21.000000. loss_func: 0.084351\n",
      "resetting env. episode 1251 reward total was -21.000000. loss_func: 0.065222\n",
      "resetting env. episode 1252 reward total was -21.000000. loss_func: 0.079185\n",
      "resetting env. episode 1253 reward total was -20.000000. loss_func: 0.404039\n",
      "resetting env. episode 1254 reward total was -21.000000. loss_func: 0.095267\n",
      "resetting env. episode 1255 reward total was -20.000000. loss_func: 0.384100\n",
      "resetting env. episode 1256 reward total was -21.000000. loss_func: 0.085129\n",
      "resetting env. episode 1257 reward total was -21.000000. loss_func: 0.053128\n",
      "resetting env. episode 1258 reward total was -20.000000. loss_func: 0.444610\n",
      "resetting env. episode 1259 reward total was -20.000000. loss_func: 0.370917\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1260 reward total was -21.000000. loss_func: 0.073147\n",
      "resetting env. episode 1261 reward total was -21.000000. loss_func: 0.106892\n",
      "resetting env. episode 1262 reward total was -20.000000. loss_func: 0.429230\n",
      "resetting env. episode 1263 reward total was -20.000000. loss_func: 0.348932\n",
      "resetting env. episode 1264 reward total was -21.000000. loss_func: 0.125275\n",
      "resetting env. episode 1265 reward total was -21.000000. loss_func: 0.110655\n",
      "resetting env. episode 1266 reward total was -20.000000. loss_func: 0.392424\n",
      "resetting env. episode 1267 reward total was -20.000000. loss_func: 0.505797\n",
      "resetting env. episode 1268 reward total was -21.000000. loss_func: 0.116153\n",
      "resetting env. episode 1269 reward total was -21.000000. loss_func: 0.067146\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1270 reward total was -21.000000. loss_func: 0.075875\n",
      "resetting env. episode 1271 reward total was -20.000000. loss_func: 0.371431\n",
      "resetting env. episode 1272 reward total was -21.000000. loss_func: 0.103420\n",
      "resetting env. episode 1273 reward total was -21.000000. loss_func: 0.083679\n",
      "resetting env. episode 1274 reward total was -21.000000. loss_func: 0.090197\n",
      "resetting env. episode 1275 reward total was -21.000000. loss_func: 0.094349\n",
      "resetting env. episode 1276 reward total was -18.000000. loss_func: 0.387864\n",
      "resetting env. episode 1277 reward total was -21.000000. loss_func: 0.096395\n",
      "resetting env. episode 1278 reward total was -20.000000. loss_func: 0.335167\n",
      "resetting env. episode 1279 reward total was -19.000000. loss_func: 0.382228\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1280 reward total was -21.000000. loss_func: 0.082506\n",
      "resetting env. episode 1281 reward total was -21.000000. loss_func: 0.092403\n",
      "resetting env. episode 1282 reward total was -21.000000. loss_func: 0.054848\n",
      "resetting env. episode 1283 reward total was -21.000000. loss_func: 0.151142\n",
      "resetting env. episode 1284 reward total was -21.000000. loss_func: 0.066055\n",
      "resetting env. episode 1285 reward total was -21.000000. loss_func: 0.167443\n",
      "resetting env. episode 1286 reward total was -21.000000. loss_func: 0.160636\n",
      "resetting env. episode 1287 reward total was -20.000000. loss_func: 0.420964\n",
      "resetting env. episode 1288 reward total was -19.000000. loss_func: 0.317698\n",
      "resetting env. episode 1289 reward total was -21.000000. loss_func: 0.069195\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1290 reward total was -18.000000. loss_func: 0.519787\n",
      "resetting env. episode 1291 reward total was -21.000000. loss_func: 0.076567\n",
      "resetting env. episode 1292 reward total was -21.000000. loss_func: 0.027976\n",
      "resetting env. episode 1293 reward total was -21.000000. loss_func: 0.064936\n",
      "resetting env. episode 1294 reward total was -21.000000. loss_func: 0.030711\n",
      "resetting env. episode 1295 reward total was -20.000000. loss_func: 0.429275\n",
      "resetting env. episode 1296 reward total was -21.000000. loss_func: 0.115142\n",
      "resetting env. episode 1297 reward total was -20.000000. loss_func: 0.359626\n",
      "resetting env. episode 1298 reward total was -20.000000. loss_func: 0.350989\n",
      "resetting env. episode 1299 reward total was -21.000000. loss_func: 0.131771\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1300 reward total was -18.000000. loss_func: 0.368682\n",
      "resetting env. episode 1301 reward total was -21.000000. loss_func: 0.128537\n",
      "resetting env. episode 1302 reward total was -20.000000. loss_func: 0.432114\n",
      "resetting env. episode 1303 reward total was -21.000000. loss_func: 0.126007\n",
      "resetting env. episode 1304 reward total was -21.000000. loss_func: 0.062700\n",
      "resetting env. episode 1305 reward total was -21.000000. loss_func: 0.081535\n",
      "resetting env. episode 1306 reward total was -20.000000. loss_func: 0.389223\n",
      "resetting env. episode 1307 reward total was -21.000000. loss_func: 0.099780\n",
      "resetting env. episode 1308 reward total was -20.000000. loss_func: 0.360832\n",
      "resetting env. episode 1309 reward total was -21.000000. loss_func: 0.049782\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1310 reward total was -21.000000. loss_func: 0.057115\n",
      "resetting env. episode 1311 reward total was -20.000000. loss_func: 0.483352\n",
      "resetting env. episode 1312 reward total was -21.000000. loss_func: 0.089226\n",
      "resetting env. episode 1313 reward total was -21.000000. loss_func: 0.131516\n",
      "resetting env. episode 1314 reward total was -20.000000. loss_func: 0.351097\n",
      "resetting env. episode 1315 reward total was -19.000000. loss_func: 0.523575\n",
      "resetting env. episode 1316 reward total was -21.000000. loss_func: 0.052750\n",
      "resetting env. episode 1317 reward total was -21.000000. loss_func: 0.133155\n",
      "resetting env. episode 1318 reward total was -21.000000. loss_func: 0.112938\n",
      "resetting env. episode 1319 reward total was -20.000000. loss_func: 0.386175\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1320 reward total was -21.000000. loss_func: 0.105442\n",
      "resetting env. episode 1321 reward total was -20.000000. loss_func: 0.358236\n",
      "resetting env. episode 1322 reward total was -19.000000. loss_func: 0.339693\n",
      "resetting env. episode 1323 reward total was -21.000000. loss_func: 0.106393\n",
      "resetting env. episode 1324 reward total was -19.000000. loss_func: 0.548953\n",
      "resetting env. episode 1325 reward total was -21.000000. loss_func: 0.059269\n",
      "resetting env. episode 1326 reward total was -20.000000. loss_func: 0.343561\n",
      "resetting env. episode 1327 reward total was -20.000000. loss_func: 0.345221\n",
      "resetting env. episode 1328 reward total was -21.000000. loss_func: 0.136838\n",
      "resetting env. episode 1329 reward total was -21.000000. loss_func: 0.070464\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1330 reward total was -21.000000. loss_func: 0.114710\n",
      "resetting env. episode 1331 reward total was -21.000000. loss_func: 0.075214\n",
      "resetting env. episode 1332 reward total was -20.000000. loss_func: 0.377937\n",
      "resetting env. episode 1333 reward total was -20.000000. loss_func: 0.409109\n",
      "resetting env. episode 1334 reward total was -20.000000. loss_func: 0.359404\n",
      "resetting env. episode 1335 reward total was -21.000000. loss_func: 0.170117\n",
      "resetting env. episode 1336 reward total was -21.000000. loss_func: 0.142013\n",
      "resetting env. episode 1337 reward total was -21.000000. loss_func: 0.060968\n",
      "resetting env. episode 1338 reward total was -20.000000. loss_func: 0.358978\n",
      "resetting env. episode 1339 reward total was -21.000000. loss_func: 0.102048\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1340 reward total was -21.000000. loss_func: 0.061571\n",
      "resetting env. episode 1341 reward total was -21.000000. loss_func: 0.098393\n",
      "resetting env. episode 1342 reward total was -21.000000. loss_func: 0.085335\n",
      "resetting env. episode 1343 reward total was -21.000000. loss_func: 0.079766\n",
      "resetting env. episode 1344 reward total was -21.000000. loss_func: 0.104109\n",
      "resetting env. episode 1345 reward total was -20.000000. loss_func: 0.462849\n",
      "resetting env. episode 1346 reward total was -21.000000. loss_func: 0.067077\n",
      "resetting env. episode 1347 reward total was -21.000000. loss_func: 0.091078\n",
      "resetting env. episode 1348 reward total was -19.000000. loss_func: 0.445115\n",
      "resetting env. episode 1349 reward total was -21.000000. loss_func: 0.094208\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1350 reward total was -17.000000. loss_func: 0.532865\n",
      "resetting env. episode 1351 reward total was -20.000000. loss_func: 0.334715\n",
      "resetting env. episode 1352 reward total was -21.000000. loss_func: 0.110369\n",
      "resetting env. episode 1353 reward total was -21.000000. loss_func: 0.100161\n",
      "resetting env. episode 1354 reward total was -21.000000. loss_func: 0.080532\n",
      "resetting env. episode 1355 reward total was -21.000000. loss_func: 0.078777\n",
      "resetting env. episode 1356 reward total was -21.000000. loss_func: 0.083824\n",
      "resetting env. episode 1357 reward total was -21.000000. loss_func: 0.062421\n",
      "resetting env. episode 1358 reward total was -19.000000. loss_func: 0.398271\n",
      "resetting env. episode 1359 reward total was -20.000000. loss_func: 0.346718\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1360 reward total was -20.000000. loss_func: 0.387201\n",
      "resetting env. episode 1361 reward total was -21.000000. loss_func: 0.125521\n",
      "resetting env. episode 1362 reward total was -21.000000. loss_func: 0.082710\n",
      "resetting env. episode 1363 reward total was -21.000000. loss_func: 0.101713\n",
      "resetting env. episode 1364 reward total was -21.000000. loss_func: 0.038830\n",
      "resetting env. episode 1365 reward total was -21.000000. loss_func: 0.096474\n",
      "resetting env. episode 1366 reward total was -21.000000. loss_func: 0.083582\n",
      "resetting env. episode 1367 reward total was -19.000000. loss_func: 0.416071\n",
      "resetting env. episode 1368 reward total was -20.000000. loss_func: 0.384445\n",
      "resetting env. episode 1369 reward total was -20.000000. loss_func: 0.442664\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1370 reward total was -20.000000. loss_func: 0.337845\n",
      "resetting env. episode 1371 reward total was -21.000000. loss_func: 0.136726\n",
      "resetting env. episode 1372 reward total was -20.000000. loss_func: 0.371424\n",
      "resetting env. episode 1373 reward total was -21.000000. loss_func: 0.117279\n",
      "resetting env. episode 1374 reward total was -21.000000. loss_func: 0.179061\n",
      "resetting env. episode 1375 reward total was -17.000000. loss_func: 0.414836\n",
      "resetting env. episode 1376 reward total was -20.000000. loss_func: 0.349487\n",
      "resetting env. episode 1377 reward total was -18.000000. loss_func: 0.476109\n",
      "resetting env. episode 1378 reward total was -21.000000. loss_func: 0.110317\n",
      "resetting env. episode 1379 reward total was -21.000000. loss_func: 0.083161\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1380 reward total was -19.000000. loss_func: 0.434041\n",
      "resetting env. episode 1381 reward total was -16.000000. loss_func: 0.484527\n",
      "resetting env. episode 1382 reward total was -21.000000. loss_func: 0.119901\n",
      "resetting env. episode 1383 reward total was -21.000000. loss_func: 0.095282\n",
      "resetting env. episode 1384 reward total was -21.000000. loss_func: 0.079641\n",
      "resetting env. episode 1385 reward total was -19.000000. loss_func: 0.416865\n",
      "resetting env. episode 1386 reward total was -21.000000. loss_func: 0.074206\n",
      "resetting env. episode 1387 reward total was -21.000000. loss_func: 0.073787\n",
      "resetting env. episode 1388 reward total was -20.000000. loss_func: 0.356346\n",
      "resetting env. episode 1389 reward total was -18.000000. loss_func: 0.397833\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1390 reward total was -21.000000. loss_func: 0.086290\n",
      "resetting env. episode 1391 reward total was -21.000000. loss_func: 0.145317\n",
      "resetting env. episode 1392 reward total was -20.000000. loss_func: 0.390322\n",
      "resetting env. episode 1393 reward total was -20.000000. loss_func: 0.346161\n",
      "resetting env. episode 1394 reward total was -19.000000. loss_func: 0.327254\n",
      "resetting env. episode 1395 reward total was -21.000000. loss_func: 0.085235\n",
      "resetting env. episode 1396 reward total was -18.000000. loss_func: 0.535061\n",
      "resetting env. episode 1397 reward total was -19.000000. loss_func: 0.418422\n",
      "resetting env. episode 1398 reward total was -21.000000. loss_func: 0.139168\n",
      "resetting env. episode 1399 reward total was -21.000000. loss_func: 0.080545\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1400 reward total was -21.000000. loss_func: 0.049615\n",
      "resetting env. episode 1401 reward total was -21.000000. loss_func: 0.093111\n",
      "resetting env. episode 1402 reward total was -21.000000. loss_func: 0.123795\n",
      "resetting env. episode 1403 reward total was -21.000000. loss_func: 0.049513\n",
      "resetting env. episode 1404 reward total was -20.000000. loss_func: 0.354032\n",
      "resetting env. episode 1405 reward total was -20.000000. loss_func: 0.372476\n",
      "resetting env. episode 1406 reward total was -21.000000. loss_func: 0.150754\n",
      "resetting env. episode 1407 reward total was -21.000000. loss_func: 0.090029\n",
      "resetting env. episode 1408 reward total was -18.000000. loss_func: 0.397307\n",
      "resetting env. episode 1409 reward total was -21.000000. loss_func: 0.086271\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1410 reward total was -21.000000. loss_func: 0.038888\n",
      "resetting env. episode 1411 reward total was -21.000000. loss_func: 0.127968\n",
      "resetting env. episode 1412 reward total was -21.000000. loss_func: 0.095322\n",
      "resetting env. episode 1413 reward total was -20.000000. loss_func: 0.329450\n",
      "resetting env. episode 1414 reward total was -20.000000. loss_func: 0.327263\n",
      "resetting env. episode 1415 reward total was -21.000000. loss_func: 0.056905\n",
      "resetting env. episode 1416 reward total was -21.000000. loss_func: 0.063221\n",
      "resetting env. episode 1417 reward total was -21.000000. loss_func: 0.126263\n",
      "resetting env. episode 1418 reward total was -19.000000. loss_func: 0.454529\n",
      "resetting env. episode 1419 reward total was -20.000000. loss_func: 0.341675\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1420 reward total was -21.000000. loss_func: 0.103832\n",
      "resetting env. episode 1421 reward total was -21.000000. loss_func: 0.024925\n",
      "resetting env. episode 1422 reward total was -21.000000. loss_func: 0.124867\n",
      "resetting env. episode 1423 reward total was -21.000000. loss_func: 0.050915\n",
      "resetting env. episode 1424 reward total was -21.000000. loss_func: 0.086173\n",
      "resetting env. episode 1425 reward total was -21.000000. loss_func: 0.076670\n",
      "resetting env. episode 1426 reward total was -21.000000. loss_func: 0.090092\n",
      "resetting env. episode 1427 reward total was -17.000000. loss_func: 0.414057\n",
      "resetting env. episode 1428 reward total was -21.000000. loss_func: 0.093409\n",
      "resetting env. episode 1429 reward total was -20.000000. loss_func: 0.376633\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1430 reward total was -21.000000. loss_func: 0.162049\n",
      "resetting env. episode 1431 reward total was -20.000000. loss_func: 0.428005\n",
      "resetting env. episode 1432 reward total was -21.000000. loss_func: 0.102875\n",
      "resetting env. episode 1433 reward total was -21.000000. loss_func: 0.141084\n",
      "resetting env. episode 1434 reward total was -21.000000. loss_func: 0.048003\n",
      "resetting env. episode 1435 reward total was -21.000000. loss_func: 0.084578\n",
      "resetting env. episode 1436 reward total was -21.000000. loss_func: 0.084146\n",
      "resetting env. episode 1437 reward total was -21.000000. loss_func: 0.095625\n",
      "resetting env. episode 1438 reward total was -21.000000. loss_func: 0.103632\n",
      "resetting env. episode 1439 reward total was -21.000000. loss_func: 0.095541\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1440 reward total was -20.000000. loss_func: 0.437866\n",
      "resetting env. episode 1441 reward total was -21.000000. loss_func: 0.068797\n",
      "resetting env. episode 1442 reward total was -20.000000. loss_func: 0.473708\n",
      "resetting env. episode 1443 reward total was -21.000000. loss_func: 0.058145\n",
      "resetting env. episode 1444 reward total was -20.000000. loss_func: 0.362091\n",
      "resetting env. episode 1445 reward total was -21.000000. loss_func: 0.159485\n",
      "resetting env. episode 1446 reward total was -20.000000. loss_func: 0.415321\n",
      "resetting env. episode 1447 reward total was -21.000000. loss_func: 0.106309\n",
      "resetting env. episode 1448 reward total was -20.000000. loss_func: 0.370580\n",
      "resetting env. episode 1449 reward total was -19.000000. loss_func: 0.401153\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1450 reward total was -21.000000. loss_func: 0.059896\n",
      "resetting env. episode 1451 reward total was -20.000000. loss_func: 0.368273\n",
      "resetting env. episode 1452 reward total was -21.000000. loss_func: 0.071457\n",
      "resetting env. episode 1453 reward total was -21.000000. loss_func: 0.089556\n",
      "resetting env. episode 1454 reward total was -18.000000. loss_func: 0.397818\n",
      "resetting env. episode 1455 reward total was -21.000000. loss_func: 0.086281\n",
      "resetting env. episode 1456 reward total was -20.000000. loss_func: 0.514125\n",
      "resetting env. episode 1457 reward total was -21.000000. loss_func: 0.076930\n",
      "resetting env. episode 1458 reward total was -21.000000. loss_func: 0.065461\n",
      "resetting env. episode 1459 reward total was -21.000000. loss_func: 0.061252\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1460 reward total was -21.000000. loss_func: 0.097883\n",
      "resetting env. episode 1461 reward total was -21.000000. loss_func: 0.132774\n",
      "resetting env. episode 1462 reward total was -21.000000. loss_func: 0.106593\n",
      "resetting env. episode 1463 reward total was -21.000000. loss_func: 0.046196\n",
      "resetting env. episode 1464 reward total was -21.000000. loss_func: 0.069459\n",
      "resetting env. episode 1465 reward total was -19.000000. loss_func: 0.506485\n",
      "resetting env. episode 1466 reward total was -21.000000. loss_func: 0.062000\n",
      "resetting env. episode 1467 reward total was -21.000000. loss_func: 0.059774\n",
      "resetting env. episode 1468 reward total was -20.000000. loss_func: 0.471705\n",
      "resetting env. episode 1469 reward total was -21.000000. loss_func: 0.110634\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1470 reward total was -21.000000. loss_func: 0.070787\n",
      "resetting env. episode 1471 reward total was -20.000000. loss_func: 0.409560\n",
      "resetting env. episode 1472 reward total was -21.000000. loss_func: 0.056198\n",
      "resetting env. episode 1473 reward total was -21.000000. loss_func: 0.115156\n",
      "resetting env. episode 1474 reward total was -21.000000. loss_func: 0.111797\n",
      "resetting env. episode 1475 reward total was -20.000000. loss_func: 0.465652\n",
      "resetting env. episode 1476 reward total was -21.000000. loss_func: 0.087927\n",
      "resetting env. episode 1477 reward total was -21.000000. loss_func: 0.074506\n",
      "resetting env. episode 1478 reward total was -21.000000. loss_func: 0.092915\n",
      "resetting env. episode 1479 reward total was -21.000000. loss_func: 0.067871\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1480 reward total was -20.000000. loss_func: 0.392600\n",
      "resetting env. episode 1481 reward total was -21.000000. loss_func: 0.107430\n",
      "resetting env. episode 1482 reward total was -21.000000. loss_func: 0.094322\n",
      "resetting env. episode 1483 reward total was -20.000000. loss_func: 0.464259\n",
      "resetting env. episode 1484 reward total was -21.000000. loss_func: 0.135227\n",
      "resetting env. episode 1485 reward total was -20.000000. loss_func: 0.435516\n",
      "resetting env. episode 1486 reward total was -21.000000. loss_func: 0.129352\n",
      "resetting env. episode 1487 reward total was -21.000000. loss_func: 0.057422\n",
      "resetting env. episode 1488 reward total was -21.000000. loss_func: 0.098371\n",
      "resetting env. episode 1489 reward total was -21.000000. loss_func: 0.048665\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1490 reward total was -21.000000. loss_func: 0.109357\n",
      "resetting env. episode 1491 reward total was -18.000000. loss_func: 0.385787\n",
      "resetting env. episode 1492 reward total was -21.000000. loss_func: 0.055734\n",
      "resetting env. episode 1493 reward total was -21.000000. loss_func: 0.078476\n",
      "resetting env. episode 1494 reward total was -21.000000. loss_func: 0.061827\n",
      "resetting env. episode 1495 reward total was -20.000000. loss_func: 0.425958\n",
      "resetting env. episode 1496 reward total was -21.000000. loss_func: 0.074480\n",
      "resetting env. episode 1497 reward total was -21.000000. loss_func: 0.073071\n",
      "resetting env. episode 1498 reward total was -21.000000. loss_func: 0.093182\n",
      "resetting env. episode 1499 reward total was -21.000000. loss_func: 0.058442\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1500 reward total was -19.000000. loss_func: 0.356697\n",
      "resetting env. episode 1501 reward total was -21.000000. loss_func: 0.131152\n",
      "resetting env. episode 1502 reward total was -21.000000. loss_func: 0.027201\n",
      "resetting env. episode 1503 reward total was -21.000000. loss_func: 0.095547\n",
      "resetting env. episode 1504 reward total was -21.000000. loss_func: 0.132061\n",
      "resetting env. episode 1505 reward total was -20.000000. loss_func: 0.399146\n",
      "resetting env. episode 1506 reward total was -21.000000. loss_func: 0.052506\n",
      "resetting env. episode 1507 reward total was -21.000000. loss_func: 0.090609\n",
      "resetting env. episode 1508 reward total was -20.000000. loss_func: 0.379080\n",
      "resetting env. episode 1509 reward total was -20.000000. loss_func: 0.382469\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1510 reward total was -20.000000. loss_func: 0.367860\n",
      "resetting env. episode 1511 reward total was -21.000000. loss_func: 0.099351\n",
      "resetting env. episode 1512 reward total was -21.000000. loss_func: 0.124972\n",
      "resetting env. episode 1513 reward total was -21.000000. loss_func: 0.061011\n",
      "resetting env. episode 1514 reward total was -20.000000. loss_func: 0.361610\n",
      "resetting env. episode 1515 reward total was -21.000000. loss_func: 0.067541\n",
      "resetting env. episode 1516 reward total was -21.000000. loss_func: 0.091387\n",
      "resetting env. episode 1517 reward total was -21.000000. loss_func: 0.114328\n",
      "resetting env. episode 1518 reward total was -20.000000. loss_func: 0.505583\n",
      "resetting env. episode 1519 reward total was -21.000000. loss_func: 0.082573\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1520 reward total was -18.000000. loss_func: 0.490384\n",
      "resetting env. episode 1521 reward total was -21.000000. loss_func: 0.079109\n",
      "resetting env. episode 1522 reward total was -21.000000. loss_func: 0.103111\n",
      "resetting env. episode 1523 reward total was -21.000000. loss_func: 0.129687\n",
      "resetting env. episode 1524 reward total was -21.000000. loss_func: 0.059793\n",
      "resetting env. episode 1525 reward total was -21.000000. loss_func: 0.067617\n",
      "resetting env. episode 1526 reward total was -21.000000. loss_func: 0.098010\n",
      "resetting env. episode 1527 reward total was -18.000000. loss_func: 0.389359\n",
      "resetting env. episode 1528 reward total was -21.000000. loss_func: 0.132498\n",
      "resetting env. episode 1529 reward total was -21.000000. loss_func: 0.101447\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1530 reward total was -21.000000. loss_func: 0.072534\n",
      "resetting env. episode 1531 reward total was -21.000000. loss_func: 0.108795\n",
      "resetting env. episode 1532 reward total was -19.000000. loss_func: 0.383485\n",
      "resetting env. episode 1533 reward total was -20.000000. loss_func: 0.367357\n",
      "resetting env. episode 1534 reward total was -20.000000. loss_func: 0.492725\n",
      "resetting env. episode 1535 reward total was -20.000000. loss_func: 0.366118\n",
      "resetting env. episode 1536 reward total was -18.000000. loss_func: 0.333605\n",
      "resetting env. episode 1537 reward total was -21.000000. loss_func: 0.146192\n",
      "resetting env. episode 1538 reward total was -20.000000. loss_func: 0.333208\n",
      "resetting env. episode 1539 reward total was -21.000000. loss_func: 0.174000\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1540 reward total was -21.000000. loss_func: 0.078801\n",
      "resetting env. episode 1541 reward total was -21.000000. loss_func: 0.070948\n",
      "resetting env. episode 1542 reward total was -21.000000. loss_func: 0.143814\n",
      "resetting env. episode 1543 reward total was -20.000000. loss_func: 0.509568\n",
      "resetting env. episode 1544 reward total was -21.000000. loss_func: 0.080480\n",
      "resetting env. episode 1545 reward total was -20.000000. loss_func: 0.491191\n",
      "resetting env. episode 1546 reward total was -21.000000. loss_func: 0.045541\n",
      "resetting env. episode 1547 reward total was -20.000000. loss_func: 0.433720\n",
      "resetting env. episode 1548 reward total was -21.000000. loss_func: 0.108948\n",
      "resetting env. episode 1549 reward total was -18.000000. loss_func: 0.401840\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1550 reward total was -21.000000. loss_func: 0.052253\n",
      "resetting env. episode 1551 reward total was -21.000000. loss_func: 0.087966\n",
      "resetting env. episode 1552 reward total was -21.000000. loss_func: 0.099901\n",
      "resetting env. episode 1553 reward total was -18.000000. loss_func: 0.449524\n",
      "resetting env. episode 1554 reward total was -21.000000. loss_func: 0.078722\n",
      "resetting env. episode 1555 reward total was -21.000000. loss_func: 0.067105\n",
      "resetting env. episode 1556 reward total was -21.000000. loss_func: 0.032158\n",
      "resetting env. episode 1557 reward total was -20.000000. loss_func: 0.458740\n",
      "resetting env. episode 1558 reward total was -20.000000. loss_func: 0.411539\n",
      "resetting env. episode 1559 reward total was -21.000000. loss_func: 0.103186\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1560 reward total was -20.000000. loss_func: 0.389700\n",
      "resetting env. episode 1561 reward total was -21.000000. loss_func: 0.073057\n",
      "resetting env. episode 1562 reward total was -21.000000. loss_func: 0.112990\n",
      "resetting env. episode 1563 reward total was -20.000000. loss_func: 0.435491\n",
      "resetting env. episode 1564 reward total was -21.000000. loss_func: 0.083338\n",
      "resetting env. episode 1565 reward total was -21.000000. loss_func: 0.080304\n",
      "resetting env. episode 1566 reward total was -21.000000. loss_func: 0.021996\n",
      "resetting env. episode 1567 reward total was -21.000000. loss_func: 0.079320\n",
      "resetting env. episode 1568 reward total was -21.000000. loss_func: 0.105225\n",
      "resetting env. episode 1569 reward total was -21.000000. loss_func: 0.080351\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1570 reward total was -21.000000. loss_func: 0.098349\n",
      "resetting env. episode 1571 reward total was -20.000000. loss_func: 0.359080\n",
      "resetting env. episode 1572 reward total was -21.000000. loss_func: 0.082388\n",
      "resetting env. episode 1573 reward total was -21.000000. loss_func: 0.067685\n",
      "resetting env. episode 1574 reward total was -21.000000. loss_func: 0.086217\n",
      "resetting env. episode 1575 reward total was -21.000000. loss_func: 0.078491\n",
      "resetting env. episode 1576 reward total was -20.000000. loss_func: 0.419586\n",
      "resetting env. episode 1577 reward total was -21.000000. loss_func: 0.060559\n",
      "resetting env. episode 1578 reward total was -21.000000. loss_func: 0.056966\n",
      "resetting env. episode 1579 reward total was -20.000000. loss_func: 0.373049\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1580 reward total was -20.000000. loss_func: 0.370544\n",
      "resetting env. episode 1581 reward total was -21.000000. loss_func: 0.079943\n",
      "resetting env. episode 1582 reward total was -19.000000. loss_func: 0.373527\n",
      "resetting env. episode 1583 reward total was -21.000000. loss_func: 0.067062\n",
      "resetting env. episode 1584 reward total was -21.000000. loss_func: 0.081674\n",
      "resetting env. episode 1585 reward total was -19.000000. loss_func: 0.356207\n",
      "resetting env. episode 1586 reward total was -20.000000. loss_func: 0.323327\n",
      "resetting env. episode 1587 reward total was -21.000000. loss_func: 0.105332\n",
      "resetting env. episode 1588 reward total was -21.000000. loss_func: 0.069571\n",
      "resetting env. episode 1589 reward total was -21.000000. loss_func: 0.057693\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1590 reward total was -21.000000. loss_func: 0.126841\n",
      "resetting env. episode 1591 reward total was -21.000000. loss_func: 0.090980\n",
      "resetting env. episode 1592 reward total was -20.000000. loss_func: 0.410950\n",
      "resetting env. episode 1593 reward total was -21.000000. loss_func: 0.050939\n",
      "resetting env. episode 1594 reward total was -20.000000. loss_func: 0.397569\n",
      "resetting env. episode 1595 reward total was -21.000000. loss_func: 0.077539\n",
      "resetting env. episode 1596 reward total was -21.000000. loss_func: 0.122112\n",
      "resetting env. episode 1597 reward total was -20.000000. loss_func: 0.455185\n",
      "resetting env. episode 1598 reward total was -20.000000. loss_func: 0.490229\n",
      "resetting env. episode 1599 reward total was -18.000000. loss_func: 0.552416\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1600 reward total was -21.000000. loss_func: 0.053809\n",
      "resetting env. episode 1601 reward total was -21.000000. loss_func: 0.055247\n",
      "resetting env. episode 1602 reward total was -21.000000. loss_func: 0.057231\n",
      "resetting env. episode 1603 reward total was -21.000000. loss_func: 0.066849\n",
      "resetting env. episode 1604 reward total was -21.000000. loss_func: 0.093897\n",
      "resetting env. episode 1605 reward total was -20.000000. loss_func: 0.433094\n",
      "resetting env. episode 1606 reward total was -20.000000. loss_func: 0.349418\n",
      "resetting env. episode 1607 reward total was -21.000000. loss_func: 0.091952\n",
      "resetting env. episode 1608 reward total was -21.000000. loss_func: 0.065672\n",
      "resetting env. episode 1609 reward total was -20.000000. loss_func: 0.396524\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1610 reward total was -19.000000. loss_func: 0.357096\n",
      "resetting env. episode 1611 reward total was -20.000000. loss_func: 0.352921\n",
      "resetting env. episode 1612 reward total was -21.000000. loss_func: 0.106387\n",
      "resetting env. episode 1613 reward total was -21.000000. loss_func: 0.096514\n",
      "resetting env. episode 1614 reward total was -21.000000. loss_func: 0.047982\n",
      "resetting env. episode 1615 reward total was -21.000000. loss_func: 0.025159\n",
      "resetting env. episode 1616 reward total was -21.000000. loss_func: 0.067970\n",
      "resetting env. episode 1617 reward total was -20.000000. loss_func: 0.564969\n",
      "resetting env. episode 1618 reward total was -21.000000. loss_func: 0.096080\n",
      "resetting env. episode 1619 reward total was -21.000000. loss_func: 0.102774\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1620 reward total was -21.000000. loss_func: 0.053733\n",
      "resetting env. episode 1621 reward total was -21.000000. loss_func: 0.111505\n",
      "resetting env. episode 1622 reward total was -21.000000. loss_func: 0.076595\n",
      "resetting env. episode 1623 reward total was -20.000000. loss_func: 0.366121\n",
      "resetting env. episode 1624 reward total was -21.000000. loss_func: 0.132381\n",
      "resetting env. episode 1625 reward total was -21.000000. loss_func: 0.023387\n",
      "resetting env. episode 1626 reward total was -20.000000. loss_func: 0.328890\n",
      "resetting env. episode 1627 reward total was -20.000000. loss_func: 0.328789\n",
      "resetting env. episode 1628 reward total was -19.000000. loss_func: 0.363351\n",
      "resetting env. episode 1629 reward total was -20.000000. loss_func: 0.320808\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1630 reward total was -21.000000. loss_func: 0.211807\n",
      "resetting env. episode 1631 reward total was -20.000000. loss_func: 0.378867\n",
      "resetting env. episode 1632 reward total was -20.000000. loss_func: 0.340227\n",
      "resetting env. episode 1633 reward total was -21.000000. loss_func: 0.119008\n",
      "resetting env. episode 1634 reward total was -21.000000. loss_func: 0.075732\n",
      "resetting env. episode 1635 reward total was -21.000000. loss_func: 0.079502\n",
      "resetting env. episode 1636 reward total was -20.000000. loss_func: 0.375437\n",
      "resetting env. episode 1637 reward total was -19.000000. loss_func: 0.433213\n",
      "resetting env. episode 1638 reward total was -20.000000. loss_func: 0.359779\n",
      "resetting env. episode 1639 reward total was -20.000000. loss_func: 0.348924\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1640 reward total was -20.000000. loss_func: 0.342629\n",
      "resetting env. episode 1641 reward total was -21.000000. loss_func: 0.168983\n",
      "resetting env. episode 1642 reward total was -21.000000. loss_func: 0.120277\n",
      "resetting env. episode 1643 reward total was -21.000000. loss_func: 0.133445\n",
      "resetting env. episode 1644 reward total was -17.000000. loss_func: 0.387633\n",
      "resetting env. episode 1645 reward total was -21.000000. loss_func: 0.103817\n",
      "resetting env. episode 1646 reward total was -21.000000. loss_func: 0.122907\n",
      "resetting env. episode 1647 reward total was -21.000000. loss_func: 0.102937\n",
      "resetting env. episode 1648 reward total was -19.000000. loss_func: 0.353965\n",
      "resetting env. episode 1649 reward total was -21.000000. loss_func: 0.107325\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1650 reward total was -20.000000. loss_func: 0.428385\n",
      "resetting env. episode 1651 reward total was -21.000000. loss_func: 0.129384\n",
      "resetting env. episode 1652 reward total was -20.000000. loss_func: 0.372636\n",
      "resetting env. episode 1653 reward total was -21.000000. loss_func: 0.088785\n",
      "resetting env. episode 1654 reward total was -21.000000. loss_func: 0.058057\n",
      "resetting env. episode 1655 reward total was -20.000000. loss_func: 0.314988\n",
      "resetting env. episode 1656 reward total was -21.000000. loss_func: 0.099155\n",
      "resetting env. episode 1657 reward total was -21.000000. loss_func: 0.121450\n",
      "resetting env. episode 1658 reward total was -21.000000. loss_func: 0.067949\n",
      "resetting env. episode 1659 reward total was -21.000000. loss_func: 0.101097\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1660 reward total was -19.000000. loss_func: 0.393433\n",
      "resetting env. episode 1661 reward total was -20.000000. loss_func: 0.303958\n",
      "resetting env. episode 1662 reward total was -21.000000. loss_func: 0.111687\n",
      "resetting env. episode 1663 reward total was -20.000000. loss_func: 0.398025\n",
      "resetting env. episode 1664 reward total was -21.000000. loss_func: 0.115548\n",
      "resetting env. episode 1665 reward total was -20.000000. loss_func: 0.332184\n",
      "resetting env. episode 1666 reward total was -21.000000. loss_func: 0.060163\n",
      "resetting env. episode 1667 reward total was -20.000000. loss_func: 0.376337\n",
      "resetting env. episode 1668 reward total was -20.000000. loss_func: 0.398304\n",
      "resetting env. episode 1669 reward total was -21.000000. loss_func: 0.138455\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1670 reward total was -21.000000. loss_func: 0.086883\n",
      "resetting env. episode 1671 reward total was -18.000000. loss_func: 0.360567\n",
      "resetting env. episode 1672 reward total was -21.000000. loss_func: 0.070470\n",
      "resetting env. episode 1673 reward total was -21.000000. loss_func: 0.097557\n",
      "resetting env. episode 1674 reward total was -20.000000. loss_func: 0.339248\n",
      "resetting env. episode 1675 reward total was -21.000000. loss_func: 0.107733\n",
      "resetting env. episode 1676 reward total was -21.000000. loss_func: 0.049148\n",
      "resetting env. episode 1677 reward total was -20.000000. loss_func: 0.430893\n",
      "resetting env. episode 1678 reward total was -21.000000. loss_func: 0.085752\n",
      "resetting env. episode 1679 reward total was -19.000000. loss_func: 0.481309\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1680 reward total was -21.000000. loss_func: 0.047983\n",
      "resetting env. episode 1681 reward total was -20.000000. loss_func: 0.362793\n",
      "resetting env. episode 1682 reward total was -21.000000. loss_func: 0.057850\n",
      "resetting env. episode 1683 reward total was -21.000000. loss_func: 0.093872\n",
      "resetting env. episode 1684 reward total was -21.000000. loss_func: 0.104629\n",
      "resetting env. episode 1685 reward total was -20.000000. loss_func: 0.370836\n",
      "resetting env. episode 1686 reward total was -19.000000. loss_func: 0.458918\n",
      "resetting env. episode 1687 reward total was -21.000000. loss_func: 0.096896\n",
      "resetting env. episode 1688 reward total was -20.000000. loss_func: 0.345285\n",
      "resetting env. episode 1689 reward total was -20.000000. loss_func: 0.319444\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1690 reward total was -21.000000. loss_func: 0.141562\n",
      "resetting env. episode 1691 reward total was -21.000000. loss_func: 0.059882\n",
      "resetting env. episode 1692 reward total was -21.000000. loss_func: 0.077655\n",
      "resetting env. episode 1693 reward total was -21.000000. loss_func: 0.081930\n",
      "resetting env. episode 1694 reward total was -20.000000. loss_func: 0.394119\n",
      "resetting env. episode 1695 reward total was -19.000000. loss_func: 0.342215\n",
      "resetting env. episode 1696 reward total was -21.000000. loss_func: 0.125572\n",
      "resetting env. episode 1697 reward total was -21.000000. loss_func: 0.113432\n",
      "resetting env. episode 1698 reward total was -21.000000. loss_func: 0.066539\n",
      "resetting env. episode 1699 reward total was -21.000000. loss_func: 0.083708\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1700 reward total was -19.000000. loss_func: 0.416698\n",
      "resetting env. episode 1701 reward total was -21.000000. loss_func: 0.130661\n",
      "resetting env. episode 1702 reward total was -20.000000. loss_func: 0.416994\n",
      "resetting env. episode 1703 reward total was -21.000000. loss_func: 0.041433\n",
      "resetting env. episode 1704 reward total was -21.000000. loss_func: 0.089876\n",
      "resetting env. episode 1705 reward total was -21.000000. loss_func: 0.072683\n",
      "resetting env. episode 1706 reward total was -21.000000. loss_func: 0.105045\n",
      "resetting env. episode 1707 reward total was -20.000000. loss_func: 0.374781\n",
      "resetting env. episode 1708 reward total was -19.000000. loss_func: 0.323530\n",
      "resetting env. episode 1709 reward total was -20.000000. loss_func: 0.315455\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1710 reward total was -20.000000. loss_func: 0.311079\n",
      "resetting env. episode 1711 reward total was -21.000000. loss_func: 0.184588\n",
      "resetting env. episode 1712 reward total was -21.000000. loss_func: 0.101095\n",
      "resetting env. episode 1713 reward total was -19.000000. loss_func: 0.367853\n",
      "resetting env. episode 1714 reward total was -21.000000. loss_func: 0.078324\n",
      "resetting env. episode 1715 reward total was -21.000000. loss_func: 0.098307\n",
      "resetting env. episode 1716 reward total was -21.000000. loss_func: 0.076845\n",
      "resetting env. episode 1717 reward total was -21.000000. loss_func: 0.123590\n",
      "resetting env. episode 1718 reward total was -21.000000. loss_func: 0.064330\n",
      "resetting env. episode 1719 reward total was -20.000000. loss_func: 0.465221\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1720 reward total was -21.000000. loss_func: 0.101948\n",
      "resetting env. episode 1721 reward total was -20.000000. loss_func: 0.539417\n",
      "resetting env. episode 1722 reward total was -21.000000. loss_func: 0.077176\n",
      "resetting env. episode 1723 reward total was -21.000000. loss_func: 0.106693\n",
      "resetting env. episode 1724 reward total was -21.000000. loss_func: 0.076887\n",
      "resetting env. episode 1725 reward total was -19.000000. loss_func: 0.457768\n",
      "resetting env. episode 1726 reward total was -21.000000. loss_func: 0.089088\n",
      "resetting env. episode 1727 reward total was -16.000000. loss_func: 0.385925\n",
      "resetting env. episode 1728 reward total was -21.000000. loss_func: 0.027521\n",
      "resetting env. episode 1729 reward total was -21.000000. loss_func: 0.077038\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1730 reward total was -20.000000. loss_func: 0.315742\n",
      "resetting env. episode 1731 reward total was -20.000000. loss_func: 0.382365\n",
      "resetting env. episode 1732 reward total was -21.000000. loss_func: 0.089774\n",
      "resetting env. episode 1733 reward total was -16.000000. loss_func: 0.422460\n",
      "resetting env. episode 1734 reward total was -21.000000. loss_func: 0.099451\n",
      "resetting env. episode 1735 reward total was -21.000000. loss_func: 0.055716\n",
      "resetting env. episode 1736 reward total was -20.000000. loss_func: 0.414498\n",
      "resetting env. episode 1737 reward total was -21.000000. loss_func: 0.145015\n",
      "resetting env. episode 1738 reward total was -20.000000. loss_func: 0.428695\n",
      "resetting env. episode 1739 reward total was -19.000000. loss_func: 0.343109\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1740 reward total was -20.000000. loss_func: 0.461105\n",
      "resetting env. episode 1741 reward total was -21.000000. loss_func: 0.067863\n",
      "resetting env. episode 1742 reward total was -20.000000. loss_func: 0.351999\n",
      "resetting env. episode 1743 reward total was -21.000000. loss_func: 0.137271\n",
      "resetting env. episode 1744 reward total was -21.000000. loss_func: 0.044205\n",
      "resetting env. episode 1745 reward total was -20.000000. loss_func: 0.387198\n",
      "resetting env. episode 1746 reward total was -21.000000. loss_func: 0.101315\n",
      "resetting env. episode 1747 reward total was -21.000000. loss_func: 0.073004\n",
      "resetting env. episode 1748 reward total was -21.000000. loss_func: 0.098278\n",
      "resetting env. episode 1749 reward total was -21.000000. loss_func: 0.077944\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1750 reward total was -20.000000. loss_func: 0.433401\n",
      "resetting env. episode 1751 reward total was -21.000000. loss_func: 0.095527\n",
      "resetting env. episode 1752 reward total was -20.000000. loss_func: 0.348251\n",
      "resetting env. episode 1753 reward total was -20.000000. loss_func: 0.355545\n",
      "resetting env. episode 1754 reward total was -21.000000. loss_func: 0.094799\n",
      "resetting env. episode 1755 reward total was -21.000000. loss_func: 0.075621\n",
      "resetting env. episode 1756 reward total was -21.000000. loss_func: 0.060310\n",
      "resetting env. episode 1757 reward total was -21.000000. loss_func: 0.043614\n",
      "resetting env. episode 1758 reward total was -21.000000. loss_func: 0.075698\n",
      "resetting env. episode 1759 reward total was -21.000000. loss_func: 0.063928\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1760 reward total was -20.000000. loss_func: 0.500218\n",
      "resetting env. episode 1761 reward total was -20.000000. loss_func: 0.312980\n",
      "resetting env. episode 1762 reward total was -21.000000. loss_func: 0.112131\n",
      "resetting env. episode 1763 reward total was -20.000000. loss_func: 0.341219\n",
      "resetting env. episode 1764 reward total was -21.000000. loss_func: 0.111883\n",
      "resetting env. episode 1765 reward total was -21.000000. loss_func: 0.138711\n",
      "resetting env. episode 1766 reward total was -20.000000. loss_func: 0.357744\n",
      "resetting env. episode 1767 reward total was -21.000000. loss_func: 0.121701\n",
      "resetting env. episode 1768 reward total was -21.000000. loss_func: 0.117436\n",
      "resetting env. episode 1769 reward total was -21.000000. loss_func: 0.071340\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1770 reward total was -21.000000. loss_func: 0.056021\n",
      "resetting env. episode 1771 reward total was -21.000000. loss_func: 0.040551\n",
      "resetting env. episode 1772 reward total was -21.000000. loss_func: 0.060738\n",
      "resetting env. episode 1773 reward total was -20.000000. loss_func: 0.407937\n",
      "resetting env. episode 1774 reward total was -20.000000. loss_func: 0.423645\n",
      "resetting env. episode 1775 reward total was -21.000000. loss_func: 0.099704\n",
      "resetting env. episode 1776 reward total was -21.000000. loss_func: 0.105795\n",
      "resetting env. episode 1777 reward total was -19.000000. loss_func: 0.336464\n",
      "resetting env. episode 1778 reward total was -21.000000. loss_func: 0.085349\n",
      "resetting env. episode 1779 reward total was -21.000000. loss_func: 0.042582\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1780 reward total was -21.000000. loss_func: 0.174488\n",
      "resetting env. episode 1781 reward total was -21.000000. loss_func: 0.109442\n",
      "resetting env. episode 1782 reward total was -20.000000. loss_func: 0.325424\n",
      "resetting env. episode 1783 reward total was -21.000000. loss_func: 0.115051\n",
      "resetting env. episode 1784 reward total was -20.000000. loss_func: 0.346153\n",
      "resetting env. episode 1785 reward total was -20.000000. loss_func: 0.355118\n",
      "resetting env. episode 1786 reward total was -20.000000. loss_func: 0.353097\n",
      "resetting env. episode 1787 reward total was -21.000000. loss_func: 0.106913\n",
      "resetting env. episode 1788 reward total was -21.000000. loss_func: 0.088623\n",
      "resetting env. episode 1789 reward total was -21.000000. loss_func: 0.071281\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1790 reward total was -20.000000. loss_func: 0.374681\n",
      "resetting env. episode 1791 reward total was -21.000000. loss_func: 0.056047\n",
      "resetting env. episode 1792 reward total was -21.000000. loss_func: 0.080532\n",
      "resetting env. episode 1793 reward total was -21.000000. loss_func: 0.084984\n",
      "resetting env. episode 1794 reward total was -21.000000. loss_func: 0.111890\n",
      "resetting env. episode 1795 reward total was -20.000000. loss_func: 0.374017\n",
      "resetting env. episode 1796 reward total was -21.000000. loss_func: 0.074455\n",
      "resetting env. episode 1797 reward total was -21.000000. loss_func: 0.029235\n",
      "resetting env. episode 1798 reward total was -21.000000. loss_func: 0.075545\n",
      "resetting env. episode 1799 reward total was -21.000000. loss_func: 0.122995\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1800 reward total was -20.000000. loss_func: 0.383477\n",
      "resetting env. episode 1801 reward total was -21.000000. loss_func: 0.071601\n",
      "resetting env. episode 1802 reward total was -21.000000. loss_func: 0.099794\n",
      "resetting env. episode 1803 reward total was -20.000000. loss_func: 0.405132\n",
      "resetting env. episode 1804 reward total was -21.000000. loss_func: 0.069668\n",
      "resetting env. episode 1805 reward total was -21.000000. loss_func: 0.056437\n",
      "resetting env. episode 1806 reward total was -17.000000. loss_func: 0.346007\n",
      "resetting env. episode 1807 reward total was -21.000000. loss_func: 0.076214\n",
      "resetting env. episode 1808 reward total was -20.000000. loss_func: 0.326889\n",
      "resetting env. episode 1809 reward total was -19.000000. loss_func: 0.406600\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1810 reward total was -21.000000. loss_func: 0.164287\n",
      "resetting env. episode 1811 reward total was -21.000000. loss_func: 0.099531\n",
      "resetting env. episode 1812 reward total was -21.000000. loss_func: 0.052214\n",
      "resetting env. episode 1813 reward total was -21.000000. loss_func: 0.105716\n",
      "resetting env. episode 1814 reward total was -20.000000. loss_func: 0.353859\n",
      "resetting env. episode 1815 reward total was -21.000000. loss_func: 0.038911\n",
      "resetting env. episode 1816 reward total was -21.000000. loss_func: 0.089479\n",
      "resetting env. episode 1817 reward total was -19.000000. loss_func: 0.398375\n",
      "resetting env. episode 1818 reward total was -21.000000. loss_func: 0.071827\n",
      "resetting env. episode 1819 reward total was -17.000000. loss_func: 0.398906\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1820 reward total was -21.000000. loss_func: 0.107540\n",
      "resetting env. episode 1821 reward total was -21.000000. loss_func: 0.074543\n",
      "resetting env. episode 1822 reward total was -21.000000. loss_func: 0.111244\n",
      "resetting env. episode 1823 reward total was -20.000000. loss_func: 0.452072\n",
      "resetting env. episode 1824 reward total was -21.000000. loss_func: 0.052664\n",
      "resetting env. episode 1825 reward total was -21.000000. loss_func: 0.090094\n",
      "resetting env. episode 1826 reward total was -20.000000. loss_func: 0.405214\n",
      "resetting env. episode 1827 reward total was -21.000000. loss_func: 0.051476\n",
      "resetting env. episode 1828 reward total was -21.000000. loss_func: 0.101875\n",
      "resetting env. episode 1829 reward total was -19.000000. loss_func: 0.363746\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1830 reward total was -21.000000. loss_func: 0.052203\n",
      "resetting env. episode 1831 reward total was -21.000000. loss_func: 0.082776\n",
      "resetting env. episode 1832 reward total was -21.000000. loss_func: 0.085998\n",
      "resetting env. episode 1833 reward total was -21.000000. loss_func: 0.112502\n",
      "resetting env. episode 1834 reward total was -21.000000. loss_func: 0.074282\n",
      "resetting env. episode 1835 reward total was -19.000000. loss_func: 0.394866\n",
      "resetting env. episode 1836 reward total was -21.000000. loss_func: 0.070099\n",
      "resetting env. episode 1837 reward total was -21.000000. loss_func: 0.096342\n",
      "resetting env. episode 1838 reward total was -21.000000. loss_func: 0.089167\n",
      "resetting env. episode 1839 reward total was -21.000000. loss_func: 0.056854\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1840 reward total was -21.000000. loss_func: 0.087494\n",
      "resetting env. episode 1841 reward total was -21.000000. loss_func: 0.046482\n",
      "resetting env. episode 1842 reward total was -20.000000. loss_func: 0.388930\n",
      "resetting env. episode 1843 reward total was -20.000000. loss_func: 0.317978\n",
      "resetting env. episode 1844 reward total was -21.000000. loss_func: 0.104685\n",
      "resetting env. episode 1845 reward total was -20.000000. loss_func: 0.358337\n",
      "resetting env. episode 1846 reward total was -21.000000. loss_func: 0.105374\n",
      "resetting env. episode 1847 reward total was -20.000000. loss_func: 0.505819\n",
      "resetting env. episode 1848 reward total was -21.000000. loss_func: 0.059614\n",
      "resetting env. episode 1849 reward total was -21.000000. loss_func: 0.057386\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1850 reward total was -21.000000. loss_func: 0.121730\n",
      "resetting env. episode 1851 reward total was -19.000000. loss_func: 0.355362\n",
      "resetting env. episode 1852 reward total was -20.000000. loss_func: 0.366767\n",
      "resetting env. episode 1853 reward total was -20.000000. loss_func: 0.345488\n",
      "resetting env. episode 1854 reward total was -19.000000. loss_func: 0.454021\n",
      "resetting env. episode 1855 reward total was -21.000000. loss_func: 0.077496\n",
      "resetting env. episode 1856 reward total was -20.000000. loss_func: 0.396315\n",
      "resetting env. episode 1857 reward total was -19.000000. loss_func: 0.470656\n",
      "resetting env. episode 1858 reward total was -20.000000. loss_func: 0.300476\n",
      "resetting env. episode 1859 reward total was -19.000000. loss_func: 0.346693\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1860 reward total was -20.000000. loss_func: 0.362905\n",
      "resetting env. episode 1861 reward total was -21.000000. loss_func: 0.147459\n",
      "resetting env. episode 1862 reward total was -20.000000. loss_func: 0.354432\n",
      "resetting env. episode 1863 reward total was -19.000000. loss_func: 0.348689\n",
      "resetting env. episode 1864 reward total was -21.000000. loss_func: 0.152073\n",
      "resetting env. episode 1865 reward total was -19.000000. loss_func: 0.343674\n",
      "resetting env. episode 1866 reward total was -21.000000. loss_func: 0.161514\n",
      "resetting env. episode 1867 reward total was -21.000000. loss_func: 0.141327\n",
      "resetting env. episode 1868 reward total was -21.000000. loss_func: 0.059930\n",
      "resetting env. episode 1869 reward total was -20.000000. loss_func: 0.346184\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1870 reward total was -21.000000. loss_func: 0.112106\n",
      "resetting env. episode 1871 reward total was -19.000000. loss_func: 0.370528\n",
      "resetting env. episode 1872 reward total was -20.000000. loss_func: 0.337799\n",
      "resetting env. episode 1873 reward total was -21.000000. loss_func: 0.082376\n",
      "resetting env. episode 1874 reward total was -21.000000. loss_func: 0.080045\n",
      "resetting env. episode 1875 reward total was -21.000000. loss_func: 0.099833\n",
      "resetting env. episode 1876 reward total was -21.000000. loss_func: 0.083195\n",
      "resetting env. episode 1877 reward total was -21.000000. loss_func: 0.102528\n",
      "resetting env. episode 1878 reward total was -21.000000. loss_func: 0.060678\n",
      "resetting env. episode 1879 reward total was -18.000000. loss_func: 0.400603\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1880 reward total was -21.000000. loss_func: 0.117875\n",
      "resetting env. episode 1881 reward total was -20.000000. loss_func: 0.337996\n",
      "resetting env. episode 1882 reward total was -21.000000. loss_func: 0.113844\n",
      "resetting env. episode 1883 reward total was -20.000000. loss_func: 0.379976\n",
      "resetting env. episode 1884 reward total was -21.000000. loss_func: 0.070536\n",
      "resetting env. episode 1885 reward total was -20.000000. loss_func: 0.346817\n",
      "resetting env. episode 1886 reward total was -21.000000. loss_func: 0.088987\n",
      "resetting env. episode 1887 reward total was -18.000000. loss_func: 0.459062\n",
      "resetting env. episode 1888 reward total was -20.000000. loss_func: 0.345139\n",
      "resetting env. episode 1889 reward total was -21.000000. loss_func: 0.076859\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1890 reward total was -21.000000. loss_func: 0.064363\n",
      "resetting env. episode 1891 reward total was -20.000000. loss_func: 0.476339\n",
      "resetting env. episode 1892 reward total was -18.000000. loss_func: 0.342096\n",
      "resetting env. episode 1893 reward total was -21.000000. loss_func: 0.102338\n",
      "resetting env. episode 1894 reward total was -21.000000. loss_func: 0.093933\n",
      "resetting env. episode 1895 reward total was -21.000000. loss_func: 0.061147\n",
      "resetting env. episode 1896 reward total was -20.000000. loss_func: 0.371267\n",
      "resetting env. episode 1897 reward total was -20.000000. loss_func: 0.361915\n",
      "resetting env. episode 1898 reward total was -21.000000. loss_func: 0.121702\n",
      "resetting env. episode 1899 reward total was -21.000000. loss_func: 0.126271\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1900 reward total was -20.000000. loss_func: 0.315002\n",
      "resetting env. episode 1901 reward total was -21.000000. loss_func: 0.179238\n",
      "resetting env. episode 1902 reward total was -21.000000. loss_func: 0.117584\n",
      "resetting env. episode 1903 reward total was -21.000000. loss_func: 0.121520\n",
      "resetting env. episode 1904 reward total was -21.000000. loss_func: 0.054651\n",
      "resetting env. episode 1905 reward total was -21.000000. loss_func: 0.145572\n",
      "resetting env. episode 1906 reward total was -21.000000. loss_func: 0.176745\n",
      "resetting env. episode 1907 reward total was -17.000000. loss_func: 0.458589\n",
      "resetting env. episode 1908 reward total was -21.000000. loss_func: 0.046045\n",
      "resetting env. episode 1909 reward total was -20.000000. loss_func: 0.382347\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1910 reward total was -21.000000. loss_func: 0.046573\n",
      "resetting env. episode 1911 reward total was -20.000000. loss_func: 0.416042\n",
      "resetting env. episode 1912 reward total was -21.000000. loss_func: 0.102598\n",
      "resetting env. episode 1913 reward total was -20.000000. loss_func: 0.368186\n",
      "resetting env. episode 1914 reward total was -20.000000. loss_func: 0.464249\n",
      "resetting env. episode 1915 reward total was -17.000000. loss_func: 0.415512\n",
      "resetting env. episode 1916 reward total was -21.000000. loss_func: 0.119733\n",
      "resetting env. episode 1917 reward total was -21.000000. loss_func: 0.085612\n",
      "resetting env. episode 1918 reward total was -18.000000. loss_func: 0.403839\n",
      "resetting env. episode 1919 reward total was -21.000000. loss_func: 0.081762\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1920 reward total was -21.000000. loss_func: 0.043877\n",
      "resetting env. episode 1921 reward total was -21.000000. loss_func: 0.102670\n",
      "resetting env. episode 1922 reward total was -21.000000. loss_func: 0.073250\n",
      "resetting env. episode 1923 reward total was -21.000000. loss_func: 0.098036\n",
      "resetting env. episode 1924 reward total was -19.000000. loss_func: 0.337761\n",
      "resetting env. episode 1925 reward total was -21.000000. loss_func: 0.088751\n",
      "resetting env. episode 1926 reward total was -21.000000. loss_func: 0.095421\n",
      "resetting env. episode 1927 reward total was -20.000000. loss_func: 0.359490\n",
      "resetting env. episode 1928 reward total was -21.000000. loss_func: 0.073038\n",
      "resetting env. episode 1929 reward total was -20.000000. loss_func: 0.358598\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1930 reward total was -21.000000. loss_func: 0.084040\n",
      "resetting env. episode 1931 reward total was -19.000000. loss_func: 0.501907\n",
      "resetting env. episode 1932 reward total was -21.000000. loss_func: 0.056480\n",
      "resetting env. episode 1933 reward total was -21.000000. loss_func: 0.028144\n",
      "resetting env. episode 1934 reward total was -18.000000. loss_func: 0.486272\n",
      "resetting env. episode 1935 reward total was -20.000000. loss_func: 0.506245\n",
      "resetting env. episode 1936 reward total was -20.000000. loss_func: 0.349303\n",
      "resetting env. episode 1937 reward total was -21.000000. loss_func: 0.104752\n",
      "resetting env. episode 1938 reward total was -21.000000. loss_func: 0.072080\n",
      "resetting env. episode 1939 reward total was -21.000000. loss_func: 0.083524\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1940 reward total was -21.000000. loss_func: 0.105974\n",
      "resetting env. episode 1941 reward total was -21.000000. loss_func: 0.057697\n",
      "resetting env. episode 1942 reward total was -20.000000. loss_func: 0.383453\n",
      "resetting env. episode 1943 reward total was -21.000000. loss_func: 0.046305\n",
      "resetting env. episode 1944 reward total was -21.000000. loss_func: 0.099024\n",
      "resetting env. episode 1945 reward total was -21.000000. loss_func: 0.134899\n",
      "resetting env. episode 1946 reward total was -21.000000. loss_func: 0.039069\n",
      "resetting env. episode 1947 reward total was -21.000000. loss_func: 0.051456\n",
      "resetting env. episode 1948 reward total was -21.000000. loss_func: 0.077989\n",
      "resetting env. episode 1949 reward total was -21.000000. loss_func: 0.052114\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1950 reward total was -21.000000. loss_func: 0.083872\n",
      "resetting env. episode 1951 reward total was -21.000000. loss_func: 0.072706\n",
      "resetting env. episode 1952 reward total was -21.000000. loss_func: 0.076437\n",
      "resetting env. episode 1953 reward total was -20.000000. loss_func: 0.409648\n",
      "resetting env. episode 1954 reward total was -21.000000. loss_func: 0.040779\n",
      "resetting env. episode 1955 reward total was -21.000000. loss_func: 0.049337\n",
      "resetting env. episode 1956 reward total was -21.000000. loss_func: 0.057882\n",
      "resetting env. episode 1957 reward total was -19.000000. loss_func: 0.403819\n",
      "resetting env. episode 1958 reward total was -21.000000. loss_func: 0.097309\n",
      "resetting env. episode 1959 reward total was -19.000000. loss_func: 0.422913\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1960 reward total was -21.000000. loss_func: 0.045626\n",
      "resetting env. episode 1961 reward total was -21.000000. loss_func: 0.106678\n",
      "resetting env. episode 1962 reward total was -20.000000. loss_func: 0.443588\n",
      "resetting env. episode 1963 reward total was -21.000000. loss_func: 0.131946\n",
      "resetting env. episode 1964 reward total was -21.000000. loss_func: 0.092831\n",
      "resetting env. episode 1965 reward total was -21.000000. loss_func: 0.066524\n",
      "resetting env. episode 1966 reward total was -20.000000. loss_func: 0.449197\n",
      "resetting env. episode 1967 reward total was -18.000000. loss_func: 0.362388\n",
      "resetting env. episode 1968 reward total was -20.000000. loss_func: 0.380037\n",
      "resetting env. episode 1969 reward total was -21.000000. loss_func: 0.119477\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1970 reward total was -21.000000. loss_func: 0.073648\n",
      "resetting env. episode 1971 reward total was -21.000000. loss_func: 0.092889\n",
      "resetting env. episode 1972 reward total was -20.000000. loss_func: 0.385635\n",
      "resetting env. episode 1973 reward total was -21.000000. loss_func: 0.093517\n",
      "resetting env. episode 1974 reward total was -20.000000. loss_func: 0.354364\n",
      "resetting env. episode 1975 reward total was -20.000000. loss_func: 0.367598\n",
      "resetting env. episode 1976 reward total was -20.000000. loss_func: 0.497670\n",
      "resetting env. episode 1977 reward total was -21.000000. loss_func: 0.093385\n",
      "resetting env. episode 1978 reward total was -21.000000. loss_func: 0.090869\n",
      "resetting env. episode 1979 reward total was -21.000000. loss_func: 0.055202\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1980 reward total was -20.000000. loss_func: 0.368973\n",
      "resetting env. episode 1981 reward total was -20.000000. loss_func: 0.433020\n",
      "resetting env. episode 1982 reward total was -21.000000. loss_func: 0.110186\n",
      "resetting env. episode 1983 reward total was -21.000000. loss_func: 0.082344\n",
      "resetting env. episode 1984 reward total was -21.000000. loss_func: 0.065659\n",
      "resetting env. episode 1985 reward total was -21.000000. loss_func: 0.069574\n",
      "resetting env. episode 1986 reward total was -21.000000. loss_func: 0.069542\n",
      "resetting env. episode 1987 reward total was -21.000000. loss_func: 0.091110\n",
      "resetting env. episode 1988 reward total was -21.000000. loss_func: 0.078005\n",
      "resetting env. episode 1989 reward total was -20.000000. loss_func: 0.347384\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 1990 reward total was -19.000000. loss_func: 0.376868\n",
      "resetting env. episode 1991 reward total was -19.000000. loss_func: 0.349701\n",
      "resetting env. episode 1992 reward total was -21.000000. loss_func: 0.076078\n",
      "resetting env. episode 1993 reward total was -21.000000. loss_func: 0.102575\n",
      "resetting env. episode 1994 reward total was -21.000000. loss_func: 0.076672\n",
      "resetting env. episode 1995 reward total was -20.000000. loss_func: 0.365722\n",
      "resetting env. episode 1996 reward total was -21.000000. loss_func: 0.068743\n",
      "resetting env. episode 1997 reward total was -21.000000. loss_func: 0.056698\n",
      "resetting env. episode 1998 reward total was -17.000000. loss_func: 0.462936\n",
      "resetting env. episode 1999 reward total was -20.000000. loss_func: 0.340418\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2000 reward total was -21.000000. loss_func: 0.102347\n",
      "resetting env. episode 2001 reward total was -21.000000. loss_func: 0.095905\n",
      "resetting env. episode 2002 reward total was -21.000000. loss_func: 0.076008\n",
      "resetting env. episode 2003 reward total was -20.000000. loss_func: 0.358812\n",
      "resetting env. episode 2004 reward total was -21.000000. loss_func: 0.130081\n",
      "resetting env. episode 2005 reward total was -20.000000. loss_func: 0.377327\n",
      "resetting env. episode 2006 reward total was -19.000000. loss_func: 0.345987\n",
      "resetting env. episode 2007 reward total was -20.000000. loss_func: 0.462229\n",
      "resetting env. episode 2008 reward total was -19.000000. loss_func: 0.344309\n",
      "resetting env. episode 2009 reward total was -21.000000. loss_func: 0.082138\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2010 reward total was -20.000000. loss_func: 0.374817\n",
      "resetting env. episode 2011 reward total was -21.000000. loss_func: 0.076635\n",
      "resetting env. episode 2012 reward total was -21.000000. loss_func: 0.097970\n",
      "resetting env. episode 2013 reward total was -20.000000. loss_func: 0.324325\n",
      "resetting env. episode 2014 reward total was -21.000000. loss_func: 0.120185\n",
      "resetting env. episode 2015 reward total was -17.000000. loss_func: 0.475330\n",
      "resetting env. episode 2016 reward total was -21.000000. loss_func: 0.025895\n",
      "resetting env. episode 2017 reward total was -21.000000. loss_func: 0.043330\n",
      "resetting env. episode 2018 reward total was -21.000000. loss_func: 0.122997\n",
      "resetting env. episode 2019 reward total was -20.000000. loss_func: 0.407074\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2020 reward total was -21.000000. loss_func: 0.049356\n",
      "resetting env. episode 2021 reward total was -19.000000. loss_func: 0.421370\n",
      "resetting env. episode 2022 reward total was -21.000000. loss_func: 0.037316\n",
      "resetting env. episode 2023 reward total was -20.000000. loss_func: 0.463801\n",
      "resetting env. episode 2024 reward total was -21.000000. loss_func: 0.099812\n",
      "resetting env. episode 2025 reward total was -20.000000. loss_func: 0.463379\n",
      "resetting env. episode 2026 reward total was -20.000000. loss_func: 0.337684\n",
      "resetting env. episode 2027 reward total was -19.000000. loss_func: 0.495823\n",
      "resetting env. episode 2028 reward total was -19.000000. loss_func: 0.345285\n",
      "resetting env. episode 2029 reward total was -21.000000. loss_func: 0.088964\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2030 reward total was -20.000000. loss_func: 0.377960\n",
      "resetting env. episode 2031 reward total was -21.000000. loss_func: 0.134139\n",
      "resetting env. episode 2032 reward total was -21.000000. loss_func: 0.097742\n",
      "resetting env. episode 2033 reward total was -21.000000. loss_func: 0.089865\n",
      "resetting env. episode 2034 reward total was -20.000000. loss_func: 0.444825\n",
      "resetting env. episode 2035 reward total was -20.000000. loss_func: 0.372773\n",
      "resetting env. episode 2036 reward total was -21.000000. loss_func: 0.135426\n",
      "resetting env. episode 2037 reward total was -20.000000. loss_func: 0.516963\n",
      "resetting env. episode 2038 reward total was -20.000000. loss_func: 0.346922\n",
      "resetting env. episode 2039 reward total was -20.000000. loss_func: 0.318896\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2040 reward total was -20.000000. loss_func: 0.437681\n",
      "resetting env. episode 2041 reward total was -21.000000. loss_func: 0.150315\n",
      "resetting env. episode 2042 reward total was -19.000000. loss_func: 0.355394\n",
      "resetting env. episode 2043 reward total was -20.000000. loss_func: 0.301855\n",
      "resetting env. episode 2044 reward total was -20.000000. loss_func: 0.327326\n",
      "resetting env. episode 2045 reward total was -21.000000. loss_func: 0.131979\n",
      "resetting env. episode 2046 reward total was -20.000000. loss_func: 0.350966\n",
      "resetting env. episode 2047 reward total was -21.000000. loss_func: 0.108524\n",
      "resetting env. episode 2048 reward total was -19.000000. loss_func: 0.311439\n",
      "resetting env. episode 2049 reward total was -20.000000. loss_func: 0.319708\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2050 reward total was -20.000000. loss_func: 0.280268\n",
      "resetting env. episode 2051 reward total was -21.000000. loss_func: 0.088366\n",
      "resetting env. episode 2052 reward total was -21.000000. loss_func: 0.128789\n",
      "resetting env. episode 2053 reward total was -21.000000. loss_func: 0.096922\n",
      "resetting env. episode 2054 reward total was -21.000000. loss_func: 0.065693\n",
      "resetting env. episode 2055 reward total was -20.000000. loss_func: 0.438287\n",
      "resetting env. episode 2056 reward total was -20.000000. loss_func: 0.300341\n",
      "resetting env. episode 2057 reward total was -21.000000. loss_func: 0.085488\n",
      "resetting env. episode 2058 reward total was -18.000000. loss_func: 0.355706\n",
      "resetting env. episode 2059 reward total was -19.000000. loss_func: 0.485076\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2060 reward total was -20.000000. loss_func: 0.342623\n",
      "resetting env. episode 2061 reward total was -20.000000. loss_func: 0.317080\n",
      "resetting env. episode 2062 reward total was -21.000000. loss_func: 0.163254\n",
      "resetting env. episode 2063 reward total was -21.000000. loss_func: 0.062951\n",
      "resetting env. episode 2064 reward total was -21.000000. loss_func: 0.117935\n",
      "resetting env. episode 2065 reward total was -21.000000. loss_func: 0.025340\n",
      "resetting env. episode 2066 reward total was -21.000000. loss_func: 0.115947\n",
      "resetting env. episode 2067 reward total was -21.000000. loss_func: 0.051678\n",
      "resetting env. episode 2068 reward total was -20.000000. loss_func: 0.562252\n",
      "resetting env. episode 2069 reward total was -21.000000. loss_func: 0.093962\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2070 reward total was -21.000000. loss_func: 0.074684\n",
      "resetting env. episode 2071 reward total was -21.000000. loss_func: 0.096472\n",
      "resetting env. episode 2072 reward total was -19.000000. loss_func: 0.405344\n",
      "resetting env. episode 2073 reward total was -18.000000. loss_func: 0.396761\n",
      "resetting env. episode 2074 reward total was -21.000000. loss_func: 0.080434\n",
      "resetting env. episode 2075 reward total was -21.000000. loss_func: 0.101385\n",
      "resetting env. episode 2076 reward total was -21.000000. loss_func: 0.100584\n",
      "resetting env. episode 2077 reward total was -21.000000. loss_func: 0.084570\n",
      "resetting env. episode 2078 reward total was -21.000000. loss_func: 0.056916\n",
      "resetting env. episode 2079 reward total was -21.000000. loss_func: 0.090344\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2080 reward total was -21.000000. loss_func: 0.090088\n",
      "resetting env. episode 2081 reward total was -21.000000. loss_func: 0.056606\n",
      "resetting env. episode 2082 reward total was -21.000000. loss_func: 0.158051\n",
      "resetting env. episode 2083 reward total was -21.000000. loss_func: 0.117446\n",
      "resetting env. episode 2084 reward total was -21.000000. loss_func: 0.060624\n",
      "resetting env. episode 2085 reward total was -21.000000. loss_func: 0.024594\n",
      "resetting env. episode 2086 reward total was -20.000000. loss_func: 0.332567\n",
      "resetting env. episode 2087 reward total was -21.000000. loss_func: 0.111647\n",
      "resetting env. episode 2088 reward total was -21.000000. loss_func: 0.064896\n",
      "resetting env. episode 2089 reward total was -20.000000. loss_func: 0.390656\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2090 reward total was -21.000000. loss_func: 0.081212\n",
      "resetting env. episode 2091 reward total was -19.000000. loss_func: 0.400498\n",
      "resetting env. episode 2092 reward total was -21.000000. loss_func: 0.054566\n",
      "resetting env. episode 2093 reward total was -21.000000. loss_func: 0.120453\n",
      "resetting env. episode 2094 reward total was -21.000000. loss_func: 0.032840\n",
      "resetting env. episode 2095 reward total was -20.000000. loss_func: 0.352752\n",
      "resetting env. episode 2096 reward total was -19.000000. loss_func: 0.321472\n",
      "resetting env. episode 2097 reward total was -21.000000. loss_func: 0.131677\n",
      "resetting env. episode 2098 reward total was -21.000000. loss_func: 0.117011\n",
      "resetting env. episode 2099 reward total was -21.000000. loss_func: 0.079985\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2100 reward total was -20.000000. loss_func: 0.402980\n",
      "resetting env. episode 2101 reward total was -21.000000. loss_func: 0.037796\n",
      "resetting env. episode 2102 reward total was -21.000000. loss_func: 0.095548\n",
      "resetting env. episode 2103 reward total was -21.000000. loss_func: 0.059895\n",
      "resetting env. episode 2104 reward total was -20.000000. loss_func: 0.378478\n",
      "resetting env. episode 2105 reward total was -21.000000. loss_func: 0.042559\n",
      "resetting env. episode 2106 reward total was -21.000000. loss_func: 0.082759\n",
      "resetting env. episode 2107 reward total was -20.000000. loss_func: 0.479511\n",
      "resetting env. episode 2108 reward total was -21.000000. loss_func: 0.076919\n",
      "resetting env. episode 2109 reward total was -20.000000. loss_func: 0.400346\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2110 reward total was -21.000000. loss_func: 0.035025\n",
      "resetting env. episode 2111 reward total was -21.000000. loss_func: 0.068983\n",
      "resetting env. episode 2112 reward total was -20.000000. loss_func: 0.369772\n",
      "resetting env. episode 2113 reward total was -21.000000. loss_func: 0.091225\n",
      "resetting env. episode 2114 reward total was -21.000000. loss_func: 0.095041\n",
      "resetting env. episode 2115 reward total was -20.000000. loss_func: 0.523803\n",
      "resetting env. episode 2116 reward total was -21.000000. loss_func: 0.078252\n",
      "resetting env. episode 2117 reward total was -21.000000. loss_func: 0.080896\n",
      "resetting env. episode 2118 reward total was -19.000000. loss_func: 0.410430\n",
      "resetting env. episode 2119 reward total was -21.000000. loss_func: 0.134320\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2120 reward total was -19.000000. loss_func: 0.499176\n",
      "resetting env. episode 2121 reward total was -19.000000. loss_func: 0.418901\n",
      "resetting env. episode 2122 reward total was -21.000000. loss_func: 0.060088\n",
      "resetting env. episode 2123 reward total was -21.000000. loss_func: 0.045715\n",
      "resetting env. episode 2124 reward total was -21.000000. loss_func: 0.059546\n",
      "resetting env. episode 2125 reward total was -21.000000. loss_func: 0.101023\n",
      "resetting env. episode 2126 reward total was -21.000000. loss_func: 0.077685\n",
      "resetting env. episode 2127 reward total was -21.000000. loss_func: 0.078827\n",
      "resetting env. episode 2128 reward total was -21.000000. loss_func: 0.082182\n",
      "resetting env. episode 2129 reward total was -21.000000. loss_func: 0.086857\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2130 reward total was -20.000000. loss_func: 0.378717\n",
      "resetting env. episode 2131 reward total was -21.000000. loss_func: 0.090078\n",
      "resetting env. episode 2132 reward total was -19.000000. loss_func: 0.425802\n",
      "resetting env. episode 2133 reward total was -20.000000. loss_func: 0.308159\n",
      "resetting env. episode 2134 reward total was -21.000000. loss_func: 0.118814\n",
      "resetting env. episode 2135 reward total was -21.000000. loss_func: 0.127979\n",
      "resetting env. episode 2136 reward total was -21.000000. loss_func: 0.079174\n",
      "resetting env. episode 2137 reward total was -20.000000. loss_func: 0.356316\n",
      "resetting env. episode 2138 reward total was -21.000000. loss_func: 0.071875\n",
      "resetting env. episode 2139 reward total was -20.000000. loss_func: 0.335296\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2140 reward total was -20.000000. loss_func: 0.315516\n",
      "resetting env. episode 2141 reward total was -21.000000. loss_func: 0.069738\n",
      "resetting env. episode 2142 reward total was -20.000000. loss_func: 0.349478\n",
      "resetting env. episode 2143 reward total was -21.000000. loss_func: 0.062532\n",
      "resetting env. episode 2144 reward total was -21.000000. loss_func: 0.122597\n",
      "resetting env. episode 2145 reward total was -21.000000. loss_func: 0.042717\n",
      "resetting env. episode 2146 reward total was -21.000000. loss_func: 0.122754\n",
      "resetting env. episode 2147 reward total was -21.000000. loss_func: 0.096327\n",
      "resetting env. episode 2148 reward total was -20.000000. loss_func: 0.343825\n",
      "resetting env. episode 2149 reward total was -19.000000. loss_func: 0.344246\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2150 reward total was -20.000000. loss_func: 0.344263\n",
      "resetting env. episode 2151 reward total was -20.000000. loss_func: 0.309324\n",
      "resetting env. episode 2152 reward total was -20.000000. loss_func: 0.338005\n",
      "resetting env. episode 2153 reward total was -21.000000. loss_func: 0.112944\n",
      "resetting env. episode 2154 reward total was -20.000000. loss_func: 0.359995\n",
      "resetting env. episode 2155 reward total was -21.000000. loss_func: 0.105821\n",
      "resetting env. episode 2156 reward total was -18.000000. loss_func: 0.368149\n",
      "resetting env. episode 2157 reward total was -21.000000. loss_func: 0.166288\n",
      "resetting env. episode 2158 reward total was -21.000000. loss_func: 0.094372\n",
      "resetting env. episode 2159 reward total was -21.000000. loss_func: 0.079800\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2160 reward total was -21.000000. loss_func: 0.076662\n",
      "resetting env. episode 2161 reward total was -21.000000. loss_func: 0.075714\n",
      "resetting env. episode 2162 reward total was -20.000000. loss_func: 0.349762\n",
      "resetting env. episode 2163 reward total was -20.000000. loss_func: 0.452948\n",
      "resetting env. episode 2164 reward total was -21.000000. loss_func: 0.050288\n",
      "resetting env. episode 2165 reward total was -21.000000. loss_func: 0.087055\n",
      "resetting env. episode 2166 reward total was -20.000000. loss_func: 0.322905\n",
      "resetting env. episode 2167 reward total was -19.000000. loss_func: 0.449833\n",
      "resetting env. episode 2168 reward total was -21.000000. loss_func: 0.094182\n",
      "resetting env. episode 2169 reward total was -21.000000. loss_func: 0.072906\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2170 reward total was -21.000000. loss_func: 0.129650\n",
      "resetting env. episode 2171 reward total was -21.000000. loss_func: 0.036735\n",
      "resetting env. episode 2172 reward total was -21.000000. loss_func: 0.072346\n",
      "resetting env. episode 2173 reward total was -21.000000. loss_func: 0.068503\n",
      "resetting env. episode 2174 reward total was -19.000000. loss_func: 0.346878\n",
      "resetting env. episode 2175 reward total was -21.000000. loss_func: 0.103655\n",
      "resetting env. episode 2176 reward total was -21.000000. loss_func: 0.061229\n",
      "resetting env. episode 2177 reward total was -19.000000. loss_func: 0.443797\n",
      "resetting env. episode 2178 reward total was -20.000000. loss_func: 0.322991\n",
      "resetting env. episode 2179 reward total was -21.000000. loss_func: 0.111721\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2180 reward total was -21.000000. loss_func: 0.096724\n",
      "resetting env. episode 2181 reward total was -20.000000. loss_func: 0.356993\n",
      "resetting env. episode 2182 reward total was -21.000000. loss_func: 0.021355\n",
      "resetting env. episode 2183 reward total was -21.000000. loss_func: 0.091908\n",
      "resetting env. episode 2184 reward total was -21.000000. loss_func: 0.091457\n",
      "resetting env. episode 2185 reward total was -20.000000. loss_func: 0.346847\n",
      "resetting env. episode 2186 reward total was -21.000000. loss_func: 0.153819\n",
      "resetting env. episode 2187 reward total was -21.000000. loss_func: 0.067890\n",
      "resetting env. episode 2188 reward total was -19.000000. loss_func: 0.493998\n",
      "resetting env. episode 2189 reward total was -20.000000. loss_func: 0.452560\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2190 reward total was -21.000000. loss_func: 0.103663\n",
      "resetting env. episode 2191 reward total was -21.000000. loss_func: 0.079103\n",
      "resetting env. episode 2192 reward total was -21.000000. loss_func: 0.018177\n",
      "resetting env. episode 2193 reward total was -21.000000. loss_func: 0.066803\n",
      "resetting env. episode 2194 reward total was -21.000000. loss_func: 0.027201\n",
      "resetting env. episode 2195 reward total was -21.000000. loss_func: 0.140709\n",
      "resetting env. episode 2196 reward total was -19.000000. loss_func: 0.446517\n",
      "resetting env. episode 2197 reward total was -21.000000. loss_func: 0.104376\n",
      "resetting env. episode 2198 reward total was -21.000000. loss_func: 0.108026\n",
      "resetting env. episode 2199 reward total was -21.000000. loss_func: 0.061478\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2200 reward total was -21.000000. loss_func: 0.028743\n",
      "resetting env. episode 2201 reward total was -21.000000. loss_func: 0.080054\n",
      "resetting env. episode 2202 reward total was -20.000000. loss_func: 0.364121\n",
      "resetting env. episode 2203 reward total was -21.000000. loss_func: 0.114324\n",
      "resetting env. episode 2204 reward total was -20.000000. loss_func: 0.374365\n",
      "resetting env. episode 2205 reward total was -21.000000. loss_func: 0.078066\n",
      "resetting env. episode 2206 reward total was -21.000000. loss_func: 0.106287\n",
      "resetting env. episode 2207 reward total was -21.000000. loss_func: 0.033188\n",
      "resetting env. episode 2208 reward total was -21.000000. loss_func: 0.081356\n",
      "resetting env. episode 2209 reward total was -20.000000. loss_func: 0.388742\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2210 reward total was -21.000000. loss_func: 0.082485\n",
      "resetting env. episode 2211 reward total was -20.000000. loss_func: 0.355798\n",
      "resetting env. episode 2212 reward total was -20.000000. loss_func: 0.341957\n",
      "resetting env. episode 2213 reward total was -21.000000. loss_func: 0.042170\n",
      "resetting env. episode 2214 reward total was -20.000000. loss_func: 0.310785\n",
      "resetting env. episode 2215 reward total was -20.000000. loss_func: 0.369912\n",
      "resetting env. episode 2216 reward total was -21.000000. loss_func: 0.119138\n",
      "resetting env. episode 2217 reward total was -21.000000. loss_func: 0.027537\n",
      "resetting env. episode 2218 reward total was -20.000000. loss_func: 0.412672\n",
      "resetting env. episode 2219 reward total was -21.000000. loss_func: 0.142231\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2220 reward total was -20.000000. loss_func: 0.357657\n",
      "resetting env. episode 2221 reward total was -20.000000. loss_func: 0.317011\n",
      "resetting env. episode 2222 reward total was -21.000000. loss_func: 0.085955\n",
      "resetting env. episode 2223 reward total was -20.000000. loss_func: 0.409672\n",
      "resetting env. episode 2224 reward total was -19.000000. loss_func: 0.353678\n",
      "resetting env. episode 2225 reward total was -19.000000. loss_func: 0.336649\n",
      "resetting env. episode 2226 reward total was -21.000000. loss_func: 0.174115\n",
      "resetting env. episode 2227 reward total was -20.000000. loss_func: 0.337555\n",
      "resetting env. episode 2228 reward total was -20.000000. loss_func: 0.328878\n",
      "resetting env. episode 2229 reward total was -19.000000. loss_func: 0.319992\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2230 reward total was -20.000000. loss_func: 0.295901\n",
      "resetting env. episode 2231 reward total was -20.000000. loss_func: 0.334495\n",
      "resetting env. episode 2232 reward total was -20.000000. loss_func: 0.478333\n",
      "resetting env. episode 2233 reward total was -21.000000. loss_func: 0.105738\n",
      "resetting env. episode 2234 reward total was -21.000000. loss_func: 0.119158\n",
      "resetting env. episode 2235 reward total was -21.000000. loss_func: 0.086873\n",
      "resetting env. episode 2236 reward total was -21.000000. loss_func: 0.097566\n",
      "resetting env. episode 2237 reward total was -21.000000. loss_func: 0.105328\n",
      "resetting env. episode 2238 reward total was -21.000000. loss_func: 0.069010\n",
      "resetting env. episode 2239 reward total was -20.000000. loss_func: 0.370797\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2240 reward total was -19.000000. loss_func: 0.385514\n",
      "resetting env. episode 2241 reward total was -20.000000. loss_func: 0.359793\n",
      "resetting env. episode 2242 reward total was -21.000000. loss_func: 0.183795\n",
      "resetting env. episode 2243 reward total was -21.000000. loss_func: 0.089539\n",
      "resetting env. episode 2244 reward total was -21.000000. loss_func: 0.101158\n",
      "resetting env. episode 2245 reward total was -19.000000. loss_func: 0.341530\n",
      "resetting env. episode 2246 reward total was -20.000000. loss_func: 0.328668\n",
      "resetting env. episode 2247 reward total was -20.000000. loss_func: 0.450436\n",
      "resetting env. episode 2248 reward total was -21.000000. loss_func: 0.040632\n",
      "resetting env. episode 2249 reward total was -21.000000. loss_func: 0.137916\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2250 reward total was -21.000000. loss_func: 0.097295\n",
      "resetting env. episode 2251 reward total was -21.000000. loss_func: 0.045229\n",
      "resetting env. episode 2252 reward total was -21.000000. loss_func: 0.090187\n",
      "resetting env. episode 2253 reward total was -21.000000. loss_func: 0.075160\n",
      "resetting env. episode 2254 reward total was -21.000000. loss_func: 0.085864\n",
      "resetting env. episode 2255 reward total was -21.000000. loss_func: 0.060362\n",
      "resetting env. episode 2256 reward total was -21.000000. loss_func: 0.132802\n",
      "resetting env. episode 2257 reward total was -21.000000. loss_func: 0.043800\n",
      "resetting env. episode 2258 reward total was -20.000000. loss_func: 0.487060\n",
      "resetting env. episode 2259 reward total was -21.000000. loss_func: 0.121453\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2260 reward total was -20.000000. loss_func: 0.324509\n",
      "resetting env. episode 2261 reward total was -21.000000. loss_func: 0.070599\n",
      "resetting env. episode 2262 reward total was -21.000000. loss_func: 0.122344\n",
      "resetting env. episode 2263 reward total was -21.000000. loss_func: 0.036639\n",
      "resetting env. episode 2264 reward total was -21.000000. loss_func: 0.117822\n",
      "resetting env. episode 2265 reward total was -21.000000. loss_func: 0.108379\n",
      "resetting env. episode 2266 reward total was -21.000000. loss_func: 0.070453\n",
      "resetting env. episode 2267 reward total was -21.000000. loss_func: 0.065371\n",
      "resetting env. episode 2268 reward total was -21.000000. loss_func: 0.143842\n",
      "resetting env. episode 2269 reward total was -20.000000. loss_func: 0.343893\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2270 reward total was -19.000000. loss_func: 0.351130\n",
      "resetting env. episode 2271 reward total was -19.000000. loss_func: 0.331026\n",
      "resetting env. episode 2272 reward total was -21.000000. loss_func: 0.108904\n",
      "resetting env. episode 2273 reward total was -21.000000. loss_func: 0.065607\n",
      "resetting env. episode 2274 reward total was -21.000000. loss_func: 0.102297\n",
      "resetting env. episode 2275 reward total was -21.000000. loss_func: 0.040857\n",
      "resetting env. episode 2276 reward total was -21.000000. loss_func: 0.087734\n",
      "resetting env. episode 2277 reward total was -21.000000. loss_func: 0.092448\n",
      "resetting env. episode 2278 reward total was -20.000000. loss_func: 0.364190\n",
      "resetting env. episode 2279 reward total was -21.000000. loss_func: 0.033154\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2280 reward total was -20.000000. loss_func: 0.354200\n",
      "resetting env. episode 2281 reward total was -19.000000. loss_func: 0.523044\n",
      "resetting env. episode 2282 reward total was -20.000000. loss_func: 0.299705\n",
      "resetting env. episode 2283 reward total was -21.000000. loss_func: 0.067762\n",
      "resetting env. episode 2284 reward total was -21.000000. loss_func: 0.076757\n",
      "resetting env. episode 2285 reward total was -21.000000. loss_func: 0.037169\n",
      "resetting env. episode 2286 reward total was -21.000000. loss_func: 0.076166\n",
      "resetting env. episode 2287 reward total was -20.000000. loss_func: 0.363646\n",
      "resetting env. episode 2288 reward total was -19.000000. loss_func: 0.338462\n",
      "resetting env. episode 2289 reward total was -21.000000. loss_func: 0.198280\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2290 reward total was -21.000000. loss_func: 0.103859\n",
      "resetting env. episode 2291 reward total was -19.000000. loss_func: 0.372896\n",
      "resetting env. episode 2292 reward total was -21.000000. loss_func: 0.123249\n",
      "resetting env. episode 2293 reward total was -20.000000. loss_func: 0.377510\n",
      "resetting env. episode 2294 reward total was -21.000000. loss_func: 0.062111\n",
      "resetting env. episode 2295 reward total was -18.000000. loss_func: 0.479828\n",
      "resetting env. episode 2296 reward total was -21.000000. loss_func: 0.018871\n",
      "resetting env. episode 2297 reward total was -21.000000. loss_func: 0.033266\n",
      "resetting env. episode 2298 reward total was -21.000000. loss_func: 0.128525\n",
      "resetting env. episode 2299 reward total was -20.000000. loss_func: 0.388555\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2300 reward total was -20.000000. loss_func: 0.449829\n",
      "resetting env. episode 2301 reward total was -20.000000. loss_func: 0.335044\n",
      "resetting env. episode 2302 reward total was -21.000000. loss_func: 0.095957\n",
      "resetting env. episode 2303 reward total was -19.000000. loss_func: 0.358049\n",
      "resetting env. episode 2304 reward total was -21.000000. loss_func: 0.144970\n",
      "resetting env. episode 2305 reward total was -21.000000. loss_func: 0.049414\n",
      "resetting env. episode 2306 reward total was -21.000000. loss_func: 0.083495\n",
      "resetting env. episode 2307 reward total was -20.000000. loss_func: 0.370909\n",
      "resetting env. episode 2308 reward total was -21.000000. loss_func: 0.022256\n",
      "resetting env. episode 2309 reward total was -21.000000. loss_func: 0.121967\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2310 reward total was -19.000000. loss_func: 0.377105\n",
      "resetting env. episode 2311 reward total was -20.000000. loss_func: 0.294493\n",
      "resetting env. episode 2312 reward total was -21.000000. loss_func: 0.092787\n",
      "resetting env. episode 2313 reward total was -21.000000. loss_func: 0.122631\n",
      "resetting env. episode 2314 reward total was -21.000000. loss_func: 0.086997\n",
      "resetting env. episode 2315 reward total was -19.000000. loss_func: 0.332235\n",
      "resetting env. episode 2316 reward total was -21.000000. loss_func: 0.078489\n",
      "resetting env. episode 2317 reward total was -20.000000. loss_func: 0.369904\n",
      "resetting env. episode 2318 reward total was -21.000000. loss_func: 0.071106\n",
      "resetting env. episode 2319 reward total was -20.000000. loss_func: 0.351143\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2320 reward total was -19.000000. loss_func: 0.391525\n",
      "resetting env. episode 2321 reward total was -18.000000. loss_func: 0.413473\n",
      "resetting env. episode 2322 reward total was -19.000000. loss_func: 0.339875\n",
      "resetting env. episode 2323 reward total was -21.000000. loss_func: 0.141735\n",
      "resetting env. episode 2324 reward total was -21.000000. loss_func: 0.103472\n",
      "resetting env. episode 2325 reward total was -20.000000. loss_func: 0.358489\n",
      "resetting env. episode 2326 reward total was -19.000000. loss_func: 0.330056\n",
      "resetting env. episode 2327 reward total was -20.000000. loss_func: 0.307785\n",
      "resetting env. episode 2328 reward total was -17.000000. loss_func: 0.381659\n",
      "resetting env. episode 2329 reward total was -20.000000. loss_func: 0.544892\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2330 reward total was -21.000000. loss_func: 0.154489\n",
      "resetting env. episode 2331 reward total was -21.000000. loss_func: 0.127975\n",
      "resetting env. episode 2332 reward total was -20.000000. loss_func: 0.356286\n",
      "resetting env. episode 2333 reward total was -21.000000. loss_func: 0.097568\n",
      "resetting env. episode 2334 reward total was -21.000000. loss_func: 0.078357\n",
      "resetting env. episode 2335 reward total was -20.000000. loss_func: 0.463705\n",
      "resetting env. episode 2336 reward total was -20.000000. loss_func: 0.331375\n",
      "resetting env. episode 2337 reward total was -21.000000. loss_func: 0.061764\n",
      "resetting env. episode 2338 reward total was -21.000000. loss_func: 0.113319\n",
      "resetting env. episode 2339 reward total was -21.000000. loss_func: 0.086634\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2340 reward total was -20.000000. loss_func: 0.352423\n",
      "resetting env. episode 2341 reward total was -21.000000. loss_func: 0.116582\n",
      "resetting env. episode 2342 reward total was -20.000000. loss_func: 0.394705\n",
      "resetting env. episode 2343 reward total was -21.000000. loss_func: 0.150342\n",
      "resetting env. episode 2344 reward total was -20.000000. loss_func: 0.364104\n",
      "resetting env. episode 2345 reward total was -20.000000. loss_func: 0.455902\n",
      "resetting env. episode 2346 reward total was -21.000000. loss_func: 0.057152\n",
      "resetting env. episode 2347 reward total was -21.000000. loss_func: 0.070454\n",
      "resetting env. episode 2348 reward total was -20.000000. loss_func: 0.364107\n",
      "resetting env. episode 2349 reward total was -18.000000. loss_func: 0.331949\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2350 reward total was -21.000000. loss_func: 0.148136\n",
      "resetting env. episode 2351 reward total was -21.000000. loss_func: 0.063378\n",
      "resetting env. episode 2352 reward total was -20.000000. loss_func: 0.351416\n",
      "resetting env. episode 2353 reward total was -21.000000. loss_func: 0.052270\n",
      "resetting env. episode 2354 reward total was -21.000000. loss_func: 0.090469\n",
      "resetting env. episode 2355 reward total was -19.000000. loss_func: 0.333265\n",
      "resetting env. episode 2356 reward total was -21.000000. loss_func: 0.079892\n",
      "resetting env. episode 2357 reward total was -21.000000. loss_func: 0.074123\n",
      "resetting env. episode 2358 reward total was -21.000000. loss_func: 0.104776\n",
      "resetting env. episode 2359 reward total was -21.000000. loss_func: 0.038607\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2360 reward total was -21.000000. loss_func: 0.034478\n",
      "resetting env. episode 2361 reward total was -21.000000. loss_func: 0.108328\n",
      "resetting env. episode 2362 reward total was -19.000000. loss_func: 0.400925\n",
      "resetting env. episode 2363 reward total was -21.000000. loss_func: 0.053629\n",
      "resetting env. episode 2364 reward total was -21.000000. loss_func: 0.027982\n",
      "resetting env. episode 2365 reward total was -21.000000. loss_func: 0.087776\n",
      "resetting env. episode 2366 reward total was -21.000000. loss_func: 0.020588\n",
      "resetting env. episode 2367 reward total was -20.000000. loss_func: 0.391409\n",
      "resetting env. episode 2368 reward total was -21.000000. loss_func: 0.080422\n",
      "resetting env. episode 2369 reward total was -20.000000. loss_func: 0.354607\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2370 reward total was -19.000000. loss_func: 0.335524\n",
      "resetting env. episode 2371 reward total was -20.000000. loss_func: 0.305107\n",
      "resetting env. episode 2372 reward total was -21.000000. loss_func: 0.150620\n",
      "resetting env. episode 2373 reward total was -20.000000. loss_func: 0.548598\n",
      "resetting env. episode 2374 reward total was -21.000000. loss_func: 0.072683\n",
      "resetting env. episode 2375 reward total was -21.000000. loss_func: 0.092080\n",
      "resetting env. episode 2376 reward total was -20.000000. loss_func: 0.426585\n",
      "resetting env. episode 2377 reward total was -20.000000. loss_func: 0.290835\n",
      "resetting env. episode 2378 reward total was -20.000000. loss_func: 0.296234\n",
      "resetting env. episode 2379 reward total was -21.000000. loss_func: 0.131636\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2380 reward total was -20.000000. loss_func: 0.383246\n",
      "resetting env. episode 2381 reward total was -21.000000. loss_func: 0.091797\n",
      "resetting env. episode 2382 reward total was -20.000000. loss_func: 0.372354\n",
      "resetting env. episode 2383 reward total was -20.000000. loss_func: 0.354806\n",
      "resetting env. episode 2384 reward total was -20.000000. loss_func: 0.298912\n",
      "resetting env. episode 2385 reward total was -21.000000. loss_func: 0.117726\n",
      "resetting env. episode 2386 reward total was -20.000000. loss_func: 0.344178\n",
      "resetting env. episode 2387 reward total was -21.000000. loss_func: 0.132243\n",
      "resetting env. episode 2388 reward total was -21.000000. loss_func: 0.103048\n",
      "resetting env. episode 2389 reward total was -21.000000. loss_func: 0.074844\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2390 reward total was -21.000000. loss_func: 0.033054\n",
      "resetting env. episode 2391 reward total was -20.000000. loss_func: 0.338980\n",
      "resetting env. episode 2392 reward total was -21.000000. loss_func: 0.040182\n",
      "resetting env. episode 2393 reward total was -21.000000. loss_func: 0.040476\n",
      "resetting env. episode 2394 reward total was -21.000000. loss_func: 0.110771\n",
      "resetting env. episode 2395 reward total was -21.000000. loss_func: 0.114696\n",
      "resetting env. episode 2396 reward total was -20.000000. loss_func: 0.336791\n",
      "resetting env. episode 2397 reward total was -21.000000. loss_func: 0.134579\n",
      "resetting env. episode 2398 reward total was -19.000000. loss_func: 0.446294\n",
      "resetting env. episode 2399 reward total was -20.000000. loss_func: 0.321352\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2400 reward total was -20.000000. loss_func: 0.409080\n",
      "resetting env. episode 2401 reward total was -21.000000. loss_func: 0.058577\n",
      "resetting env. episode 2402 reward total was -21.000000. loss_func: 0.100361\n",
      "resetting env. episode 2403 reward total was -21.000000. loss_func: 0.060270\n",
      "resetting env. episode 2404 reward total was -18.000000. loss_func: 0.369491\n",
      "resetting env. episode 2405 reward total was -21.000000. loss_func: 0.036112\n",
      "resetting env. episode 2406 reward total was -20.000000. loss_func: 0.345827\n",
      "resetting env. episode 2407 reward total was -20.000000. loss_func: 0.392998\n",
      "resetting env. episode 2408 reward total was -21.000000. loss_func: 0.070299\n",
      "resetting env. episode 2409 reward total was -21.000000. loss_func: 0.077577\n",
      "Saved model to disk at Models/H5k4_RL_pong_RMSprop_accumulloss_2event.ckpt\n",
      "resetting env. episode 2410 reward total was -21.000000. loss_func: 0.078060\n",
      "resetting env. episode 2411 reward total was -21.000000. loss_func: 0.108409\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "prev_x = None # used in computing the difference frame\n",
    "xs,hs,dlogps,drs = [],[],[],[]\n",
    "ys=[];byss=[];rss=[];tpreds=[];\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 0;\n",
    "\n",
    "ModelName = 'H5k4_RL_pong_RMSprop_accumulloss_2event'\n",
    "ModelFile = 'Models/'+ModelName+'.ckpt';\n",
    "render = False;\n",
    "resume = 1;\n",
    "batch_size=1;\n",
    "learning_rate = 1e-2\n",
    "optimiser = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# episode_number = 0;\n",
    "\n",
    "if 'losshist' in locals():\n",
    "    pass\n",
    "else:\n",
    "    losshist = LossHist();\n",
    "\n",
    "while True:\n",
    "    if resume:\n",
    "        model = loadmodel(ModelFile)    \n",
    "#         losshist=losshist_temp;\n",
    "        \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss=lossfunc)\n",
    "    while True:\n",
    "        if render: env.render()\n",
    "\n",
    "        # preprocess the observation, set input to network to be difference image\n",
    "        cur_x = prepro(observation)\n",
    "        diff_x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "        prev_x = cur_x\n",
    "        x = np.reshape(diff_x,[1,D1,D2,1]);\n",
    "        \n",
    "        # Sample action and label it \n",
    "        aprob = 0.5;\n",
    "        action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "        y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "        \n",
    "        # Run predictor\n",
    "        tpred = model.predict([x,np.array([[y]])]);\n",
    "#         tpred = model.predict({'input_1':x,'input_2':np.array([[y]])});\n",
    "        \n",
    "    \n",
    "        # record various intermediates (needed later for backprop)\n",
    "        xs.append(x) # observation\n",
    "        ys.append(y)\n",
    "        tpreds.append(tpred);\n",
    "#         spreds.append(spred);\n",
    "\n",
    "        # step the environment and get new measurements\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        reward_sum += reward\n",
    "        drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "        \n",
    "\n",
    "        if done: # an episode finished\n",
    "            episode_number += 1\n",
    "\n",
    "            # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "            epx = np.vstack(xs)\n",
    "            epy = np.vstack(ys);\n",
    "            epr = np.vstack(drs)\n",
    "            eptpred=np.vstack(tpreds);\n",
    "#             epspred=np.vstack()\n",
    "            xs,hs,dlogps,drs,ys,tpreds = [],[],[],[],[],[] # reset array memory\n",
    "            \n",
    "#             time_epr=time_rewards(epr);\n",
    "            tpr=time_rewards(epr);\n",
    "            time_epr = decouple(tpr);\n",
    "            \n",
    "            \n",
    "            curr_loss = model.train_on_batch([epx,epy], time_epr)\n",
    "            losshist.add(episode_number,curr_loss);\n",
    "            \n",
    "            if episode_number % batch_size == 0:\n",
    "                #accumulate gradient over batch where appropriate\n",
    "                pass\n",
    "   \n",
    "            # boring book-keeping\n",
    "            running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "            print 'resetting env. episode %d reward total was %f. loss_func: %f' % (episode_number, reward_sum, curr_loss)\n",
    "            if episode_number % 10  == 9: \n",
    "                savemodel(model,ModelFile)\n",
    "\n",
    "            reward_sum = 0\n",
    "            observation = env.reset() # reset env\n",
    "            prev_x = None\n",
    "            #     print ('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33882cdd50>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAJCCAYAAABj+qvQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCEEMAAAgIf8fRU4hD2SneLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3390dc2490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# discount_rewards(epdlogp)\n",
    "x.size\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "fig=plt.figure(figsize=[10,10])\n",
    "ax1=plt.subplot()\n",
    "ax1.plot((time_epr))\n",
    "ax1.plot(eptpred[:,0])\n",
    "ax1.plot(eptpred[:,1])\n",
    "\n",
    "# ax1.plot(np.sign(-(epspred-.5))*2*(eptpred-1))\n",
    "\n",
    "\n",
    "# ax1.plot(discounted_epr)\n",
    "# ax1.scatter(abs(time_epr),eptpred)\n",
    "# ax1.set_xlim([0, 500])\n",
    "# ax1.set_xlim([500, 1000])\n",
    "# ax1.set_ylim([-0, 50])\n",
    "\n",
    "\n",
    "# ax1.imshow(eph[:500,:500].T)\n",
    "# tpreds.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " ..., \n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n"
     ]
    }
   ],
   "source": [
    "# print(time_epr.ravel())\n",
    "# time_epr\n",
    "# tpreds\n",
    "# H\n",
    "# np.expand_dims(epx,1).shape\n",
    "# curr_loss = sess.run(loss,feed_dict={xinput: epx, input_y: epy, rtime: time_epr});\n",
    "# epx.shape\n",
    "# tf.reshape(epy);\n",
    "# D*H\n",
    "# oSaver = tf.train.Saver()\n",
    "print(sess.run(score,feed_dict={xinput: epx, input_y: epy, rtime: time_epr}))\n",
    "# oSess = sess\n",
    "# oSaver.save(oSess, ModelFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
